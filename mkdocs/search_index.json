{
    "docs": [
        {
            "location": "/",
            "text": "ILLIXR\n\n\n\n\n\n\n\n\n\n    \n\n\n\n\nIllinois Extended Reality testbed or ILLIXR (pronounced like elixir) is\n    the first fully open-source Extended Reality (XR) system and testbed.\nThe modular, extensible, and \nOpenXR\n-compatible ILLIXR runtime\n    integrates state-of-the-art XR components into a complete XR system.\nThe testbed is part of the broader \nILLIXR consortium\n,\n    an industry-supported community effort to democratize XR systems\n    research, development, and benchmarking.\n\n\nYou can find the complete ILLIXR system \nhere\n.\n\n\nILLIXR also provides its components in standalone configurations to enable architects and\n    system designers to research each component in isolation.\nThe standalone components are packaged together in the \nv1-latest release\n of ILLIXR. \n\n\nILLIXR's modular and extensible runtime allows adding new components and swapping different\n    implementations of a given component.\nILLIXR currently contains the following components: \n\n\n\n\n\n\nPerception\n\n\n\n\nEye Tracking\n\n\nRITNet\n **\n\n\n\n\n\n\nScene Reconstruction\n\n\nElasticFusion\n **\n\n\nKinectFusion\n **\n\n\n\n\n\n\nSimultaneous Localization and Mapping\n\n\nOpenVINS\n **\n\n\nKimera-VIO\n **\n\n\n\n\n\n\nCameras and IMUs\n\n\nZED Mini\n\n\nIntel RealSense\n\n\n\n\n\n\n\n\n\n\n\n\nVisual\n\n\n\n\nChromatic aberration correction\n\n\nComputational holography for adaptive multi-focal displays\n **\n\n\nLens distortion correction\n\n\nAsynchronous Reprojection (TimeWarp)\n\n\n\n\n\n\n\n\nAural\n\n\n\n\nAudio encoding\n **\n\n\nAudio playback\n **\n\n\n\n\n\n\n\n\n(** Source is hosted in an external repository under the \nILLIXR project\n.)\n\n\nWe continue to add more components (new components and new implementations). \n\n\nMany of the current components of ILLIXR were developed by domain experts and obtained from\n    publicly available repositories.\nThey were modified for one or more of the following reasons: fixing compilation, adding features,\n    or removing extraneous code or dependencies.\nEach component not developed by us is available as a forked github repository for\n    proper attribution to its authors.\n\n\nPapers, talks, demos, consortium\n\n\nA \npaper\n with details on ILLIXR, including its components, runtime, telemetry support,\n    and a comprehensive analysis of performance, power, and quality on desktop and embedded systems.\n\n\nA \ntalk presented at NVIDIA GTC'21\n describing ILLIXR and announcing the ILLIXR consortium:\n    \nVideo\n.\n    \nSlides\n. \n\n\nA \ndemo\n of an OpenXR application running with ILLIXR.\n\n\nThe \nILLIXR consortium\n is an industry-supported community effort to democratize\n    XR systems research, development, and benchmarking.\nVisit our \nweb site\n for more information.\n\n\nCitation\n\n\nWe request that you cite our following \npaper\n (new version coming soon)\n    when you use ILLIXR for a publication.\nWe would also appreciate it if you send us a citation once your work has been published.\n\n\n@misc{HuzaifaDesai2020,\n    title={Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research},\n    author={Muhammad Huzaifa and Rishi Desai and Samuel Grayson and Xutao Jiang and Ying Jing and Jae Lee and Fang Lu and Yihan Pang and Joseph Ravichandran and Finn Sinclair and Boyuan Tian and Hengzhi Yuan and Jeffrey Zhang and Sarita V. Adve},\n    year={2021},\n    eprint={2004.04643},\n    primaryClass={cs.DC}\n}\n\n\n\n\nGetting Started and Documentation\n\n\nFor more information, see our \nGetting Started page\n.\n\n\nAcknowledgements\n\n\nThe ILLIXR project started in \nSarita Adve\u2019s research group\n,\n    co-led by PhD candidate Muhammad Huzaifa, at the University of Illinois at Urbana-Champaign.\nOther major contributors include\n    Rishi Desai,\n    Samuel Grayson,\n    Xutao Jiang,\n    Ying Jing,\n    Jae Lee,\n    Fang Lu,\n    Yihan Pang,\n    Joseph Ravichandran,\n    Giordano Salvador,\n    Finn Sinclair,\n    Boyuan Tian,\n    Henghzhi Yuan,\n    and\n    Jeffrey Zhang.\n\n\nILLIXR came together after many consultations with researchers and practitioners in many domains:\n    audio,\n    graphics,\n    optics,\n    robotics,\n    signal processing,\n    and\n    extended reality systems.\nWe are deeply grateful for all of these discussions and specifically to the following:\n    Wei Cu,\n    Aleksandra Faust,\n    Liang Gao,\n    Matt Horsnell,\n    Amit Jindal,\n    Steve LaValle,\n    Steve Lovegrove,\n    Andrew Maimone,\n    Vegard \u00d8ye,\n    Martin Persson,\n    Archontis Politis,\n    Eric Shaffer,\n    Paris Smaragdis,\n    Sachin Talathi,\n    and\n    Chris Widdowson.\n\n\nOur OpenXR implementation is derived from \nMonado\n.\nWe are particularly thankful to Jakob Bornecrantz and Ryan Pavlik.\n\n\nThe development of ILLIXR was supported by\n    the Applications Driving Architectures (ADA) Research Center\n        (a JUMP Center co-sponsored by SRC and DARPA),\n    the Center for Future Architectures Research (C-FAR, a STARnet research center),\n    a Semiconductor Research Corporation program sponsored by MARCO and DARPA,\n    and\n    by a Google Faculty Research Award.\nThe development of ILLIXR was also aided by generous hardware and software donations\n    from ARM and NVIDIA.\nFacebook Reality Labs provided the \nOpenEDS Semantic Segmentation Dataset\n.\n\n\nWesley Darvin came up with the name for ILLIXR.\n\n\nLicensing Structure\n\n\nILLIXR is available as open-source software under the permissive\n    \nUniversity of Illinois/NCSA Open Source License\n.\nAs mentioned above, ILLIXR largely consists of components developed by domain experts and\n    modified for the purposes of inclusion in ILLIXR.\nHowever, ILLIXR does contain software developed solely by us.\n\nThe NCSA license is limited to only this software\n.\nThe external libraries and softwares included in ILLIXR each have their own licenses and\n    must be used according to those licenses:\n\n\n\n\n\n\nElasticFusion\n \\ \nElasticFusion license\n\n\n\n\n\n\nKinectFusion\n \\ \nMIT License\n\n\n\n\n\n\nGTSAM\n \\ \nSimplified BSD License\n\n\n\n\n\n\nHOTlab\n \\ \nGNU Lesser General Public License v3.0\n\n\n\n\n\n\nKimera-VIO\n \\ \nSimplified BSD License\n\n\n\n\n\n\nlibspatialaudio\n \\ \nGNU Lesser General Public License v2.1\n\n\n\n\n\n\nMonado\n \\ \nBoost Software License 1.0\n\n\n\n\n\n\nmoodycamel::ConcurrentQueue\n \\ \nSimplified BSD License\n\n\n\n\n\n\nOpen-VINS\n \\ \nGNU General Public License v3.0\n\n\n\n\n\n\nRITnet\n \\ \nMIT License\n\n\n\n\n\n\nNote that ILLIXR's extensibility allows the source to be configured and compiled using only\n    permissively licensed software.\n\n\nGet in Touch\n\n\nWhether you are a computer architect, a compiler writer, a systems person, work on XR related algorithms\n    or applications, or just anyone interested in XR research, development, or products,\n    we would love to hear from you and hope you will contribute!\nYou can join\n    the \nILLIXR consortium\n,\n    \nDiscord\n,\n    or \nmailing list\n,\n    or send us an \nemail\n,\n    or just send us a pull request!",
            "title": "Home"
        },
        {
            "location": "/#illixr",
            "text": "Illinois Extended Reality testbed or ILLIXR (pronounced like elixir) is\n    the first fully open-source Extended Reality (XR) system and testbed.\nThe modular, extensible, and  OpenXR -compatible ILLIXR runtime\n    integrates state-of-the-art XR components into a complete XR system.\nThe testbed is part of the broader  ILLIXR consortium ,\n    an industry-supported community effort to democratize XR systems\n    research, development, and benchmarking.  You can find the complete ILLIXR system  here .  ILLIXR also provides its components in standalone configurations to enable architects and\n    system designers to research each component in isolation.\nThe standalone components are packaged together in the  v1-latest release  of ILLIXR.   ILLIXR's modular and extensible runtime allows adding new components and swapping different\n    implementations of a given component.\nILLIXR currently contains the following components:     Perception   Eye Tracking  RITNet  **    Scene Reconstruction  ElasticFusion  **  KinectFusion  **    Simultaneous Localization and Mapping  OpenVINS  **  Kimera-VIO  **    Cameras and IMUs  ZED Mini  Intel RealSense       Visual   Chromatic aberration correction  Computational holography for adaptive multi-focal displays  **  Lens distortion correction  Asynchronous Reprojection (TimeWarp)     Aural   Audio encoding  **  Audio playback  **     (** Source is hosted in an external repository under the  ILLIXR project .)  We continue to add more components (new components and new implementations).   Many of the current components of ILLIXR were developed by domain experts and obtained from\n    publicly available repositories.\nThey were modified for one or more of the following reasons: fixing compilation, adding features,\n    or removing extraneous code or dependencies.\nEach component not developed by us is available as a forked github repository for\n    proper attribution to its authors.",
            "title": "ILLIXR"
        },
        {
            "location": "/#papers-talks-demos-consortium",
            "text": "A  paper  with details on ILLIXR, including its components, runtime, telemetry support,\n    and a comprehensive analysis of performance, power, and quality on desktop and embedded systems.  A  talk presented at NVIDIA GTC'21  describing ILLIXR and announcing the ILLIXR consortium:\n     Video .\n     Slides .   A  demo  of an OpenXR application running with ILLIXR.  The  ILLIXR consortium  is an industry-supported community effort to democratize\n    XR systems research, development, and benchmarking.\nVisit our  web site  for more information.",
            "title": "Papers, talks, demos, consortium"
        },
        {
            "location": "/#citation",
            "text": "We request that you cite our following  paper  (new version coming soon)\n    when you use ILLIXR for a publication.\nWe would also appreciate it if you send us a citation once your work has been published.  @misc{HuzaifaDesai2020,\n    title={Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research},\n    author={Muhammad Huzaifa and Rishi Desai and Samuel Grayson and Xutao Jiang and Ying Jing and Jae Lee and Fang Lu and Yihan Pang and Joseph Ravichandran and Finn Sinclair and Boyuan Tian and Hengzhi Yuan and Jeffrey Zhang and Sarita V. Adve},\n    year={2021},\n    eprint={2004.04643},\n    primaryClass={cs.DC}\n}",
            "title": "Citation"
        },
        {
            "location": "/#getting-started-and-documentation",
            "text": "For more information, see our  Getting Started page .",
            "title": "Getting Started and Documentation"
        },
        {
            "location": "/#acknowledgements",
            "text": "The ILLIXR project started in  Sarita Adve\u2019s research group ,\n    co-led by PhD candidate Muhammad Huzaifa, at the University of Illinois at Urbana-Champaign.\nOther major contributors include\n    Rishi Desai,\n    Samuel Grayson,\n    Xutao Jiang,\n    Ying Jing,\n    Jae Lee,\n    Fang Lu,\n    Yihan Pang,\n    Joseph Ravichandran,\n    Giordano Salvador,\n    Finn Sinclair,\n    Boyuan Tian,\n    Henghzhi Yuan,\n    and\n    Jeffrey Zhang.  ILLIXR came together after many consultations with researchers and practitioners in many domains:\n    audio,\n    graphics,\n    optics,\n    robotics,\n    signal processing,\n    and\n    extended reality systems.\nWe are deeply grateful for all of these discussions and specifically to the following:\n    Wei Cu,\n    Aleksandra Faust,\n    Liang Gao,\n    Matt Horsnell,\n    Amit Jindal,\n    Steve LaValle,\n    Steve Lovegrove,\n    Andrew Maimone,\n    Vegard \u00d8ye,\n    Martin Persson,\n    Archontis Politis,\n    Eric Shaffer,\n    Paris Smaragdis,\n    Sachin Talathi,\n    and\n    Chris Widdowson.  Our OpenXR implementation is derived from  Monado .\nWe are particularly thankful to Jakob Bornecrantz and Ryan Pavlik.  The development of ILLIXR was supported by\n    the Applications Driving Architectures (ADA) Research Center\n        (a JUMP Center co-sponsored by SRC and DARPA),\n    the Center for Future Architectures Research (C-FAR, a STARnet research center),\n    a Semiconductor Research Corporation program sponsored by MARCO and DARPA,\n    and\n    by a Google Faculty Research Award.\nThe development of ILLIXR was also aided by generous hardware and software donations\n    from ARM and NVIDIA.\nFacebook Reality Labs provided the  OpenEDS Semantic Segmentation Dataset .  Wesley Darvin came up with the name for ILLIXR.",
            "title": "Acknowledgements"
        },
        {
            "location": "/#licensing-structure",
            "text": "ILLIXR is available as open-source software under the permissive\n     University of Illinois/NCSA Open Source License .\nAs mentioned above, ILLIXR largely consists of components developed by domain experts and\n    modified for the purposes of inclusion in ILLIXR.\nHowever, ILLIXR does contain software developed solely by us. The NCSA license is limited to only this software .\nThe external libraries and softwares included in ILLIXR each have their own licenses and\n    must be used according to those licenses:    ElasticFusion  \\  ElasticFusion license    KinectFusion  \\  MIT License    GTSAM  \\  Simplified BSD License    HOTlab  \\  GNU Lesser General Public License v3.0    Kimera-VIO  \\  Simplified BSD License    libspatialaudio  \\  GNU Lesser General Public License v2.1    Monado  \\  Boost Software License 1.0    moodycamel::ConcurrentQueue  \\  Simplified BSD License    Open-VINS  \\  GNU General Public License v3.0    RITnet  \\  MIT License    Note that ILLIXR's extensibility allows the source to be configured and compiled using only\n    permissively licensed software.",
            "title": "Licensing Structure"
        },
        {
            "location": "/#get-in-touch",
            "text": "Whether you are a computer architect, a compiler writer, a systems person, work on XR related algorithms\n    or applications, or just anyone interested in XR research, development, or products,\n    we would love to hear from you and hope you will contribute!\nYou can join\n    the  ILLIXR consortium ,\n     Discord ,\n    or  mailing list ,\n    or send us an  email ,\n    or just send us a pull request!",
            "title": "Get in Touch"
        },
        {
            "location": "/CONTRIBUTING/",
            "text": "Contributing Guidelines\n\n\nPlease follow these steps when making pull requests (PRs):\n\n\n\n\n\n\nFirst, create an issue describing the problem that needs to be fixed.\n    If an issue already exists, skip this step.\n    If you are looking for an issue to fix, see the \n\"good first issue\" label\n.\n\n\n\n\n\n\nAssign the issue to yourself and add appropriate labels.\n    If you are an external contributor, comment on the issue so one of the ILLIXR team members\n        can assign the issue to you.\n\n\n\n\n\n\nBefore you start making changes, make a new branch.\n    The branch \nMUST\n be named \nissue-<issue number>-<some descriptive name>\n.\n    For instance, \nissue-32-fix-mem-leak\n addresses the memory leak described in Issue #32.\n\n\n\n\n\n\nFix the issue.\n\n\n\n\n\n\nAdd your name to \nILLIXR/CONTRIBUTORS\n.\n\n\n\n\n\n\nPush commits up to GitHub.\n\n\n\n\n\n\nOpen a PR, and link it to the issue that the PR aims to resolve.\n    Please give the PR a descriptive name.\n\n\n\n\n\n\nAs you make progress on your PR, keep your branch up-to-date with the \nmaster\n branch which\n        may have been updated \nafter\n starting your PR.\n    Your PR \nMUST\n be updated to reflect changes to \nmaster\n in order to be merged.\n    Use the following procedure for updating your branch and when you are ready to commit your changes:\n\n\n\n\n\n## While on your PR branch <issue-branch> hosted at <your-remote> repository:\ngit commit # or git stash                                               ## Line A\ngit checkout master\n\ngit pull <illixr-remote> master --rebase && git fetch <illixr-remote>   ## Line B\n\ngit checkout <issue-branch>\ngit rebase master                                                       ## Line C\n\n## If you stashed your changes on 'Line A':\ngit stash apply <stash-number> && git commit\n\ngit push <your-remote> <issue-branch> --force-with-lease                ## Line D\n\n\n\nFor ILLIXR team members (others jump \nhere\n):\n\n\n\n\n\n\nIn the example above, \n<illixr-remote>\n and \n<your-remote>\n are the same.\n\n\n\n\n\n\nWhen collaborating on branches in our repository, \nLine B\n may pull in changes that overwrite\n        the git commit history when performing \nLine C\n.\n    Subsequently, performing \nLine D\n will rewrite the history in the public branch.\n    To preserve branch commit histories in the case that a rollback is needed, we will employ\n        a checkpointing process for force updated branches.\n    This process will be manually performed, but may be automated in the future.\n\n\nIf \nLine B\n shows an update to master, the following example illustrates your local repository\n    just after performing \nLine B\n:\n\n\n\n\n\nA -- B -- C -- P -- Q -- R                                          ## master\n           \\\n            D -- E -- F                                             ## issue-123-fixing-bug\n\n\n\nIn this example, commits \nP\n, \nQ\n, and \nR\n have been merged to \nmaster\n\n    (from feature branches not shown) after feature branch \nissue-123-fixing-bug\n was\n    forked from \nmaster\n.\n\n\nTo checkpoint the \nissue-123-fixing-bug\n branch while it is checked out:\n\n\n\n\n\ngit branch issue-123.0-fixing-bug                                   ## Make alias for old issue-123-fixing-bug\ngit checkout -b issue-123.1-fixing-bug                              ## Make new branch to rebase with master\ngit rebase master                                                   ## Replay issue-123-fixing-bug onto master\ngit branch -D issue-123-fixing-bug                                  ## Remove old issue-123-fixing-bug\ngit branch issue-123-fixing-bug                                     ## Make issue-123-fixing-bug an alias of new branch\ngit push <illixr-remote> issue-123.{0,1}-fixing-bug                 ## Push new checkpointed branches to remote\ngit push <illixr-remote> issue-123-fixing-bug --force-with-lease    ## Force update issue-123-fixing-bug\n\n\n\n\n\nNote:\nThe term \nalias\n here is used to refer to branches which point to the same commit.\nThis usage is different from standard \nGit Aliases\n used for git command shortcuts.\n\n\n\n\nAfter checkpointing, your local repository should look as follows:\n\n\n\n\n\n                           D' -- E' -- F'                           ## issue-123.1-fixing-bug, issue-123-fixing-bug\n                          /\nA -- B -- C -- P -- Q -- R                                          ## master\n           \\\n            D -- E -- F                                             ## issue-123.0-fixing-bug\n\n\n\nCommits \nD\n, \nE\n, and \nF\n have been added to a new branch starting from \nR\n,\n    but now have been given new hashes.\nThis new branch is our up-to-date copy of the feature branch \nissue-123-fixing-bug\n.\n\n\nWhile working on a checkpointed branch, keep aliases up-to-date using \ngit rebase\n:\n\n\n\n\n\ngit commit                                                          ## Add changes to issue-123.1-fixing-bug\ngit checkout issue-123-fixing-bug                                   ## Switch to main issue-123-fixing-bug branch\ngit rebase issue-123.1-fixing-bug                                   ## Fast-forward issue-123-fixing-bug to issue-123.1-fixing-bug\n\n\n\nConflicts are possible when two or more collaborators push changes concurrently to\n    the same branch.\nAs long as each collaborator ensures that the branch update process starts at \nLine A\n,\n    conflicts can be detected and handled locally.\nIn other words, \nevery\n call to \ngit-push\n should be preceeded by a call to \ngit-pull\n,\n    following the process from \nLine A\n to \nLine D\n (or equivalent; git's CLI allows many\n    ways to achieve the same results).\n\n\n\n\nNote:\n\nLine B\n rebases the \nmaster\n branch assuming that we have checked out \nmaster\n.\nForgetting to specify \nmaster\n in \nLine B\n may result in a \nlossy\n forced update in the\n    example below.\nForgetting to checkout \nmaster\n will immediately apply your checked out feature branch's\n    changes, possibly also resulting in a \nlossy\n forced update.\n\n\n\n\nThe output of \nLine B\n for a collaborator after the checkpointing process may contain\n    something like this:\n\n\n\n\n\nFrom github.com:ILLIXR/ILLIXR\n  A..R          master                  -> <illixr-remote>/master\n+ A..F'         issue-123-fixing-bug    -> <illixr-remote>/issue-123-fixing-bug  (forced update)\n* [new branch]  issue-123.0-fixing-bug  -> <illixr-remote>/issue-123.0-fixing-bug\n* [new branch]  issue-123.1-fixing-bug  -> <illixr-remote>/issue-123.1-fixing-bug\n\n\n\nConflicts which do not involve updates to the \nmaster\n branch can be resolved simply\n    by rebasing the current feature branch with the updated feature branch,\n    applying new changes on top of the updated feature branch:\n\n\n\n\n\n## For the latest checkpoint X (local) and Y (remote), let Z := Y + 1 in\ngit checkout issue-123.X-fixing-bug -b issue-123.Z-fixing-bug       ## Make new branch issue-123.Z-fixing-bug\ngit rebase <illixr-remote>/issue-123.Y-fixing-bug                   ## Replay updates from issue-123.X-fixing-bug\ngit push <illixr-remote> issue-123.Z-fixing-bug                     ## Make sure to update issue-123-fixing-bug after\n\n\n\nThe \n--force-with-lease\n argument in \nLine D\n is \nnot\n required for our new checkpoint branch,\n    since a new branch should not conflict with a non-existing remote branch.\nWe \nexpect\n the subversion number for a new branch resulting from our\n    checkpoint conflict resolution to be new and unique.\nIf the push fails, another conflict has occurred, and checkpoint conflict resolution\n    should be repeated.\n\nLine D\n should be safe to perform for the main feature branch now that we have\n    replayed our commits on top of the updated feature branch.\n\n\n\n\nNote:\nIn the above example, the \ngit-rebase\n is performed using the remote copy of\n    the checkpointed branch.\nWe do this because \nLine B\n will not fast-forward or force update our local branches\n    (with the same subversion number as a conflicting remote branch, if any).\n\n\n\n\nIn the case of a conflict with updates to \nmaster\n, \nLine A\n should show updates to\n    both the \nmaster\n branch \nand\n the feature branch to be pushed in \nLine D\n.\nA checkpointed version of the feature branch may also appear.\nThis is because a feature branch should only be checkpointed in the presence of a\n    change to the \nmaster\n branch.\nForced pushes should generally \nnot\n be used for any other purpose.\nIf multiple updates to \nmaster\n and the feature branch have occured, additional\n    checkpointed versions of the feature branch may also appear.\nIn this scenario, we need to rebase our latest version of the feature branch with\n    the latest version of the feature branch pulled from \n<illixr-remote>\n.\n\n\n\n\n\n\n\n\n\n\nPhilosophy\n\n\nWhy are the above steps necessary?\n\n\n\n\n\n\nAssigning the issue to yourself ensures that multiple people don't work on the same thing\n        in parallel.\n\n\n\n\n\n\nThe branch naming scheme organizes things a bit for us, and also makes it easy to find branches.\n\n\n\n\n\n\nLinking the issue to the PR ensures that we know which issue is being resolved,\n        and also automatically closes the issue when the PR gets merged.\n\n\n\n\n\n\nUsing rebases keeps the \nmaster\n and feature branch histories streamlined (minimizing branching),\n        thus making it easier to compose feature branches for integration testing.\n    See this article on \nrebasing public branches\n for more information.\n\n\n\n\n\n\nIf your PR has not seen activity from the ILLIXR team after a long period of time (e.g., 2 weeks),\n    feel free to contact the team directly on the GitHub Issue Conversation tab or at\n    the Gitter forum linked below.\n\n\nOther Procedures\n\n\n\n\n\n\nBranch Management:\n\n\nThe branch rebasing and checkpointing process detailed above is tedious, and may be automated in\n    the future.\nCheck back in with this document occasionally for improvements to the branch management process.\n\n\n\n\n\n\nCode Formatting:\n\n\nAs ILLIXR grows, contributions will need to be standardized to accomodate multiple collaborators\n    with different coding styles.\nDuring code review of a PR, you may be asked to reformat your code to match the standards set for\n    ILLIXR code base.\nThis process may be manually triggered by a comment from a review, or automated via Git and GitHub\n    in the future.\n\n\n\n\n\n\nIssue Templates:\n\n\nTo make collaboration easier, templates for Issues and Pull Requests will be added to\n    the GitHub web interface.\nIf an appropriate template exists for your task, please ensure to select it before submitting.\n\n\n\n\n\n\nGetting Help\n\n\nYou can get seek help from our development community in three places:\n\n\n\n\n\n\nMain documentation site\n\n\n\n\n\n\nAPI documentation site\n\n\n\n\n\n\nGitter community forum",
            "title": "CONTRIBUTING"
        },
        {
            "location": "/CONTRIBUTING/#contributing-guidelines",
            "text": "Please follow these steps when making pull requests (PRs):    First, create an issue describing the problem that needs to be fixed.\n    If an issue already exists, skip this step.\n    If you are looking for an issue to fix, see the  \"good first issue\" label .    Assign the issue to yourself and add appropriate labels.\n    If you are an external contributor, comment on the issue so one of the ILLIXR team members\n        can assign the issue to you.    Before you start making changes, make a new branch.\n    The branch  MUST  be named  issue-<issue number>-<some descriptive name> .\n    For instance,  issue-32-fix-mem-leak  addresses the memory leak described in Issue #32.    Fix the issue.    Add your name to  ILLIXR/CONTRIBUTORS .    Push commits up to GitHub.    Open a PR, and link it to the issue that the PR aims to resolve.\n    Please give the PR a descriptive name.    As you make progress on your PR, keep your branch up-to-date with the  master  branch which\n        may have been updated  after  starting your PR.\n    Your PR  MUST  be updated to reflect changes to  master  in order to be merged.\n    Use the following procedure for updating your branch and when you are ready to commit your changes:   ## While on your PR branch <issue-branch> hosted at <your-remote> repository:\ngit commit # or git stash                                               ## Line A\ngit checkout master\n\ngit pull <illixr-remote> master --rebase && git fetch <illixr-remote>   ## Line B\n\ngit checkout <issue-branch>\ngit rebase master                                                       ## Line C\n\n## If you stashed your changes on 'Line A':\ngit stash apply <stash-number> && git commit\n\ngit push <your-remote> <issue-branch> --force-with-lease                ## Line D  For ILLIXR team members (others jump  here ):    In the example above,  <illixr-remote>  and  <your-remote>  are the same.    When collaborating on branches in our repository,  Line B  may pull in changes that overwrite\n        the git commit history when performing  Line C .\n    Subsequently, performing  Line D  will rewrite the history in the public branch.\n    To preserve branch commit histories in the case that a rollback is needed, we will employ\n        a checkpointing process for force updated branches.\n    This process will be manually performed, but may be automated in the future.  If  Line B  shows an update to master, the following example illustrates your local repository\n    just after performing  Line B :   A -- B -- C -- P -- Q -- R                                          ## master\n           \\\n            D -- E -- F                                             ## issue-123-fixing-bug  In this example, commits  P ,  Q , and  R  have been merged to  master \n    (from feature branches not shown) after feature branch  issue-123-fixing-bug  was\n    forked from  master .  To checkpoint the  issue-123-fixing-bug  branch while it is checked out:   git branch issue-123.0-fixing-bug                                   ## Make alias for old issue-123-fixing-bug\ngit checkout -b issue-123.1-fixing-bug                              ## Make new branch to rebase with master\ngit rebase master                                                   ## Replay issue-123-fixing-bug onto master\ngit branch -D issue-123-fixing-bug                                  ## Remove old issue-123-fixing-bug\ngit branch issue-123-fixing-bug                                     ## Make issue-123-fixing-bug an alias of new branch\ngit push <illixr-remote> issue-123.{0,1}-fixing-bug                 ## Push new checkpointed branches to remote\ngit push <illixr-remote> issue-123-fixing-bug --force-with-lease    ## Force update issue-123-fixing-bug   Note:\nThe term  alias  here is used to refer to branches which point to the same commit.\nThis usage is different from standard  Git Aliases  used for git command shortcuts.   After checkpointing, your local repository should look as follows:                              D' -- E' -- F'                           ## issue-123.1-fixing-bug, issue-123-fixing-bug\n                          /\nA -- B -- C -- P -- Q -- R                                          ## master\n           \\\n            D -- E -- F                                             ## issue-123.0-fixing-bug  Commits  D ,  E , and  F  have been added to a new branch starting from  R ,\n    but now have been given new hashes.\nThis new branch is our up-to-date copy of the feature branch  issue-123-fixing-bug .  While working on a checkpointed branch, keep aliases up-to-date using  git rebase :   git commit                                                          ## Add changes to issue-123.1-fixing-bug\ngit checkout issue-123-fixing-bug                                   ## Switch to main issue-123-fixing-bug branch\ngit rebase issue-123.1-fixing-bug                                   ## Fast-forward issue-123-fixing-bug to issue-123.1-fixing-bug  Conflicts are possible when two or more collaborators push changes concurrently to\n    the same branch.\nAs long as each collaborator ensures that the branch update process starts at  Line A ,\n    conflicts can be detected and handled locally.\nIn other words,  every  call to  git-push  should be preceeded by a call to  git-pull ,\n    following the process from  Line A  to  Line D  (or equivalent; git's CLI allows many\n    ways to achieve the same results).   Note: Line B  rebases the  master  branch assuming that we have checked out  master .\nForgetting to specify  master  in  Line B  may result in a  lossy  forced update in the\n    example below.\nForgetting to checkout  master  will immediately apply your checked out feature branch's\n    changes, possibly also resulting in a  lossy  forced update.   The output of  Line B  for a collaborator after the checkpointing process may contain\n    something like this:   From github.com:ILLIXR/ILLIXR\n  A..R          master                  -> <illixr-remote>/master\n+ A..F'         issue-123-fixing-bug    -> <illixr-remote>/issue-123-fixing-bug  (forced update)\n* [new branch]  issue-123.0-fixing-bug  -> <illixr-remote>/issue-123.0-fixing-bug\n* [new branch]  issue-123.1-fixing-bug  -> <illixr-remote>/issue-123.1-fixing-bug  Conflicts which do not involve updates to the  master  branch can be resolved simply\n    by rebasing the current feature branch with the updated feature branch,\n    applying new changes on top of the updated feature branch:   ## For the latest checkpoint X (local) and Y (remote), let Z := Y + 1 in\ngit checkout issue-123.X-fixing-bug -b issue-123.Z-fixing-bug       ## Make new branch issue-123.Z-fixing-bug\ngit rebase <illixr-remote>/issue-123.Y-fixing-bug                   ## Replay updates from issue-123.X-fixing-bug\ngit push <illixr-remote> issue-123.Z-fixing-bug                     ## Make sure to update issue-123-fixing-bug after  The  --force-with-lease  argument in  Line D  is  not  required for our new checkpoint branch,\n    since a new branch should not conflict with a non-existing remote branch.\nWe  expect  the subversion number for a new branch resulting from our\n    checkpoint conflict resolution to be new and unique.\nIf the push fails, another conflict has occurred, and checkpoint conflict resolution\n    should be repeated. Line D  should be safe to perform for the main feature branch now that we have\n    replayed our commits on top of the updated feature branch.   Note:\nIn the above example, the  git-rebase  is performed using the remote copy of\n    the checkpointed branch.\nWe do this because  Line B  will not fast-forward or force update our local branches\n    (with the same subversion number as a conflicting remote branch, if any).   In the case of a conflict with updates to  master ,  Line A  should show updates to\n    both the  master  branch  and  the feature branch to be pushed in  Line D .\nA checkpointed version of the feature branch may also appear.\nThis is because a feature branch should only be checkpointed in the presence of a\n    change to the  master  branch.\nForced pushes should generally  not  be used for any other purpose.\nIf multiple updates to  master  and the feature branch have occured, additional\n    checkpointed versions of the feature branch may also appear.\nIn this scenario, we need to rebase our latest version of the feature branch with\n    the latest version of the feature branch pulled from  <illixr-remote> .",
            "title": "Contributing Guidelines"
        },
        {
            "location": "/CONTRIBUTING/#philosophy",
            "text": "Why are the above steps necessary?    Assigning the issue to yourself ensures that multiple people don't work on the same thing\n        in parallel.    The branch naming scheme organizes things a bit for us, and also makes it easy to find branches.    Linking the issue to the PR ensures that we know which issue is being resolved,\n        and also automatically closes the issue when the PR gets merged.    Using rebases keeps the  master  and feature branch histories streamlined (minimizing branching),\n        thus making it easier to compose feature branches for integration testing.\n    See this article on  rebasing public branches  for more information.    If your PR has not seen activity from the ILLIXR team after a long period of time (e.g., 2 weeks),\n    feel free to contact the team directly on the GitHub Issue Conversation tab or at\n    the Gitter forum linked below.",
            "title": "Philosophy"
        },
        {
            "location": "/CONTRIBUTING/#other-procedures",
            "text": "Branch Management:  The branch rebasing and checkpointing process detailed above is tedious, and may be automated in\n    the future.\nCheck back in with this document occasionally for improvements to the branch management process.    Code Formatting:  As ILLIXR grows, contributions will need to be standardized to accomodate multiple collaborators\n    with different coding styles.\nDuring code review of a PR, you may be asked to reformat your code to match the standards set for\n    ILLIXR code base.\nThis process may be manually triggered by a comment from a review, or automated via Git and GitHub\n    in the future.    Issue Templates:  To make collaboration easier, templates for Issues and Pull Requests will be added to\n    the GitHub web interface.\nIf an appropriate template exists for your task, please ensure to select it before submitting.",
            "title": "Other Procedures"
        },
        {
            "location": "/CONTRIBUTING/#getting-help",
            "text": "You can get seek help from our development community in three places:    Main documentation site    API documentation site    Gitter community forum",
            "title": "Getting Help"
        },
        {
            "location": "/LICENSE/",
            "text": "Copyright (c) 2019 The Board of Trustees of the University of Illinois.  All rights reserved.\n\n\nDeveloped by: Professor Sarita Adve's research group\n              University of Illinois at Urbana-Champaign\n              http://rsim.cs.illinois.edu\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal with\nthe Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to\ndo so, subject to the following conditions:\n\n Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimers.\n\n Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimers in the documentation\n  and/or other materials provided with the distribution.\n* Neither the names of Professor Sarita Adve's research group, University of\n  Illinois at Urbana-Champaign, nor the names of its contributors may be used\n  to endorse or promote products derived from this Software without specific\n  prior written permission.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\nCONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE\nSOFTWARE.",
            "title": "LICENSE"
        },
        {
            "location": "/building_illixr/",
            "text": "Building ILLIXR\n\n\nThe ILLIXR application is kick-started through a tool called \nRunner\n\n    (found in \nrunner/\n and \nrunner.sh\n).\nThe Runner tool is responsible for\n    preparing the environment,\n    downloading required assets/code,\n    compiling each plugin,\n    and\n    launching the ILLIXR application.\nRunner is necessary for our project since ILLIXR manages plugins and data that span\n    many locations and launch \nconfigurations\n.\nA configuration (defined via a \nYAML\n file in \nILLIXR/configs/\n) specifies parameters\n    and plugins required to launch ILLIXR for a specific design/evaluation scenario.\n\n\nCompilation and Usage\n\n\nTo run ILLIXR (from the root directory of the project) using\n    the default \nnative\n launch configuration,\n\n\n\n\n\n./runner.sh configs/native.yaml\n\n\n\nTo drop into \ngdb\n, add \ncommand: gdb -q --args $cmd\n in the \naction\n block of\n    \nconfigs/native.yaml\n, and use the same command.\n\n\nTo run ILLIXR with Monado,\n\n\n\n\n\n./runner.sh configs/monado.yaml\n\n\n\nThe \nOpenXR\n application to run is defined in the \naction.openxr_app\n\n    (a \nYAML\n object).\n\n\nConfiguration\n\n\nAs introduced in the \nintroduction to the ILLIXR build process\n, a \nConfiguration\n\n    (or \nconfig\n) describes the key information needed to launch an ILLIXR application.\nThis section provides a detailed breakdown of the structure of a configuration file.\nThe default \nILLIXR/configs/native.yaml\n for the \nnative\n action will be used as\n    the running example.\n\n\nThe first block in the config file contains a list of \nplugin_groups\n,\n    where each \nplugin_group\n is a list of plugins.\n\n\n\n\n\nplugin_groups:\n  - plugin_group:\n      - path: plugin1/\n      - path: plugin2/\n      - path: plugin3/\n      - path: plugin4/\n\n\n\nThis defines a list of plugins by their location, \npath\n.\nAllowed paths will be described below.\nThe \nplugin_groups\n get flattened and those plugins are initialized \nin order\n at runtime.\nSeveral of the default plugins are order-sensitive.\n\n\nThe next block in the config defines the offline IMU data, camera data, and ground-truth data.\n\n\n\n\n\ndata:\n  subpath: mav0\n  relative_to:\n    archive_path:\n      download_url: 'http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_medium/V1_02_medium.zip'\n\n\n\nNext, we define the location of OBJ files for \ngldemo\n.\n\n\n\n\n\ndemo_data: demo_data/\n\n\n\nThen, we define the \nAction\n to be taken for the configuration.\nEach action has a name, and can contain a number of member fields beyond this.\n\n\n\n\n\naction:\n  name: native\n  command: gdb -q --args $cmd\n\n\n\nThe \nnative\n action supports an optional \ncommand\n argument.\nIn that argument \n$cmd\n is replaced with the separated command-line arguments to run ILLIXR,\n    while \n$quoted_cmd\n is replaced with a single string comprising all command-line arguments.\nThe \ncommand\n argument also supports \n$env_cmd\n, which interpret command-line argument\n    assignments in the form of \nVARNAME=VALUE\n as environment variable mappings.\nSee the \nconfiguration\n glossary entry\n for more details about supported actions.\n\n\nFinally, we support two compilation \nprofiles\n:\n    \nopt\n, which compiles with \n-O3\n and disables debug prints and assertions,\n    and\n    \ndbg\n, which compiles with debug flags and enables debug prints and assertions.\n\n\n\n\n\nprofile: opt\n\n\n\nYou can \n!include\n other configuration files via \npyyaml-include\n.\nConsider separating the site-specific configuration options into its own file.\n\n\nSpecifying Paths\n\n\nA path refers to a location of a resource. There are 5 ways of specifying a path:\n\n\n\n\n\n\nSimple path\n:\n    Either absolute or relative path in the native filesystem.\n\n\n\n\n\n\nGit repo\n:\n    A git repository.\n\n\n\n\n\n- git_repo: https://github.com/user/repo.git\n  version: master # branch name, SHA-256, or tag\n\n\n\n\n\n\n\nDownload URL\n:\n    A resource downloaded from the internet.\n\n\n\n\n\n- download_url: https://example.com/file.txt\n\n\n\n\n\n\n\nZip archive\n:\n    A path that points within the contents of a zip archive.\n    Note that \narchive_path\n is itself a path (recursive).\n\n\n\n\n\n- archive_path: path/to/archive.zip\n- archive_path:\n    download_url: https://example.com/file.zip\n\n\n\n\n\n\n\nComplex path\n:\n    A hard-coded path relative to another path (recursive).\n    This is useful to specify a \nsubdirectory\n of a git repository or zip archive.\n\n\n\n\n\n- subpath: path/within/git_repo\n  relative_to:\n    git_repo: ...\n    version: ...\n\n\n\n\n\n\n\nRationale\n\n\n\n\n\n\nPreviously, we would have to specify which plugins to build and which to run separately,\n        violating \nDRY principle\n.\n\n\n\n\n\n\nPreviously, configuration had to be hard-coded into the component source code,\n        or passed as parsed/unparsed as strings in env-vars on a per-component basis.\n    This gives us a consistent way to deal with all configurations.\n\n\n\n\n\n\nCurrently, plugins are specified by a path to the directory containing their source code\n        and build system.\n\n\n\n\n\n\nPhilosophy\n\n\n\n\n\n\nEach plugin should not have to know or care how the others are compiled.\n    In the future, they may even be distributed separately, just as SOs.\n    Therefore, each plugin needs its own build system.\n\n\n\n\n\n\nDespite this per-plugin flexibility, building the 'default' set of ILLIXR plugins\n        should be extremely easy.\n\n\n\n\n\n\nIt should be easy to build in parallel.\n\n\n\n\n\n\nAlways rebuild every time, so the binary is always \"fresh.\"\n    This is a great convenience when experimenting.\n    However, this implies that rebuilding must be fast when not much has changed.\n\n\n\n\n\n\nMake is the de facto standard for building C/C++ programs.\n    GNU Make, and the makefile language begets no shortage of problems\n        [\n1\n,\n2\n,\n3\n,\n4\n,\n5\n], but we choose\n    Make for its tradeoff of between simplicity and functionality.\n    What it lacks in functionality (compared to CMake, Ninja, scons, Bazel, Meson)\n        it makes up for in simplicity.\n    It's still the build system in which it is the easiest to invoke arbitrary commands in\n        shell and the easiest to have a \ncommon.mk\n included in each plugin.\n    This decision to use Make should be revisited, when this project outgrows its ability,\n        but for now, Make remains, in our judgement, \nthe best tool for the job\n.",
            "title": "Building illixr"
        },
        {
            "location": "/building_illixr/#building-illixr",
            "text": "The ILLIXR application is kick-started through a tool called  Runner \n    (found in  runner/  and  runner.sh ).\nThe Runner tool is responsible for\n    preparing the environment,\n    downloading required assets/code,\n    compiling each plugin,\n    and\n    launching the ILLIXR application.\nRunner is necessary for our project since ILLIXR manages plugins and data that span\n    many locations and launch  configurations .\nA configuration (defined via a  YAML  file in  ILLIXR/configs/ ) specifies parameters\n    and plugins required to launch ILLIXR for a specific design/evaluation scenario.",
            "title": "Building ILLIXR"
        },
        {
            "location": "/building_illixr/#compilation-and-usage",
            "text": "To run ILLIXR (from the root directory of the project) using\n    the default  native  launch configuration,   ./runner.sh configs/native.yaml  To drop into  gdb , add  command: gdb -q --args $cmd  in the  action  block of\n     configs/native.yaml , and use the same command.  To run ILLIXR with Monado,   ./runner.sh configs/monado.yaml  The  OpenXR  application to run is defined in the  action.openxr_app \n    (a  YAML  object).",
            "title": "Compilation and Usage"
        },
        {
            "location": "/building_illixr/#configuration",
            "text": "As introduced in the  introduction to the ILLIXR build process , a  Configuration \n    (or  config ) describes the key information needed to launch an ILLIXR application.\nThis section provides a detailed breakdown of the structure of a configuration file.\nThe default  ILLIXR/configs/native.yaml  for the  native  action will be used as\n    the running example.  The first block in the config file contains a list of  plugin_groups ,\n    where each  plugin_group  is a list of plugins.   plugin_groups:\n  - plugin_group:\n      - path: plugin1/\n      - path: plugin2/\n      - path: plugin3/\n      - path: plugin4/  This defines a list of plugins by their location,  path .\nAllowed paths will be described below.\nThe  plugin_groups  get flattened and those plugins are initialized  in order  at runtime.\nSeveral of the default plugins are order-sensitive.  The next block in the config defines the offline IMU data, camera data, and ground-truth data.   data:\n  subpath: mav0\n  relative_to:\n    archive_path:\n      download_url: 'http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_medium/V1_02_medium.zip'  Next, we define the location of OBJ files for  gldemo .   demo_data: demo_data/  Then, we define the  Action  to be taken for the configuration.\nEach action has a name, and can contain a number of member fields beyond this.   action:\n  name: native\n  command: gdb -q --args $cmd  The  native  action supports an optional  command  argument.\nIn that argument  $cmd  is replaced with the separated command-line arguments to run ILLIXR,\n    while  $quoted_cmd  is replaced with a single string comprising all command-line arguments.\nThe  command  argument also supports  $env_cmd , which interpret command-line argument\n    assignments in the form of  VARNAME=VALUE  as environment variable mappings.\nSee the  configuration  glossary entry  for more details about supported actions.  Finally, we support two compilation  profiles :\n     opt , which compiles with  -O3  and disables debug prints and assertions,\n    and\n     dbg , which compiles with debug flags and enables debug prints and assertions.   profile: opt  You can  !include  other configuration files via  pyyaml-include .\nConsider separating the site-specific configuration options into its own file.",
            "title": "Configuration"
        },
        {
            "location": "/building_illixr/#specifying-paths",
            "text": "A path refers to a location of a resource. There are 5 ways of specifying a path:    Simple path :\n    Either absolute or relative path in the native filesystem.    Git repo :\n    A git repository.   - git_repo: https://github.com/user/repo.git\n  version: master # branch name, SHA-256, or tag    Download URL :\n    A resource downloaded from the internet.   - download_url: https://example.com/file.txt    Zip archive :\n    A path that points within the contents of a zip archive.\n    Note that  archive_path  is itself a path (recursive).   - archive_path: path/to/archive.zip\n- archive_path:\n    download_url: https://example.com/file.zip    Complex path :\n    A hard-coded path relative to another path (recursive).\n    This is useful to specify a  subdirectory  of a git repository or zip archive.   - subpath: path/within/git_repo\n  relative_to:\n    git_repo: ...\n    version: ...",
            "title": "Specifying Paths"
        },
        {
            "location": "/building_illixr/#rationale",
            "text": "Previously, we would have to specify which plugins to build and which to run separately,\n        violating  DRY principle .    Previously, configuration had to be hard-coded into the component source code,\n        or passed as parsed/unparsed as strings in env-vars on a per-component basis.\n    This gives us a consistent way to deal with all configurations.    Currently, plugins are specified by a path to the directory containing their source code\n        and build system.",
            "title": "Rationale"
        },
        {
            "location": "/building_illixr/#philosophy",
            "text": "Each plugin should not have to know or care how the others are compiled.\n    In the future, they may even be distributed separately, just as SOs.\n    Therefore, each plugin needs its own build system.    Despite this per-plugin flexibility, building the 'default' set of ILLIXR plugins\n        should be extremely easy.    It should be easy to build in parallel.    Always rebuild every time, so the binary is always \"fresh.\"\n    This is a great convenience when experimenting.\n    However, this implies that rebuilding must be fast when not much has changed.    Make is the de facto standard for building C/C++ programs.\n    GNU Make, and the makefile language begets no shortage of problems\n        [ 1 , 2 , 3 , 4 , 5 ], but we choose\n    Make for its tradeoff of between simplicity and functionality.\n    What it lacks in functionality (compared to CMake, Ninja, scons, Bazel, Meson)\n        it makes up for in simplicity.\n    It's still the build system in which it is the easiest to invoke arbitrary commands in\n        shell and the easiest to have a  common.mk  included in each plugin.\n    This decision to use Make should be revisited, when this project outgrows its ability,\n        but for now, Make remains, in our judgement,  the best tool for the job .",
            "title": "Philosophy"
        },
        {
            "location": "/debugging_illixr/",
            "text": "ILLIXR Debugging Tips\n\n\nDebugging Locally\n\n\nThe config described in \nBuilding ILLIXR\n supports running the runtime with\n    arbitrary commands like \ngdb\n.\nWhen debugging locally, we recommend using either \ngdb\n or \nvalgrind\n in this way.\n\n\nDebugging Pull Requests or with a Clean Environment\n\n\n1. Get a Docker Image\n\n\nFrom your Local Project\n\n\nFrom the root directory in your project, run:\n\n\n\n\n\ndocker build [--build-arg=JOBS=\"<integer>\"] [--no-cache] --tag <repository>:<tag> .\n\n\n\nNote the optional \nDockerfile\n argument, \nJOBS\n, which specifies the number of threads/tasks to use for building.\nAlso note the optional argument, \n--no-cache\n, which forces Docker to rerun commands in \nDockerfile\n\n    (see \nthis article\n for more information).\nFor this project's main module, you can use something like \nillixr-illixr\n for the \n<repository>\n value,\n    and your current branch name or release version as the \n<tag>\n value.\n\n\nNote that building the docker image can take some time (up to 40min on a 4-core desktop machine) and uses somewhere between 2-4GB of RAM.\n\n\nFrom a GitHub Pull Request's CI/CD Flow\n\n\nFollow these steps when a CI/CD build fails on a PR:\n\n\n\n\n\n\nClick \ndetails\n on the failing build.\n\n\n\n\n\n\nIn the build view go to the Push Docker Image tab and copy the \ndocker push ghcr.io/illixr/illixr-tests:<branch-name>\n command.\n\n\n\n\n\n\nThen in your terminal, run:\n\n\n\n\n\ndocker pull ghcr.io/illixr/illixr-tests:<branch-name>\n\n\n\n\n\n\n\n2. Test your Image in the Docker container\n\n\nVerify that your image was created successfully:\n\n\n\n\n\ndocker image ls\n\n\n\nTake note of your image's \nREPOSITORY\n and \nTAG\n values.\nNow run:\n\n\n\n\n\ndocker run -it --entrypoint /bin/bash <repository>:<tag>\n\n\n\nYou are now in a bash shell in a docker container.\n\n\nFrom here you can test whichever project flow you wish, such as the usual \n./runner.sh configs/native.yaml\n,\n    or the CI/CD testing flow (\n./runner.sh configs/ci.yaml\n).",
            "title": "Debugging illixr"
        },
        {
            "location": "/debugging_illixr/#illixr-debugging-tips",
            "text": "",
            "title": "ILLIXR Debugging Tips"
        },
        {
            "location": "/debugging_illixr/#debugging-locally",
            "text": "The config described in  Building ILLIXR  supports running the runtime with\n    arbitrary commands like  gdb .\nWhen debugging locally, we recommend using either  gdb  or  valgrind  in this way.",
            "title": "Debugging Locally"
        },
        {
            "location": "/debugging_illixr/#debugging-pull-requests-or-with-a-clean-environment",
            "text": "",
            "title": "Debugging Pull Requests or with a Clean Environment"
        },
        {
            "location": "/debugging_illixr/#1-get-a-docker-image",
            "text": "",
            "title": "1. Get a Docker Image"
        },
        {
            "location": "/debugging_illixr/#from-your-local-project",
            "text": "From the root directory in your project, run:   docker build [--build-arg=JOBS=\"<integer>\"] [--no-cache] --tag <repository>:<tag> .  Note the optional  Dockerfile  argument,  JOBS , which specifies the number of threads/tasks to use for building.\nAlso note the optional argument,  --no-cache , which forces Docker to rerun commands in  Dockerfile \n    (see  this article  for more information).\nFor this project's main module, you can use something like  illixr-illixr  for the  <repository>  value,\n    and your current branch name or release version as the  <tag>  value.  Note that building the docker image can take some time (up to 40min on a 4-core desktop machine) and uses somewhere between 2-4GB of RAM.",
            "title": "From your Local Project"
        },
        {
            "location": "/debugging_illixr/#from-a-github-pull-requests-cicd-flow",
            "text": "Follow these steps when a CI/CD build fails on a PR:    Click  details  on the failing build.    In the build view go to the Push Docker Image tab and copy the  docker push ghcr.io/illixr/illixr-tests:<branch-name>  command.    Then in your terminal, run:   docker pull ghcr.io/illixr/illixr-tests:<branch-name>",
            "title": "From a GitHub Pull Request's CI/CD Flow"
        },
        {
            "location": "/debugging_illixr/#2-test-your-image-in-the-docker-container",
            "text": "Verify that your image was created successfully:   docker image ls  Take note of your image's  REPOSITORY  and  TAG  values.\nNow run:   docker run -it --entrypoint /bin/bash <repository>:<tag>  You are now in a bash shell in a docker container.  From here you can test whichever project flow you wish, such as the usual  ./runner.sh configs/native.yaml ,\n    or the CI/CD testing flow ( ./runner.sh configs/ci.yaml ).",
            "title": "2. Test your Image in the Docker container"
        },
        {
            "location": "/external_switchboard_and_phonebook/",
            "text": "Using Switchboard and Phonebook Externally\n\n\nSwitchboard was designed as a self-contained entity from ILLIXR that one can reuse in other\nprojects. The relevant API is \nhere for Switchboard\n and \nhere for\nPhonebook\n.\n\n\nOne simply needs to copy these files, maintaining directory structure.\n\n\ncommon/switchboard.hpp\ncommon/phonebook.hpp\ncommon/record_logger.hpp\ncommon/managed_thread.hpp\ncommon/concurrentqueue/blockingconcurrentqueue.hpp\ncommon/concurrentqueue/concurrentqueue.hpp\ncommon/concurrentqueue/lightweightsemaphore.hpp\n\n\n\n\nThis will serve as our \nmain.cpp\n:\n\n\n#include <iostream>\n#include \"common/switchboard.hpp\"\n\nclass service : public ILLIXR::phonebook::service {\npublic:\n    void act() { std::cout << \"Hello from service\\n\"; };\n};\n\nclass data : public ILLIXR::switchboard::event {\npublic:\n    data(size_t id_) : id{id_} { }\n    size_t id;\n};\n\nint main() {\n    ILLIXR::phonebook main_pb;\n    main_pb.register_impl<service>(std::make_shared<service>());\n    main_pb.lookup_impl<service>()->act();\n\n    // From docs of Switchboard: if first arg is null, logging is disabled.\n    // Logging should be disabled if we are running externally.\n    ILLIXR::switchboard main_sb {nullptr};\n    auto writer = main_sb.get_writer<data>(\"topic\");\n    auto reader = main_sb.get_reader<data>(\"topic\");\n    writer.put(writer.allocate<data>(42));\n    std::cout << \"The answer to life... is \" << reader.get_ro()->id << std::endl;\n\n    return 0;\n}\n\n\n\n\nWe use Switchboard and Phonebook with \nclang\n 10 or greater, but you can probably make this work in\nGCC or other compilers as long as they support C++17.\n\n\nFor example:\n\n\n# Must copy with directory structure\nmkdir -p common/concurrentqueue\ncp path/to/ILLIXR/common/switchboard.hpp common\ncp path/to/ILLIXR/common/phonebook.hpp common\ncp path/to/ILLIXR/common/record_logger.hpp common\ncp path/to/ILLIXR/common/managed_thread.hpp common\ncp path/to/ILLIXR/common/concurrentqueue/blockingconcurrentqueue.hpp common/concurrentqueue/blockingconcurrentqueue.hpp\ncp path/to/ILLIXR/common/concurrentqueue/concurrentqueue.hpp common/concurrentqueue/concurrentqueue.hpp\ncp path/to/ILLIXR/common/concurrentqueue/lightweightsemaphore.hpp common/concurrentqueue/lightweightsemaphore.hpp\nemacs main.cpp # copy and paste from this doc\n\n# This will *probbaly* work with any C++-17 compatible compiler, but I've tested with clang-10.\n# Nix is my preferred package manager, but you can use whichever you like.\n# This command will not affect system packages, just create a temporary environment with the right clang.\nnix-shell -p clang_10\n\n# Compile\nclang++ -Wextra -pthread -std=c++17 main.cpp\n\n# Run\n./a.out\n\n\n\n\nThe output is:\n\n\nRegister 7service\nHello from service\nCreating: topic for 4data\nThe answer to life... is 42",
            "title": "External switchboard and phonebook"
        },
        {
            "location": "/external_switchboard_and_phonebook/#using-switchboard-and-phonebook-externally",
            "text": "Switchboard was designed as a self-contained entity from ILLIXR that one can reuse in other\nprojects. The relevant API is  here for Switchboard  and  here for\nPhonebook .  One simply needs to copy these files, maintaining directory structure.  common/switchboard.hpp\ncommon/phonebook.hpp\ncommon/record_logger.hpp\ncommon/managed_thread.hpp\ncommon/concurrentqueue/blockingconcurrentqueue.hpp\ncommon/concurrentqueue/concurrentqueue.hpp\ncommon/concurrentqueue/lightweightsemaphore.hpp  This will serve as our  main.cpp :  #include <iostream>\n#include \"common/switchboard.hpp\"\n\nclass service : public ILLIXR::phonebook::service {\npublic:\n    void act() { std::cout << \"Hello from service\\n\"; };\n};\n\nclass data : public ILLIXR::switchboard::event {\npublic:\n    data(size_t id_) : id{id_} { }\n    size_t id;\n};\n\nint main() {\n    ILLIXR::phonebook main_pb;\n    main_pb.register_impl<service>(std::make_shared<service>());\n    main_pb.lookup_impl<service>()->act();\n\n    // From docs of Switchboard: if first arg is null, logging is disabled.\n    // Logging should be disabled if we are running externally.\n    ILLIXR::switchboard main_sb {nullptr};\n    auto writer = main_sb.get_writer<data>(\"topic\");\n    auto reader = main_sb.get_reader<data>(\"topic\");\n    writer.put(writer.allocate<data>(42));\n    std::cout << \"The answer to life... is \" << reader.get_ro()->id << std::endl;\n\n    return 0;\n}  We use Switchboard and Phonebook with  clang  10 or greater, but you can probably make this work in\nGCC or other compilers as long as they support C++17.  For example:  # Must copy with directory structure\nmkdir -p common/concurrentqueue\ncp path/to/ILLIXR/common/switchboard.hpp common\ncp path/to/ILLIXR/common/phonebook.hpp common\ncp path/to/ILLIXR/common/record_logger.hpp common\ncp path/to/ILLIXR/common/managed_thread.hpp common\ncp path/to/ILLIXR/common/concurrentqueue/blockingconcurrentqueue.hpp common/concurrentqueue/blockingconcurrentqueue.hpp\ncp path/to/ILLIXR/common/concurrentqueue/concurrentqueue.hpp common/concurrentqueue/concurrentqueue.hpp\ncp path/to/ILLIXR/common/concurrentqueue/lightweightsemaphore.hpp common/concurrentqueue/lightweightsemaphore.hpp\nemacs main.cpp # copy and paste from this doc\n\n# This will *probbaly* work with any C++-17 compatible compiler, but I've tested with clang-10.\n# Nix is my preferred package manager, but you can use whichever you like.\n# This command will not affect system packages, just create a temporary environment with the right clang.\nnix-shell -p clang_10\n\n# Compile\nclang++ -Wextra -pthread -std=c++17 main.cpp\n\n# Run\n./a.out  The output is:  Register 7service\nHello from service\nCreating: topic for 4data\nThe answer to life... is 42",
            "title": "Using Switchboard and Phonebook Externally"
        },
        {
            "location": "/getting_started/",
            "text": "Getting Started\n\n\nThese instructions have been tested with Ubuntu 18.04 and 20.04.\n\n\nILLIXR Runtime without Monado\n\n\n\n\n\n\nClone the repository\n:\n\n\n\n\n\ngit clone https://github.com/ILLIXR/ILLIXR\n\n\n\nNote for ILLIXR versions older than \nv2.2.0\n:\n\n\nUpdate the submodules.\nSubmodules are git repositories inside a git repository that need to be pulled down separately:\n\n\n\n\n\ngit submodule update --init --recursive\n\n\n\n\n\n\n\nInstall dependencies\n:\n\n\n\n\n\n./install_deps.sh [--jobs <integer>]\n\n\n\nThis script installs some Ubuntu/Debian packages and builds several dependencies from source.\nWithout any arguments, the script will print the help message, and proceed using default values.\nTo change the number of threads/tasks to use for building, specify using the \n--jobs\n argument.\nOther available options can be inspected using the \n--help\n flag.\n\n\n\n\n\n\nInspect \nconfigs/native.yaml\n.\n\n\nThe schema definition is in \nrunner/config_schema.yaml\n.\nFor more details on the runner and the config files, see \nBuilding ILLIXR\n.\n\n\n\n\n\n\nBuild and run ILLIXR without Monado\n:\n\n\n\n\n\n./runner.sh configs/native.yaml\n\n\n\nIf you are running ILLIXR without a graphical environment,\n    try ILLIXR headlessly using \nXvfb\n:\n\n\n\n\n\n./runner.sh configs/headless.yaml\n\n\n\n\n\n\n\nTo clean up after building, run\n:\n\n\n\n\n\n./runner.sh configs/clean.yaml\n\n\n\nOr simply:\n\n\n\n\n\n./clean.sh\n\n\n\n\n\n\n\nILLIXR Runtime with Monado\n\n\nILLIXR leverages \nMonado\n, an open-source implementation of \nOpenXR\n,\n    to support a wide range of OpenXR client applications.\nBecause of a low-level driver issue, Monado only supports Ubuntu 18.04+.\n\n\n\n\n\n\nCompile and run:\n\n\n\n\n\n./runner.sh configs/monado.yaml\n\n\n\n\n\n\n\nILLIXR under Virtualization\n\n\nILLIXR can be run inside a \nQEMU-KVM\n image.\nCheck out the instructions \nhere\n.\n\n\nNext Steps\n\n\nTry browsing the source for the runtime and provided plugins.\nThe source code is divided into components in the following directories:\n\n\n\n\n\n\nILLIXR/runtime/\n:\n    A directory holding the implementation for loading and interfacing plugins.\n    This directory contains \nSpindle\n.\n\n\n\n\n\n\nILLIXR/common/\n:\n    A directory holding resources and utilities available globally to all plugins.\n    Most plugins symlink this directory into theirs.\n    This directory contains the interfaces for \nSwitchboard\n and \nPhonebook\n.\n\n\n\n\n\n\nILLIXR/<plugin_dir>/\n:\n    A unique directory for each plugin.\n    Most of the core XR functionality is implemented via plugins.\n    See \nDefault Components\n for more details.\n\n\n\n\n\n\nIf you edit any of the source files, the runner will detect and rebuild the respective binary\n    the next time it runs.\nIf you want to add your own plugin, see \nWriting Your Plugin\n.\n\n\nOtherwise, proceed to the next section, \nBuilding ILLIXR\n.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#getting-started",
            "text": "These instructions have been tested with Ubuntu 18.04 and 20.04.",
            "title": "Getting Started"
        },
        {
            "location": "/getting_started/#illixr-runtime-without-monado",
            "text": "Clone the repository :   git clone https://github.com/ILLIXR/ILLIXR  Note for ILLIXR versions older than  v2.2.0 :  Update the submodules.\nSubmodules are git repositories inside a git repository that need to be pulled down separately:   git submodule update --init --recursive    Install dependencies :   ./install_deps.sh [--jobs <integer>]  This script installs some Ubuntu/Debian packages and builds several dependencies from source.\nWithout any arguments, the script will print the help message, and proceed using default values.\nTo change the number of threads/tasks to use for building, specify using the  --jobs  argument.\nOther available options can be inspected using the  --help  flag.    Inspect  configs/native.yaml .  The schema definition is in  runner/config_schema.yaml .\nFor more details on the runner and the config files, see  Building ILLIXR .    Build and run ILLIXR without Monado :   ./runner.sh configs/native.yaml  If you are running ILLIXR without a graphical environment,\n    try ILLIXR headlessly using  Xvfb :   ./runner.sh configs/headless.yaml    To clean up after building, run :   ./runner.sh configs/clean.yaml  Or simply:   ./clean.sh",
            "title": "ILLIXR Runtime without Monado"
        },
        {
            "location": "/getting_started/#illixr-runtime-with-monado",
            "text": "ILLIXR leverages  Monado , an open-source implementation of  OpenXR ,\n    to support a wide range of OpenXR client applications.\nBecause of a low-level driver issue, Monado only supports Ubuntu 18.04+.    Compile and run:   ./runner.sh configs/monado.yaml",
            "title": "ILLIXR Runtime with Monado"
        },
        {
            "location": "/getting_started/#illixr-under-virtualization",
            "text": "ILLIXR can be run inside a  QEMU-KVM  image.\nCheck out the instructions  here .",
            "title": "ILLIXR under Virtualization"
        },
        {
            "location": "/getting_started/#next-steps",
            "text": "Try browsing the source for the runtime and provided plugins.\nThe source code is divided into components in the following directories:    ILLIXR/runtime/ :\n    A directory holding the implementation for loading and interfacing plugins.\n    This directory contains  Spindle .    ILLIXR/common/ :\n    A directory holding resources and utilities available globally to all plugins.\n    Most plugins symlink this directory into theirs.\n    This directory contains the interfaces for  Switchboard  and  Phonebook .    ILLIXR/<plugin_dir>/ :\n    A unique directory for each plugin.\n    Most of the core XR functionality is implemented via plugins.\n    See  Default Components  for more details.    If you edit any of the source files, the runner will detect and rebuild the respective binary\n    the next time it runs.\nIf you want to add your own plugin, see  Writing Your Plugin .  Otherwise, proceed to the next section,  Building ILLIXR .",
            "title": "Next Steps"
        },
        {
            "location": "/glossary/",
            "text": "Glossary of ILLIXR Terminology\n\n\nA collection of ILLIXR and ILLIXR-adjacent terms and their definitions can be found\n    on this page your reference.\n\n\nGeneral\n\n\nRuntime\n\n\nThe ILLIXR system runtime is responsible for the dynamic orchestration of ILLIXR\n    device resources,\n    system resources,\n    and\n    client applications.\n\n\nThe runtime implementation is located in \nILLIXR/runtime/\n.\nSee the \nBuilding ILLIXR\n and \nMonado Overiew\n pages for details about the ILLIXR runtime.\n\n\nPlugin\n\n\nA modular component that can be detected and enabled for use by an ILLIXR application.\nA plugin can be internal or external to the \nILLIXR project\n.\nEach plugin is compiled and launched dynamically at runtime based on the\n    ILLIXR \nconfiguration\n used.\nILLIXR also implements a \nMonado\n runtime \ntranslation Plugin\n.\n\n\nFor a list of supported plugins and their details, see the \nILLIXR Plugins\n page.\nFor instructions for how to modify or write your own plugins, see the \nModifying a Plugin\n\n    and \nWriting Your Plugin\n pages.\n\n\nSee the \nPlugin\n API documentation\n.\n\n\nConfig(uration)\n\n\nA file describing the key information required to launch an ILLIXR application.\nConfigurations for ILLIXR are implemented as \nYAML\n files.\nEach configuration comprises an \naction\n, a \nprofile\n, and a list of \nplugins\n as\n    defined by our configuration specification \nSchema\n.\n\n\n\n\n\n\nAction\n \n(Previously Loader)\n:\n    An \naction\n encapsulates a task for \nRunner\n.\n\n\n\n\n\n\nnative\n:\n    The default application launch configuration.\n    Does not use our \nMonado\n runtime integration.\n    Defined in \nILLIXR/configs/native.yaml\n.\n\n\n\n\n\n\nnative-lookup\n:\n    Same as \nnative\n, but using a \nground truth\n lookup from a file for\n        the \npose\n instead of computing it.\n    Defined in \nILLIXR/configs/native-lookup.yaml\n.\n\n\n\n\n\n\nheadless\n:\n    Same as \nnative\n, but using \nXvfb\n to run without a graphical environment.\n    Defined in \nILLIXR/configs/headless.yaml\n.\n\n\n\n\n\n\nci\n:\n    Same as \nheadless\n, but using \nDocker\n virtualization and debug-enabled compilation.\n    Defined in \nILLIXR/configs/ci.yaml\n.\n\n\n\n\n\n\nmonado\n:\n    Similar to \nnative\n, but uses our \nMonado\n runtime integration.\n    Defined in \nILLIXR/configs/monado.yaml\n.\n\n\n\n\n\n\nclean\n:\n    A meta-task that fetches all supported plugins and then cleans up builds across\n        the entire ILLIXR project.\n    Defined in \nILLIXR/configs/clean.yaml\n and supported by \nILLIXR/clean.sh\n.\n\n\n\n\n\n\ndocs\n:\n    A meta-task that generates and populates the documention subdirectories in the project.\n\n\n\n\n\n\n\n\n\n\nProfile\n:\n    A \nprofile\n captures the compilation mode used by \nRunner\n.\n\n\n\n\n\n\nopt\n:\n    Sets \nRunner\n to compile the ILLIXR application and plugins with optimizations.\n\n\n\n\n\n\ndbg\n:\n    Sets \nRunner\n to compile the ILLIXR application and plugins without optimizations,\n        while enabling debug logic and debug logging.\n\n\n\n\n\n\n\n\n\n\nSchema\n:\n    A \nschema\n captures the specification describing the allowable structure of\n        a configuration file.\n    Our schema is implemented using the \njson-schema specification\n.\n    Defined in \nILLIXR/runner/config_schema.yaml\n.\n\n\n\n\n\n\nFor more details about the structure of a configuration, see the \nBuilding ILLIXR page\n.\n\n\nFramebuffer\n\n\nA region of memory used to hold graphical information to be output to a display or graphics device.\n\n\n\n\n\n\nFrame\n:\n    A single frame (image) to be output to a display at a certain instant of time based on the\n        system's \nframe rate\n.\n\n\n\n\n\n\nFrame Rate\n:\n    The interval period between complete (as defined by the output resolution) frame updates\n        and refreshes.\n    In many systems, the target frame rate is determined by a fixed vertical sync (\nVSYNC\n) period.\n\n\n\n\n\n\nDepth Buffer\n:\n    A framebuffer representing the depth information of a 3D scene.\n    Depth information is useful for applications such as graphics and \nSLAM\n.\n\n\n\n\n\n\nEye Buffer\n:\n    A framebuffer dedicated for display through a \nHMD\n lens to be perceived by a user's eye.\n\n\n\n\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nSwap Chain\n\n\nA set of virtual \nframebuffers\n to be output to a display.\nOnly one framebuffer in a swap chain is displayed at a time, enabling the\n    other virtual framebuffers to be concurrently modified in memory.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nCompositor\n\n\nA window manager that establishes a \nframebuffer\n for each window of a graphical system.\nA compositor merges information across its windows to construct a unified framebuffer.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nHead-mounted Display\n\n\nA display device worn on the head and face for use with VR and XR applications.\nAlso known as a \nHMD\n.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nEye Tracking\n\n\nThe process of measuring the eye movement of a user (who is possibly also wearing a \nHMD\n).\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nEvent Stream\n\n\nA communication interface supporting writes, sychronous reads, and asynchronous reads.\nFor synchronous reads, every value written to the stream is visible to consumers.\nFor asynchronous reads, only the latest values written are guaranteed to be visible to consumers.\n\n\nPose\n\n\nThe combination of orientation and position of an object, used for computer vision\n    and robotics applications.\nILLIXR applications make use of poses to track the \nuser's HMD\n within the virtual environment.\nInternally, ILLIXR has multiple classifications of poses which are used for various purposes.\n\n\n\n\n\n\nSlow Pose\n:\n    A \nslow pose\n is a ... \nTODO\n\n\n\n\n\n\nFast Pose\n:\n    A \nfast pose\n is a ... \nTODO\n\n\n\n\n\n\nTrue Pose\n:\n    A \ntrue pose\n is a ... \nTODO\n\n    \nDepracated\n starting ILLIXR release \nv2.X.X\n.\n\n\n\n\n\n\nPose Prediction\n:\n    To improve the user's perception latency experience the time between, \npose prediction\n\n        uses history and current system information to pre-compute the user's next pose\n    Pre-computing the next pose allows for components downstream from the pose output\n        in the event stream dataflow graph to begin computation.\n\n\n\n\n\n\nPose Prediction is implemented in the \npose_prediction\n ILLIXR plugin\n.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nGround Truth\n\n\nThe most accurate source of measurement available for a data set.\nTypically, ground truth measurements are provided for the evaluation of sensor data where the sensor\n    or other data source is not as accurate or reliable as the source for the ground truth.\n\n\n\n\n\n\nGround Truth Poses\n:\n    A collection of poses used to evaluate the accuracy of pose generation and prediction algorithms.\n\n\n\n\n\n\nGround Truth Images\n:\n    A collection of images used to evaluate the accuracy of visual processing algorithms,\n        like \nSLAM\n and \nVIO\n.\n\n\n\n\n\n\nSee the \nILLIXR Plugins\n page for information about sensors implemented in ILLIXR.\n\n\nInertial Measurement Unit\n\n\nA device that reports its orientation in space and any forces applied it.\nAlso known as an \nIMU\n.\n\n\nAn IMU is implemented in the \noffline_imu_cam\n ILLIXR plugin\n.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nSimultaneous Localization and Mapping\n\n\nThe computational process of creating a map of an unknown environment, and finding one's location\n    within that space.\nAlso known as \nSLAM\n.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nVisual Interial Odometry\n\n\nThe process of computing a \npose estimate\n from incoming visual information and measurements\n    from the \nIMU\n.\nAlso known as \nVIO\n.\nOften used in combination with \nSLAM\n techniques.\n\n\nSee the \nWikipedia article\n.\n\n\nAsynchronous Reprojection\n\n\nThe processing of rendered video for motion interpolation.\nAsynchronous reprojection improves the perception of the rendered video to the \nHMD\n\n    when rendering misses it target \nframe rate\n.\n\n\nAsynchronous reprojection is implemented in the \ntimewarpgl\n ILLIXR plugin\n.\n\n\nSee the \nWikipedia article\n.\n\n\nDistortion Correction\n\n\nThe processing of visual anomalies in images where rectilinear features have been warped.\n\n\nFor more information, see the \nWikipedia artice\n.\n\n\nChromatic Abberation Correction\n\n\nThe processing of visual anomalies in images where colors are diffracted due to imperfect optics\n    or other perturbing factors.\n\n\nFor more information, see the \nWikipedia article\n.\n\n\nComponents\n\n\nRunner\n\n\nAn ILLIXR tool responsible for\n    preparing the environment,\n    downloading required assets & code,\n    compiling each plugin,\n    and\n    launching the ILLIXR application.\nThe implementation resides in \nILLIXR/runner/\n, and can be launched with\n    the appropriate environment setup via \nILLIXR/runner.sh\n.\n\n\n\n\nAction\n \n(Previously Loader)\n:\n    See \nConfiguration\n.\n\n\n\n\nSpindle\n\n\nAn ILLIXR component responsible for launching and managing plugin threads.\nThe implementation resides in \nILLIXR/runtime/\n.\n\n\nSee the \nSpindle\n API documentation\n.\n\n\nPhonebook\n\n\nAn ILLIXR service directory used to introspectively interface plugins and their data.\nThe implementation resides in \nILLIXR/runtime/\n.\n\n\nSee the \nPhonebook\n API documentation\n.\n\n\nSwitchboard\n\n\nAn ILLIXR event stream manager that maintains data pipelines between plugins.\nThe implementation resides in \nILLIXR/runtime/\n.\n\n\nSee the \nSwitchboard\n API documentation\n.\n\n\nTechnologies\n\n\nOpenXR\n\n\nAn open standard for Augmented and Virtual Reality.\nILLIXR components target the OpenXR standard and interact with the ILLIXR device\n    via the Application Interface.\n\n\nFor more information, visit the \nofficial site from the Khronos Group\n.\n\n\nMonado\n\n\nAn open source, modular implementation of the OpenXR standard for \nGNU/Linux\n.\n\n\nSee the ILLIXR \nMonado Overview\n and \nMonado Dataflow\n pages for details about our\n    runtime integration using Monado.\n\n\nFor more information, visit the \nofficial Monado development site\n.\n\n\nGodot\n\n\nAn open source game development engine.\nILLIXR applications targeting the \nOpenXR\n use Godot to access the engine's integration\n    with the OpenXR standard via \nMonado\n.\n\n\nFor more information, visit the \nofficial Godot site\n.\n\n\nXvfb\n\n\nA virtual framebuffer for the \nX11 Window Sytem\n.\nILLIXR uses Xvfb to enable running the graphical ILLIXR application without requiring the user\n    to have a graphical environment configured at application launch.\n\n\nFor more information, see the \nXfvb man page\n.\n\n\nDocker\n\n\nA platform and containerization framework for deploying applications under virtualization.\nILLIXR uses Docker to deploy and test code in a continuous integration and deployment pipeline.\n\n\nFor more information, see the \nDocker overview and getting started page\n.\n\n\nQEMU-KVM\n\n\nAn open source virtulization tool and machine emulator.\nSee the instructions for running \nILLIXR under Virtualization\n.\n\n\nFor more information, see the \nofficial QEMU page\n.\n\n\nYAML\n\n\nA markup language and data serilization standard designed to be user friendly.\nWe make use of the \nPyYAML\n and \npyyaml-include\n libraries to implement\n    our \nConfiguration\n implementation.\n\n\nFor more information, visit the \nofficial YAML page\n.\n\n\nSQLite\n\n\nA SQL database engine implementation in C designed to be lightweight and easy to use.\nThe ILLIXR project allows user to records application statistics to a local database\n    for efficient processing.\nSee the \nLogging and Metrics page\n for usage details.\n\n\nFor more information, see the \nSQLite development site\n.\n\n\nVulkan\n\n\nA cross-platform graphics API that allows developers to efficiently target\n    low-level hardware features.\n\n\nFor more information, see the \nofficial Vulkan page from the Khronos Group\n.\n\n\nOpenGL\n\n\nA cross-platform graphics API that allows developers to create graphics applications\n    easily and portably.\nAlso known as \nGL\n.\n\n\n\n\n\n\nGL Context\n:\n    A data structure storing the state of an OpenGL application instance.\n    Within a GL context resides \nframebuffer\n data.\n    It is not thread safe to share contexts without appropriate synchronization.\n\n\n\n\n\n\nGLFW\n:\n    An open source implementation of OpenGL.\n    Supports Windows, MacOS and, Linux (\nX11\n and Wayland).\n    See the \nGLFW development site\n.\n\n\n\n\n\n\nFor more information, see the \nofficial OpenGL page from the Khronos Group\n.\n\n\nUbuntu\n\n\nAn open source \nGNU/Linux\n operating system and distribution.\nILLIXR currently supports the \nLong Term Support (LTS)\n versions of Ubuntu:\n    18.04 LTS (Bionic)\n    and\n    20.04 LTS (Focal).\n\n\nFor more information, visit the \nofficial Ubuntu site\n.",
            "title": "Glossary"
        },
        {
            "location": "/glossary/#glossary-of-illixr-terminology",
            "text": "A collection of ILLIXR and ILLIXR-adjacent terms and their definitions can be found\n    on this page your reference.",
            "title": "Glossary of ILLIXR Terminology"
        },
        {
            "location": "/glossary/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/glossary/#runtime",
            "text": "The ILLIXR system runtime is responsible for the dynamic orchestration of ILLIXR\n    device resources,\n    system resources,\n    and\n    client applications.  The runtime implementation is located in  ILLIXR/runtime/ .\nSee the  Building ILLIXR  and  Monado Overiew  pages for details about the ILLIXR runtime.",
            "title": "Runtime"
        },
        {
            "location": "/glossary/#plugin",
            "text": "A modular component that can be detected and enabled for use by an ILLIXR application.\nA plugin can be internal or external to the  ILLIXR project .\nEach plugin is compiled and launched dynamically at runtime based on the\n    ILLIXR  configuration  used.\nILLIXR also implements a  Monado  runtime  translation Plugin .  For a list of supported plugins and their details, see the  ILLIXR Plugins  page.\nFor instructions for how to modify or write your own plugins, see the  Modifying a Plugin \n    and  Writing Your Plugin  pages.  See the  Plugin  API documentation .",
            "title": "Plugin"
        },
        {
            "location": "/glossary/#configuration",
            "text": "A file describing the key information required to launch an ILLIXR application.\nConfigurations for ILLIXR are implemented as  YAML  files.\nEach configuration comprises an  action , a  profile , and a list of  plugins  as\n    defined by our configuration specification  Schema .    Action   (Previously Loader) :\n    An  action  encapsulates a task for  Runner .    native :\n    The default application launch configuration.\n    Does not use our  Monado  runtime integration.\n    Defined in  ILLIXR/configs/native.yaml .    native-lookup :\n    Same as  native , but using a  ground truth  lookup from a file for\n        the  pose  instead of computing it.\n    Defined in  ILLIXR/configs/native-lookup.yaml .    headless :\n    Same as  native , but using  Xvfb  to run without a graphical environment.\n    Defined in  ILLIXR/configs/headless.yaml .    ci :\n    Same as  headless , but using  Docker  virtualization and debug-enabled compilation.\n    Defined in  ILLIXR/configs/ci.yaml .    monado :\n    Similar to  native , but uses our  Monado  runtime integration.\n    Defined in  ILLIXR/configs/monado.yaml .    clean :\n    A meta-task that fetches all supported plugins and then cleans up builds across\n        the entire ILLIXR project.\n    Defined in  ILLIXR/configs/clean.yaml  and supported by  ILLIXR/clean.sh .    docs :\n    A meta-task that generates and populates the documention subdirectories in the project.      Profile :\n    A  profile  captures the compilation mode used by  Runner .    opt :\n    Sets  Runner  to compile the ILLIXR application and plugins with optimizations.    dbg :\n    Sets  Runner  to compile the ILLIXR application and plugins without optimizations,\n        while enabling debug logic and debug logging.      Schema :\n    A  schema  captures the specification describing the allowable structure of\n        a configuration file.\n    Our schema is implemented using the  json-schema specification .\n    Defined in  ILLIXR/runner/config_schema.yaml .    For more details about the structure of a configuration, see the  Building ILLIXR page .",
            "title": "Config(uration)"
        },
        {
            "location": "/glossary/#framebuffer",
            "text": "A region of memory used to hold graphical information to be output to a display or graphics device.    Frame :\n    A single frame (image) to be output to a display at a certain instant of time based on the\n        system's  frame rate .    Frame Rate :\n    The interval period between complete (as defined by the output resolution) frame updates\n        and refreshes.\n    In many systems, the target frame rate is determined by a fixed vertical sync ( VSYNC ) period.    Depth Buffer :\n    A framebuffer representing the depth information of a 3D scene.\n    Depth information is useful for applications such as graphics and  SLAM .    Eye Buffer :\n    A framebuffer dedicated for display through a  HMD  lens to be perceived by a user's eye.    For more information, see the  Wikipedia article .",
            "title": "Framebuffer"
        },
        {
            "location": "/glossary/#swap-chain",
            "text": "A set of virtual  framebuffers  to be output to a display.\nOnly one framebuffer in a swap chain is displayed at a time, enabling the\n    other virtual framebuffers to be concurrently modified in memory.  For more information, see the  Wikipedia article .",
            "title": "Swap Chain"
        },
        {
            "location": "/glossary/#compositor",
            "text": "A window manager that establishes a  framebuffer  for each window of a graphical system.\nA compositor merges information across its windows to construct a unified framebuffer.  For more information, see the  Wikipedia article .",
            "title": "Compositor"
        },
        {
            "location": "/glossary/#head-mounted-display",
            "text": "A display device worn on the head and face for use with VR and XR applications.\nAlso known as a  HMD .  For more information, see the  Wikipedia article .",
            "title": "Head-mounted Display"
        },
        {
            "location": "/glossary/#eye-tracking",
            "text": "The process of measuring the eye movement of a user (who is possibly also wearing a  HMD ).  For more information, see the  Wikipedia article .",
            "title": "Eye Tracking"
        },
        {
            "location": "/glossary/#event-stream",
            "text": "A communication interface supporting writes, sychronous reads, and asynchronous reads.\nFor synchronous reads, every value written to the stream is visible to consumers.\nFor asynchronous reads, only the latest values written are guaranteed to be visible to consumers.",
            "title": "Event Stream"
        },
        {
            "location": "/glossary/#pose",
            "text": "The combination of orientation and position of an object, used for computer vision\n    and robotics applications.\nILLIXR applications make use of poses to track the  user's HMD  within the virtual environment.\nInternally, ILLIXR has multiple classifications of poses which are used for various purposes.    Slow Pose :\n    A  slow pose  is a ...  TODO    Fast Pose :\n    A  fast pose  is a ...  TODO    True Pose :\n    A  true pose  is a ...  TODO \n     Depracated  starting ILLIXR release  v2.X.X .    Pose Prediction :\n    To improve the user's perception latency experience the time between,  pose prediction \n        uses history and current system information to pre-compute the user's next pose\n    Pre-computing the next pose allows for components downstream from the pose output\n        in the event stream dataflow graph to begin computation.    Pose Prediction is implemented in the  pose_prediction  ILLIXR plugin .  For more information, see the  Wikipedia article .",
            "title": "Pose"
        },
        {
            "location": "/glossary/#ground-truth",
            "text": "The most accurate source of measurement available for a data set.\nTypically, ground truth measurements are provided for the evaluation of sensor data where the sensor\n    or other data source is not as accurate or reliable as the source for the ground truth.    Ground Truth Poses :\n    A collection of poses used to evaluate the accuracy of pose generation and prediction algorithms.    Ground Truth Images :\n    A collection of images used to evaluate the accuracy of visual processing algorithms,\n        like  SLAM  and  VIO .    See the  ILLIXR Plugins  page for information about sensors implemented in ILLIXR.",
            "title": "Ground Truth"
        },
        {
            "location": "/glossary/#inertial-measurement-unit",
            "text": "A device that reports its orientation in space and any forces applied it.\nAlso known as an  IMU .  An IMU is implemented in the  offline_imu_cam  ILLIXR plugin .  For more information, see the  Wikipedia article .",
            "title": "Inertial Measurement Unit"
        },
        {
            "location": "/glossary/#simultaneous-localization-and-mapping",
            "text": "The computational process of creating a map of an unknown environment, and finding one's location\n    within that space.\nAlso known as  SLAM .  For more information, see the  Wikipedia article .",
            "title": "Simultaneous Localization and Mapping"
        },
        {
            "location": "/glossary/#visual-interial-odometry",
            "text": "The process of computing a  pose estimate  from incoming visual information and measurements\n    from the  IMU .\nAlso known as  VIO .\nOften used in combination with  SLAM  techniques.  See the  Wikipedia article .",
            "title": "Visual Interial Odometry"
        },
        {
            "location": "/glossary/#asynchronous-reprojection",
            "text": "The processing of rendered video for motion interpolation.\nAsynchronous reprojection improves the perception of the rendered video to the  HMD \n    when rendering misses it target  frame rate .  Asynchronous reprojection is implemented in the  timewarpgl  ILLIXR plugin .  See the  Wikipedia article .",
            "title": "Asynchronous Reprojection"
        },
        {
            "location": "/glossary/#distortion-correction",
            "text": "The processing of visual anomalies in images where rectilinear features have been warped.  For more information, see the  Wikipedia artice .",
            "title": "Distortion Correction"
        },
        {
            "location": "/glossary/#chromatic-abberation-correction",
            "text": "The processing of visual anomalies in images where colors are diffracted due to imperfect optics\n    or other perturbing factors.  For more information, see the  Wikipedia article .",
            "title": "Chromatic Abberation Correction"
        },
        {
            "location": "/glossary/#components",
            "text": "",
            "title": "Components"
        },
        {
            "location": "/glossary/#runner",
            "text": "An ILLIXR tool responsible for\n    preparing the environment,\n    downloading required assets & code,\n    compiling each plugin,\n    and\n    launching the ILLIXR application.\nThe implementation resides in  ILLIXR/runner/ , and can be launched with\n    the appropriate environment setup via  ILLIXR/runner.sh .   Action   (Previously Loader) :\n    See  Configuration .",
            "title": "Runner"
        },
        {
            "location": "/glossary/#spindle",
            "text": "An ILLIXR component responsible for launching and managing plugin threads.\nThe implementation resides in  ILLIXR/runtime/ .  See the  Spindle  API documentation .",
            "title": "Spindle"
        },
        {
            "location": "/glossary/#phonebook",
            "text": "An ILLIXR service directory used to introspectively interface plugins and their data.\nThe implementation resides in  ILLIXR/runtime/ .  See the  Phonebook  API documentation .",
            "title": "Phonebook"
        },
        {
            "location": "/glossary/#switchboard",
            "text": "An ILLIXR event stream manager that maintains data pipelines between plugins.\nThe implementation resides in  ILLIXR/runtime/ .  See the  Switchboard  API documentation .",
            "title": "Switchboard"
        },
        {
            "location": "/glossary/#technologies",
            "text": "",
            "title": "Technologies"
        },
        {
            "location": "/glossary/#openxr",
            "text": "An open standard for Augmented and Virtual Reality.\nILLIXR components target the OpenXR standard and interact with the ILLIXR device\n    via the Application Interface.  For more information, visit the  official site from the Khronos Group .",
            "title": "OpenXR"
        },
        {
            "location": "/glossary/#monado",
            "text": "An open source, modular implementation of the OpenXR standard for  GNU/Linux .  See the ILLIXR  Monado Overview  and  Monado Dataflow  pages for details about our\n    runtime integration using Monado.  For more information, visit the  official Monado development site .",
            "title": "Monado"
        },
        {
            "location": "/glossary/#godot",
            "text": "An open source game development engine.\nILLIXR applications targeting the  OpenXR  use Godot to access the engine's integration\n    with the OpenXR standard via  Monado .  For more information, visit the  official Godot site .",
            "title": "Godot"
        },
        {
            "location": "/glossary/#xvfb",
            "text": "A virtual framebuffer for the  X11 Window Sytem .\nILLIXR uses Xvfb to enable running the graphical ILLIXR application without requiring the user\n    to have a graphical environment configured at application launch.  For more information, see the  Xfvb man page .",
            "title": "Xvfb"
        },
        {
            "location": "/glossary/#docker",
            "text": "A platform and containerization framework for deploying applications under virtualization.\nILLIXR uses Docker to deploy and test code in a continuous integration and deployment pipeline.  For more information, see the  Docker overview and getting started page .",
            "title": "Docker"
        },
        {
            "location": "/glossary/#qemu-kvm",
            "text": "An open source virtulization tool and machine emulator.\nSee the instructions for running  ILLIXR under Virtualization .  For more information, see the  official QEMU page .",
            "title": "QEMU-KVM"
        },
        {
            "location": "/glossary/#yaml",
            "text": "A markup language and data serilization standard designed to be user friendly.\nWe make use of the  PyYAML  and  pyyaml-include  libraries to implement\n    our  Configuration  implementation.  For more information, visit the  official YAML page .",
            "title": "YAML"
        },
        {
            "location": "/glossary/#sqlite",
            "text": "A SQL database engine implementation in C designed to be lightweight and easy to use.\nThe ILLIXR project allows user to records application statistics to a local database\n    for efficient processing.\nSee the  Logging and Metrics page  for usage details.  For more information, see the  SQLite development site .",
            "title": "SQLite"
        },
        {
            "location": "/glossary/#vulkan",
            "text": "A cross-platform graphics API that allows developers to efficiently target\n    low-level hardware features.  For more information, see the  official Vulkan page from the Khronos Group .",
            "title": "Vulkan"
        },
        {
            "location": "/glossary/#opengl",
            "text": "A cross-platform graphics API that allows developers to create graphics applications\n    easily and portably.\nAlso known as  GL .    GL Context :\n    A data structure storing the state of an OpenGL application instance.\n    Within a GL context resides  framebuffer  data.\n    It is not thread safe to share contexts without appropriate synchronization.    GLFW :\n    An open source implementation of OpenGL.\n    Supports Windows, MacOS and, Linux ( X11  and Wayland).\n    See the  GLFW development site .    For more information, see the  official OpenGL page from the Khronos Group .",
            "title": "OpenGL"
        },
        {
            "location": "/glossary/#ubuntu",
            "text": "An open source  GNU/Linux  operating system and distribution.\nILLIXR currently supports the  Long Term Support (LTS)  versions of Ubuntu:\n    18.04 LTS (Bionic)\n    and\n    20.04 LTS (Focal).  For more information, visit the  official Ubuntu site .",
            "title": "Ubuntu"
        },
        {
            "location": "/illixr_plugins/",
            "text": "ILLIXR plugins\n\n\nThis page details the structure of ILLIXR's \nplugins\n and how they interact with each other.\n\n\nDefault Plugins\n\n\n\n\n\n\noffline_imu_cam\n:\n    Reads \nIMU\n data and images from files on disk, emulating a real sensor on the \nheadset\n\n        (feeds the application input measurements with timing similar to an actual IMU).\n\n\nTopic details:\n\n\n\n\nPublishes\n \nimu_cam_type\n on \nimu_cam\n topic.\n\n\n\n\n\n\n\n\nground_truth_slam\n:\n    Reads the \nground truth\n from the same dataset as the \noffline_imu_cam\n plugin.\n    Ground truth data can be compared against the measurements from \noffline_imu_cam\n for accuracy.\n    Timing information is taken from the \noffline_imu_cam\n measurements/data.\n\n\nTopic details:\n\n\n\n\nPublishes\n \npose_type\n on \ntrue_pose\n topic.\n\n\nAsynchronously \nreads\n \nimu_cam_type\n on \nimu_cam\n topic.\n\n\n\n\n\n\n\n\nkimera_vio\n:\n    Runs Kimera-VIO (\nupstream\n) on the input, and outputs the \nheadset's\n \npose\n.\n    In practice, the Kimera-VIO plugin publishes a fairly \nslow pose\n, so \nIMU\n integration\n        and \npose prediction\n is required to infer a \nfast pose\n.\n\n\nTopic details:\n\n\n\n\nPublishes\n \npose_type\n on \nslow_pose\n topic.\n\n\nPublishes\n \nimu_integrator_input\n on \nimu_integrator_input\n topic.\n\n\nSynchronously \nreads\n/\nsubscribes\n to \nimu_cam_type\n on \nimu_cam\n topic.\n\n\n\n\n\n\n\n\ngtsam_integrator\n:\n    Integrates over all \nIMU\n samples since the last published \nSLAM\n pose to provide a\n        \nfast pose\n every time a new IMU sample arrives using the GTSAM library (\nupstream\n).\n\n\nTopic details:\n\n\n\n\nPublishes\n \nimu_raw_type\n on \nimu_raw\n topic.\n\n\nSynchronously \nreads/subscribes\n to \nimu_cam_type\n on \nimu_cam\n topic.\n\n\nAsynchronously \nreads\n \nimu_integrator_input\n on \nimu_integrator_input\n topic.\n\n\n\n\n\n\n\n\npose_prediction\n:\n    Uses the latest \nIMU\n value to predict a \npose\n for a future point in time.\n    Implements the \npose_prediction\n service (defined in \ncommon\n),\n        so poses can be served directly to other plugins.\n\n\nTopic details:\n\n\n\n\nAsynchronously \nreads\n \npose_type\n on \nslow_pose\n topic,\n        but it is only used as a fallback.\n\n\nAsynchronously \nreads\n \nimu_raw\n on \nimu_raw\n topic.\n\n\nAsynchronously \nreads\n \npose_type\n on \ntrue_pose\n topic,\n        but it is only used if the client asks for the true pose.\n\n\nAsynchronously \nreads\n \ntime_type\n on \nvsync_estimate\n topic.\n    This tells \npose_predict\n what time to estimate for.\n\n\n\n\n\n\n\n\ngldemo\n:\n    Renders a static scene (into left and right \neye buffers\n) given the \npose\n\n        from \npose_prediction\n.\n\n\nTopic details:\n\n\n\n\nCalls\n \npose_prediction\n.\n\n\nPublishes\n \nrendered_frame\n on \neyebuffer\n topic.\n\n\nAsynchronously \nreads\n \ntime_type\n on \nvsync_estimate\n topic.\n\n\n\n\n\n\n\n\ntimewarp_gl\n:\n    \nAsynchronous reprojection\n of the \neye buffers\n.\n    The timewarp ends just after \nvsync\n, so it can deduce when the next vsync will be.\n\n\nTopic details:\n\n\n\n\nCalls\n \npose_prediction\n.\n\n\nAsynchronously \nreads\n \nrendered_frame\n on \neyebuffer\n topic.\n\n\nPublishes\n \ntime_type\n on \nvsync_estimate\n topic.\n\n\nPublishes\n \nhologram_input\n on \nhologram_in\n topic.\n\n\nPublishes\n \ntexture_pose\n on \ntexture_pose\n topic if \nILLIXR_OFFLOAD_ENABLE\n is set in the env.\n\n\n\n\n\n\n\n\ndebugview\n:\n    Renders incoming \nframes\n from the graphics pipeline for debugging live executions of the application.\n\n\nTopic details:\n\n\n\n\nCalls\n \npose_prediction\n.\n\n\nAsynchronously \nreads\n \nfast_pose\n on \nimu_raw\n topic. (\nIMU\n biases are unused).\n\n\nAsynchronously \nreads\n \nslow_pose\n on \nslow_pose\n topic.\n\n\nSynchronously \nreads\n \nimu_cam\n on \nimu_cam\n topic.\n\n\n\n\n\n\n\n\naudio_pipeline\n:\n    Launches a thread for \nbinaural\n recording and one for binaural playback.\n    Audio output is not yet routed to the system's speakers or microphone,\n        but the plugin's compute workload is still representative of a real system.\n    By default this plugin is enabled (see \nnative\n \nconfiguration\n).\n\n\nTopic details:\n\n\n\n\nCalls\n \npose_prediction\n.\n\n\n\n\n\n\n\n\nBelow this point, we will use Switchboard terminology.\nRead the \nAPI documentation on \nSwitchboard\n for more information.\n\n\n\n\n\n\n\n\nIn the above figure, rectangles are plugins.\n\n\n\n\n\n\nSolid arrows from plugins to topics represent publishing.\n\n\n\n\n\n\nSolid arrows from topics to plugins represent synchronous reading.\n    Some action is taken for \nevery\n event which gets published on the topic.\n\n\n\n\n\n\nDashed arrows from topics to plugins represent asynchronous reading.\n    Plugin readers only need the \nlatest\n event on their topic.\n\n\n\n\n\n\nImagine the topic as a trough filling with events from its publisher.\n    Synchronous readers (AKA subscribers) drain the trough,\n        while asynchronous readers just skim fresh events off the top of the trough.\n\n\n\n\n\n\nSee \nWriting Your Plugin\n to extend ILLIXR.\n\n\nOther Supported Plugins\n\n\nILLIXR supports additional plugins to replace some of the default plugins.\n\n\n\n\n\n\nhologram\n:\n    Adapts the eyebuffer for use on a holographic display.\n    By default, this plugin is disabled, since an NVIDIA GPU is currently required.\n\n\nTopic details:\n\n\n\n\nAsynchronously \nreads\n \nhologram_input\n on \nhologram_in\n topic.\n    Hologram is too slow to run for every input,\n        so the plugin implements an asynchronous reader which can drop inputs.\n\n\n\n\n\n\n\n\nopen_vins\n:\n    An alternate \nSLAM\n (\nupstream\n) implementation that uses a MSCKF\n        (Multi-State Constrained Kalman Filter) to determine poses via camera/\nIMU\n.\n\n\nTopic details:\n\n\n\n\nSame interface as \nKimera-VIO\n.\n\n\n\n\n\n\n\n\nrk4_integrator\n:\n    Integrates over all \nIMU\n samples since the last published \nSLAM\n \npose\n to\n        provide a \nfast pose\n every time a new IMU sample arrives using RK4 integration.\n\n\nTopic details:\n\n\n\n\nSame interface as \ngtsam_integrator\n.\n\n\n\n\n\n\n\n\npose_lookup\n:\n    Implements the \npose_predict\n service, but uses \nground truth\n from the dataset.\n    The plugin peeks \"into the future\" to determine what the exact \npose\n will be at a certain time.\n\n\nTopic details:\n\n\n\n\nAsynchronously \nreads\n \ntime_type\n on \nvsync_estimate\n topic.\n    This tells \npose_lookup\n what time to lookup.\n\n\n\n\n\n\n\n\noffload_data\n:\n    Writes \nframes\n and \nposes\n output from the \nasynchronous reprojection\n plugin to disk for analysis.\n\n\nTopic details:\n\n\n\n\nSynchronously \nreads\n \ntexture_pose\n on \ntexture_pose\n topic.\n\n\n\n\n\n\n\n\nzed\n:\n    Reads images and \nIMU\n measurements from the \nZED Mini\n.\n    Unlike \noffline_imu_cam\n, \nzed\n additionally has RGB and \ndepth\n data.\n    Note that this plugin implements two threads: one for the camera, and one for the IMU.\n\n\nTopic details:\n\n\n\n\nPublishes\n \nimu_cam_type\n on \nimu_cam\n topic.\n\n\nPublishes\n \nrgb_depth_type\n on \nrgb_depth\n topic.\n\n\n\n\n\n\n\n\nrealsense\n:\n    Reads images and \nIMU\n measurements from the \nIntel Realsense\n.\n\n\nTopic details:\n\n\n\n\nSame interface as \nzed\n.\n\n\n\n\n\n\n\n\nSee \nBuilding ILLIXR\n for more information on adding plugins to a \nconfig\n file.",
            "title": "Illixr plugins"
        },
        {
            "location": "/illixr_plugins/#illixr-plugins",
            "text": "This page details the structure of ILLIXR's  plugins  and how they interact with each other.",
            "title": "ILLIXR plugins"
        },
        {
            "location": "/illixr_plugins/#default-plugins",
            "text": "offline_imu_cam :\n    Reads  IMU  data and images from files on disk, emulating a real sensor on the  headset \n        (feeds the application input measurements with timing similar to an actual IMU).  Topic details:   Publishes   imu_cam_type  on  imu_cam  topic.     ground_truth_slam :\n    Reads the  ground truth  from the same dataset as the  offline_imu_cam  plugin.\n    Ground truth data can be compared against the measurements from  offline_imu_cam  for accuracy.\n    Timing information is taken from the  offline_imu_cam  measurements/data.  Topic details:   Publishes   pose_type  on  true_pose  topic.  Asynchronously  reads   imu_cam_type  on  imu_cam  topic.     kimera_vio :\n    Runs Kimera-VIO ( upstream ) on the input, and outputs the  headset's   pose .\n    In practice, the Kimera-VIO plugin publishes a fairly  slow pose , so  IMU  integration\n        and  pose prediction  is required to infer a  fast pose .  Topic details:   Publishes   pose_type  on  slow_pose  topic.  Publishes   imu_integrator_input  on  imu_integrator_input  topic.  Synchronously  reads / subscribes  to  imu_cam_type  on  imu_cam  topic.     gtsam_integrator :\n    Integrates over all  IMU  samples since the last published  SLAM  pose to provide a\n         fast pose  every time a new IMU sample arrives using the GTSAM library ( upstream ).  Topic details:   Publishes   imu_raw_type  on  imu_raw  topic.  Synchronously  reads/subscribes  to  imu_cam_type  on  imu_cam  topic.  Asynchronously  reads   imu_integrator_input  on  imu_integrator_input  topic.     pose_prediction :\n    Uses the latest  IMU  value to predict a  pose  for a future point in time.\n    Implements the  pose_prediction  service (defined in  common ),\n        so poses can be served directly to other plugins.  Topic details:   Asynchronously  reads   pose_type  on  slow_pose  topic,\n        but it is only used as a fallback.  Asynchronously  reads   imu_raw  on  imu_raw  topic.  Asynchronously  reads   pose_type  on  true_pose  topic,\n        but it is only used if the client asks for the true pose.  Asynchronously  reads   time_type  on  vsync_estimate  topic.\n    This tells  pose_predict  what time to estimate for.     gldemo :\n    Renders a static scene (into left and right  eye buffers ) given the  pose \n        from  pose_prediction .  Topic details:   Calls   pose_prediction .  Publishes   rendered_frame  on  eyebuffer  topic.  Asynchronously  reads   time_type  on  vsync_estimate  topic.     timewarp_gl :\n     Asynchronous reprojection  of the  eye buffers .\n    The timewarp ends just after  vsync , so it can deduce when the next vsync will be.  Topic details:   Calls   pose_prediction .  Asynchronously  reads   rendered_frame  on  eyebuffer  topic.  Publishes   time_type  on  vsync_estimate  topic.  Publishes   hologram_input  on  hologram_in  topic.  Publishes   texture_pose  on  texture_pose  topic if  ILLIXR_OFFLOAD_ENABLE  is set in the env.     debugview :\n    Renders incoming  frames  from the graphics pipeline for debugging live executions of the application.  Topic details:   Calls   pose_prediction .  Asynchronously  reads   fast_pose  on  imu_raw  topic. ( IMU  biases are unused).  Asynchronously  reads   slow_pose  on  slow_pose  topic.  Synchronously  reads   imu_cam  on  imu_cam  topic.     audio_pipeline :\n    Launches a thread for  binaural  recording and one for binaural playback.\n    Audio output is not yet routed to the system's speakers or microphone,\n        but the plugin's compute workload is still representative of a real system.\n    By default this plugin is enabled (see  native   configuration ).  Topic details:   Calls   pose_prediction .     Below this point, we will use Switchboard terminology.\nRead the  API documentation on  Switchboard  for more information.     In the above figure, rectangles are plugins.    Solid arrows from plugins to topics represent publishing.    Solid arrows from topics to plugins represent synchronous reading.\n    Some action is taken for  every  event which gets published on the topic.    Dashed arrows from topics to plugins represent asynchronous reading.\n    Plugin readers only need the  latest  event on their topic.    Imagine the topic as a trough filling with events from its publisher.\n    Synchronous readers (AKA subscribers) drain the trough,\n        while asynchronous readers just skim fresh events off the top of the trough.    See  Writing Your Plugin  to extend ILLIXR.",
            "title": "Default Plugins"
        },
        {
            "location": "/illixr_plugins/#other-supported-plugins",
            "text": "ILLIXR supports additional plugins to replace some of the default plugins.    hologram :\n    Adapts the eyebuffer for use on a holographic display.\n    By default, this plugin is disabled, since an NVIDIA GPU is currently required.  Topic details:   Asynchronously  reads   hologram_input  on  hologram_in  topic.\n    Hologram is too slow to run for every input,\n        so the plugin implements an asynchronous reader which can drop inputs.     open_vins :\n    An alternate  SLAM  ( upstream ) implementation that uses a MSCKF\n        (Multi-State Constrained Kalman Filter) to determine poses via camera/ IMU .  Topic details:   Same interface as  Kimera-VIO .     rk4_integrator :\n    Integrates over all  IMU  samples since the last published  SLAM   pose  to\n        provide a  fast pose  every time a new IMU sample arrives using RK4 integration.  Topic details:   Same interface as  gtsam_integrator .     pose_lookup :\n    Implements the  pose_predict  service, but uses  ground truth  from the dataset.\n    The plugin peeks \"into the future\" to determine what the exact  pose  will be at a certain time.  Topic details:   Asynchronously  reads   time_type  on  vsync_estimate  topic.\n    This tells  pose_lookup  what time to lookup.     offload_data :\n    Writes  frames  and  poses  output from the  asynchronous reprojection  plugin to disk for analysis.  Topic details:   Synchronously  reads   texture_pose  on  texture_pose  topic.     zed :\n    Reads images and  IMU  measurements from the  ZED Mini .\n    Unlike  offline_imu_cam ,  zed  additionally has RGB and  depth  data.\n    Note that this plugin implements two threads: one for the camera, and one for the IMU.  Topic details:   Publishes   imu_cam_type  on  imu_cam  topic.  Publishes   rgb_depth_type  on  rgb_depth  topic.     realsense :\n    Reads images and  IMU  measurements from the  Intel Realsense .  Topic details:   Same interface as  zed .     See  Building ILLIXR  for more information on adding plugins to a  config  file.",
            "title": "Other Supported Plugins"
        },
        {
            "location": "/logging_and_metrics/",
            "text": "Logging and Metrics\n\n\nThe ILLIXR project supports several ways for an ILLIXR application to log and report details about\n    its execution.\n\n\nLogging\n\n\nILLIXR implements a modular logging system that enables users to capture and record key statistics\n    in real-time.\n\n\n\n\n\n\nrecord_logger\n:\n    The base class describing ILLIXR's logging interface.\n\n\n\n\n\n\nnoop_logger\n:\n    Implements a trivially empty implementation of \nrecord_logger\n.\n    Can be used for debugging or performance if runtime statistics are not needed.\n\n\n\n\n\n\nsqlite_record_logger\n:\n    Extends the \nrecord_logger\n to store records in a local \nSQLite database\n.\n\n\n\n\n\n\nMetrics\n\n\nILLIXR allows users to generate higher order statistics from logged results called \nMetrics\n.\n\n\nTODO",
            "title": "Logging and metrics"
        },
        {
            "location": "/logging_and_metrics/#logging-and-metrics",
            "text": "The ILLIXR project supports several ways for an ILLIXR application to log and report details about\n    its execution.",
            "title": "Logging and Metrics"
        },
        {
            "location": "/logging_and_metrics/#logging",
            "text": "ILLIXR implements a modular logging system that enables users to capture and record key statistics\n    in real-time.    record_logger :\n    The base class describing ILLIXR's logging interface.    noop_logger :\n    Implements a trivially empty implementation of  record_logger .\n    Can be used for debugging or performance if runtime statistics are not needed.    sqlite_record_logger :\n    Extends the  record_logger  to store records in a local  SQLite database .",
            "title": "Logging"
        },
        {
            "location": "/logging_and_metrics/#metrics",
            "text": "ILLIXR allows users to generate higher order statistics from logged results called  Metrics .  TODO",
            "title": "Metrics"
        },
        {
            "location": "/modifying_a_plugin/",
            "text": "Modifying a plugin\n\n\nTutorial\n\n\nThis is how you can modify an existing ILLIXR plugin\n\n\n\n\n\n\nClone the repository for the component you want to modify.\n    For example:\n\n\n\n\n\ngit clone https://github.com/ILLIXR/audio_pipeline.git\n\n\n\n\n\n\n\nModify the config file like this:\n\n\nOriginal Config\n\n\n\n\n\nplugin_group:\n  - path: timewarp_gl/\n  - name: audio\n    path:\n      git_repo: https://github.com/ILLIXR/audio_pipeline.git\n      version: 3433bb452b2ec661c9d3ef65d9cf3a2805e94cdc\n\n\n\nNew Config\n\n\n\n\n\nplugin_group:\n  - path: timewarp_gl/\n  - path: /PATH/TO/LOCAL/AUDIO-PLUGIN\n\n\n\n\n\n\n\nSee the instructions on \nBuilding ILLIXR\n to learn how to run ILLIXR.\n\n\n\n\n\n\nTo push the modification to upstream ILLIXR, push up the changes to the plugin's repository\n        and modify the original config with the commit version updated.\n    Then create a PR on the main ILLIXR repository.",
            "title": "Modifying a plugin"
        },
        {
            "location": "/modifying_a_plugin/#modifying-a-plugin",
            "text": "",
            "title": "Modifying a plugin"
        },
        {
            "location": "/modifying_a_plugin/#tutorial",
            "text": "This is how you can modify an existing ILLIXR plugin    Clone the repository for the component you want to modify.\n    For example:   git clone https://github.com/ILLIXR/audio_pipeline.git    Modify the config file like this:  Original Config   plugin_group:\n  - path: timewarp_gl/\n  - name: audio\n    path:\n      git_repo: https://github.com/ILLIXR/audio_pipeline.git\n      version: 3433bb452b2ec661c9d3ef65d9cf3a2805e94cdc  New Config   plugin_group:\n  - path: timewarp_gl/\n  - path: /PATH/TO/LOCAL/AUDIO-PLUGIN    See the instructions on  Building ILLIXR  to learn how to run ILLIXR.    To push the modification to upstream ILLIXR, push up the changes to the plugin's repository\n        and modify the original config with the commit version updated.\n    Then create a PR on the main ILLIXR repository.",
            "title": "Tutorial"
        },
        {
            "location": "/monado_illixr_runtime_overview/",
            "text": "Monado Integration Overview\n\n\nILLIXR's \nPlugins\n provide XR services, and the \nRuntime\n ties them together.\nHowever, we don't want to force developers to write \ntheir whole application\n specifically\n    for ILLIXR.\nAs such, we want to implement a common interface XR runtimes, such as \nOpenXR\n,\n    so one application can work on several runtimes (including ours).\nIn order to support OpenXR, we modified \nMonado\n, an existing, open-source implementation\n    of the standard.\n\n\n\n\n\n\nWhen running ILLIXR without Monado, the ILLIXR runtime is the entry-point.\n    Phonebook and switchboard are initialized and plugins are loaded, among which is the gldemo app.\n\n\n\n\n\n\nWhen running from Monado, however, as mandated by OpenXR specifications,\n        the application is the entry point.\n    As a result, the ILLIXR runtime system is loaded at a later point as a shared library.\n    This page documents the changes to the ILLIXR runtime when an OpenXR application is used.\n\n\n\n\n\n\nOpenXR Application Launch\n\n\nAs specified by \nOpenXR\n, the OpenXR application initializes the OpenXR runtime by reading a\n    configuration JSON file pointed to by an environment variable and loads the OpenXR runtime,\n    which is Monado in this case, as a shared library into its address space.\nConsult the OpenXR specifications and the OpenXR-SDK from Khronos Group for more details.\n\n\nMonado Device Probe and ILLIXR Initialization\n\n\nDuring initialization, \nMonado\n asks all drivers to probe for and initialize \nHMDs\n\n    and controllers, internally known as \nxdev\ns.\nOur ILLIXR driver will always respond to Monado with one discovered HMD that\n    will be used to capture OpenXR queries and events from Monado's state tracker.\nThe driver obtains the path to the ILLIXR runtime \n.so\n file and a list of plugins from\n    environment variables.\n\n\nAfter probing is finished, the application will start to create an OpenXR session.\nAt some point in this process, the application will send its rendering context to the runtime,\n    which we capture and send to the ILLIXR driver.\nAt this moment, all necessary data is ready and ILLIXR will be launched.\n\n\nILLIXR Runtime Launch\n\n\nWhen used with \nMonado\n, the ILLIXR \nRuntime\n is compiled into\n    a shared library instead of an executable.\nThe library exports its two major functionalities:\n    initializing \nSwitchboard\n and \nPhonebook\n,\n    and\n    loading \nPlugins\n.\n\n\nThe driver starts to load the runtime by loading the shared library into the current\n    (application's) address space and calls the Switchboard and Phonebook initialization.\nThen, it calls the plugin loading for each ILLIXR plugin\n    (except \ngldemo\n, which is replaced by the OpenXR app).\nFinally, it calls a special plugin loading which takes a function address instead of a file path\n    to load a \nTranslation Plugin\n into ILLIXR as the application.\nIf the plugin implements a long running computation, it may block the main ILLIXR thread\n    which drives the entire application.\nTo remedy this, a plugin should implement long running processing in its own thread.\nThis way, the driver will be able to reacquire control and return to Monado\n    and the application efficiently.\n\n\nTranslation Plugin\n\n\nWhen the application and all \nILLIXR plugins\n are up and running,\n    the translation plugin handles the connection between \nMonado\n and ILLIXR.\nIt might be confusing to see that this plugin is part of the ILLIXR driver which is part of\n    Monado while at the same time also part of ILLIXR as a plugin.\nHowever, Monado and ILLIXR are running in different threads in the same address space.\nThe translation plugin is the interface of these two parallel systems.\n\n\nThe translation plugin handles two types of events at the moment:\n    \npose\n requests and \nframe\n submissions.\nFrom the view of Monado, the translation plugin is the destination of all requests:\n    from the application,\n    to Monado's state trackers,\n    to the xdev interface who is responsible for servicing the request.\nFrom the view of ILLIXR, the translation plugin behaves the same as the \ngldemo\n application\n:\n    reading pose and submitting frames.\n\n\nFor implementation details regarding the representation of poses and frames in Monado\n    and in ILLIXR, please see ILLIXR's \nMonado Integration Dataflow\n.",
            "title": "Monado illixr runtime overview"
        },
        {
            "location": "/monado_illixr_runtime_overview/#monado-integration-overview",
            "text": "ILLIXR's  Plugins  provide XR services, and the  Runtime  ties them together.\nHowever, we don't want to force developers to write  their whole application  specifically\n    for ILLIXR.\nAs such, we want to implement a common interface XR runtimes, such as  OpenXR ,\n    so one application can work on several runtimes (including ours).\nIn order to support OpenXR, we modified  Monado , an existing, open-source implementation\n    of the standard.    When running ILLIXR without Monado, the ILLIXR runtime is the entry-point.\n    Phonebook and switchboard are initialized and plugins are loaded, among which is the gldemo app.    When running from Monado, however, as mandated by OpenXR specifications,\n        the application is the entry point.\n    As a result, the ILLIXR runtime system is loaded at a later point as a shared library.\n    This page documents the changes to the ILLIXR runtime when an OpenXR application is used.",
            "title": "Monado Integration Overview"
        },
        {
            "location": "/monado_illixr_runtime_overview/#openxr-application-launch",
            "text": "As specified by  OpenXR , the OpenXR application initializes the OpenXR runtime by reading a\n    configuration JSON file pointed to by an environment variable and loads the OpenXR runtime,\n    which is Monado in this case, as a shared library into its address space.\nConsult the OpenXR specifications and the OpenXR-SDK from Khronos Group for more details.",
            "title": "OpenXR Application Launch"
        },
        {
            "location": "/monado_illixr_runtime_overview/#monado-device-probe-and-illixr-initialization",
            "text": "During initialization,  Monado  asks all drivers to probe for and initialize  HMDs \n    and controllers, internally known as  xdev s.\nOur ILLIXR driver will always respond to Monado with one discovered HMD that\n    will be used to capture OpenXR queries and events from Monado's state tracker.\nThe driver obtains the path to the ILLIXR runtime  .so  file and a list of plugins from\n    environment variables.  After probing is finished, the application will start to create an OpenXR session.\nAt some point in this process, the application will send its rendering context to the runtime,\n    which we capture and send to the ILLIXR driver.\nAt this moment, all necessary data is ready and ILLIXR will be launched.",
            "title": "Monado Device Probe and ILLIXR Initialization"
        },
        {
            "location": "/monado_illixr_runtime_overview/#illixr-runtime-launch",
            "text": "When used with  Monado , the ILLIXR  Runtime  is compiled into\n    a shared library instead of an executable.\nThe library exports its two major functionalities:\n    initializing  Switchboard  and  Phonebook ,\n    and\n    loading  Plugins .  The driver starts to load the runtime by loading the shared library into the current\n    (application's) address space and calls the Switchboard and Phonebook initialization.\nThen, it calls the plugin loading for each ILLIXR plugin\n    (except  gldemo , which is replaced by the OpenXR app).\nFinally, it calls a special plugin loading which takes a function address instead of a file path\n    to load a  Translation Plugin  into ILLIXR as the application.\nIf the plugin implements a long running computation, it may block the main ILLIXR thread\n    which drives the entire application.\nTo remedy this, a plugin should implement long running processing in its own thread.\nThis way, the driver will be able to reacquire control and return to Monado\n    and the application efficiently.",
            "title": "ILLIXR Runtime Launch"
        },
        {
            "location": "/monado_illixr_runtime_overview/#translation-plugin",
            "text": "When the application and all  ILLIXR plugins  are up and running,\n    the translation plugin handles the connection between  Monado  and ILLIXR.\nIt might be confusing to see that this plugin is part of the ILLIXR driver which is part of\n    Monado while at the same time also part of ILLIXR as a plugin.\nHowever, Monado and ILLIXR are running in different threads in the same address space.\nThe translation plugin is the interface of these two parallel systems.  The translation plugin handles two types of events at the moment:\n     pose  requests and  frame  submissions.\nFrom the view of Monado, the translation plugin is the destination of all requests:\n    from the application,\n    to Monado's state trackers,\n    to the xdev interface who is responsible for servicing the request.\nFrom the view of ILLIXR, the translation plugin behaves the same as the  gldemo  application :\n    reading pose and submitting frames.  For implementation details regarding the representation of poses and frames in Monado\n    and in ILLIXR, please see ILLIXR's  Monado Integration Dataflow .",
            "title": "Translation Plugin"
        },
        {
            "location": "/monado_integration_dataflow/",
            "text": "Monado Integration Dataflow\n\n\nThe dataflow for the ILLIXR \nMonado\n integration comprises two steps:\n1.  getting pose data from ILLIXR,\n    and\n1.  sending a user rendered \nframe\n back to ILLIXR.\n\n\nIn Monado, ILLIXR is recognized as an \nHMD\n for Monado, while in ILLIXR,\n    Monado looks like a user application (such as \ngldemo\n).\nAfter ILLIXR is initialized from Monado, and Monado is registered as a \nplugin\n for ILLIXR,\n    the most recent \npose\n information can be easily obtained via \nSwitchboard\n.\n\n\nThe \ncompositor\n side of Monado integration with ILLIXR is implemented more subtly.\nThe original Monado compositor primarily performs \ndistortion correction\n\n    and \naberration correction\n in a \nVulkan\n back-end compositor.\nThe compositor also has two client compositors (one for \nOpenGL\n applications and another\n    for Vulkan applications) which pass frame data to the back-end compositor.\nILLIXR integration intercepts the frame at GL client compositor and sends it to Switchboard\n    of ILLIXR, which is then used by \ntimewarp_gl\n component\n.\n\n\nTo get an OpenGL frame and use it without copying pixels, ILLIXR needs to get the user\n    application GL context.\nThis is done at OpenXR session creation time, where ILLIXR is initialized.\nNote that, logically, ILLIXR is initialized during OpenXR instance creation,\n    or is otherwise running in the background all the time.\nCurrently, ILLIXR is initialized at session creation time, since ILLIXR only supports single\n    OpenXR session, and requires a user application GL context upon initialization,\n\n\nThe current ILLIXR integration for Monado is a temporary solution and has some drawbacks caused\n    by the concurrent and continued development from both the Monado and ILLIXR projects.\nThe integration:\n\n\n\n\n\n\nDoes not use the pose that user application declares to use at rendering\n        (using the OpenXR specification).\n    This is due to incongruencies with Monado's internal interfaces and representations.\n    The pose difference used by \ntimewarp\n is computed using the most recent query\n        for a pose update.\n\n\n\n\n\n\nCannot submit frame data with a depth buffer.\n\n\n\n\n\n\nCannot have poses that make use of \nOpenXR Spaces\n.\n    Raw pose data is instead retrieved from the application's \nSLAM\n algorithms.\n\n\n\n\n\n\nDoes not support controller action.\n\n\n\n\n\n\nOnly supports GL user-space applications.\n\n\n\n\n\n\nUser-space applications cannot acquire more than one \nswap chain\n buffer for each eye\n        during the the processing of a frame.\n\n\n\n\n\n\nMust initialize ILLIXR during the session initialization.",
            "title": "Monado integration dataflow"
        },
        {
            "location": "/monado_integration_dataflow/#monado-integration-dataflow",
            "text": "The dataflow for the ILLIXR  Monado  integration comprises two steps:\n1.  getting pose data from ILLIXR,\n    and\n1.  sending a user rendered  frame  back to ILLIXR.  In Monado, ILLIXR is recognized as an  HMD  for Monado, while in ILLIXR,\n    Monado looks like a user application (such as  gldemo ).\nAfter ILLIXR is initialized from Monado, and Monado is registered as a  plugin  for ILLIXR,\n    the most recent  pose  information can be easily obtained via  Switchboard .  The  compositor  side of Monado integration with ILLIXR is implemented more subtly.\nThe original Monado compositor primarily performs  distortion correction \n    and  aberration correction  in a  Vulkan  back-end compositor.\nThe compositor also has two client compositors (one for  OpenGL  applications and another\n    for Vulkan applications) which pass frame data to the back-end compositor.\nILLIXR integration intercepts the frame at GL client compositor and sends it to Switchboard\n    of ILLIXR, which is then used by  timewarp_gl  component .  To get an OpenGL frame and use it without copying pixels, ILLIXR needs to get the user\n    application GL context.\nThis is done at OpenXR session creation time, where ILLIXR is initialized.\nNote that, logically, ILLIXR is initialized during OpenXR instance creation,\n    or is otherwise running in the background all the time.\nCurrently, ILLIXR is initialized at session creation time, since ILLIXR only supports single\n    OpenXR session, and requires a user application GL context upon initialization,  The current ILLIXR integration for Monado is a temporary solution and has some drawbacks caused\n    by the concurrent and continued development from both the Monado and ILLIXR projects.\nThe integration:    Does not use the pose that user application declares to use at rendering\n        (using the OpenXR specification).\n    This is due to incongruencies with Monado's internal interfaces and representations.\n    The pose difference used by  timewarp  is computed using the most recent query\n        for a pose update.    Cannot submit frame data with a depth buffer.    Cannot have poses that make use of  OpenXR Spaces .\n    Raw pose data is instead retrieved from the application's  SLAM  algorithms.    Does not support controller action.    Only supports GL user-space applications.    User-space applications cannot acquire more than one  swap chain  buffer for each eye\n        during the the processing of a frame.    Must initialize ILLIXR during the session initialization.",
            "title": "Monado Integration Dataflow"
        },
        {
            "location": "/releases/",
            "text": "Updating Tags and Documentation\n\n\nUpdating Tags\n\n\n\n\n\n\nGet latest tags:\n\n\n\n\n\ngit pull --tags -f\n\n\n\n\n\n\n\nTag your branch. Please use semantic versioning to name the tag; i.e., \nv<major>.<minor>.<patch>\n:\n\n\n\n\n\ngit tag -f <tag-name> ## `-f` is required if updating an existing tag\n\n\n\n\n\n\n\nPush your tag upstream:\n\n\n\n\n\ngit push origin --tags\n\n\n\n\n\n\n\nUpdating Documentation\n\n\n\n\n\n\nRun \ndoxygen\n from the root directory of the project:\n\n\n\n\n\ndoxygen doxygen.conf\n\n\n\n\n\n\n\nRun \nmkdocs\n to deploy new documentation:\n\n\n\n\n\nmkdocs gh-deploy",
            "title": "Releases"
        },
        {
            "location": "/releases/#updating-tags-and-documentation",
            "text": "",
            "title": "Updating Tags and Documentation"
        },
        {
            "location": "/releases/#updating-tags",
            "text": "Get latest tags:   git pull --tags -f    Tag your branch. Please use semantic versioning to name the tag; i.e.,  v<major>.<minor>.<patch> :   git tag -f <tag-name> ## `-f` is required if updating an existing tag    Push your tag upstream:   git push origin --tags",
            "title": "Updating Tags"
        },
        {
            "location": "/releases/#updating-documentation",
            "text": "Run  doxygen  from the root directory of the project:   doxygen doxygen.conf    Run  mkdocs  to deploy new documentation:   mkdocs gh-deploy",
            "title": "Updating Documentation"
        },
        {
            "location": "/virtualization/",
            "text": "Setting up ILLIXR in QEMU\n\n\nBuild QEMU\n\n\nRun \nILLIXR/install_deps.sh\n and select \nyes\n when asked to install \nQEMU\n.\nThis will build QEMU and install it to \n/opt/ILLIXR\n.\n\n\nWhy build QEMU from source?\n\n\nThe version of QEMU available through package managers doesn't always ship with all\n    the options we need to run ILLIXR, so building QEMU from source is the best option.\nThis \nqemu\n installation will not conflict with existing \nqemu\n installs on your system.\n\n\nSetup Ubuntu in the VM\n\n\nRun \nILLIXR/qemu/run.sh\n to download \nUbuntu 18.04\n, create a virtual hard drive\n    (\nillixr.qcow2\n), and launch \nqemu\n from \n/opt/ILLIXR\n.\n\n\nYour VM image will be created at \nILLIXR/qemu/illixr.qcow2\n.\nUbuntu will be downloaded and saved at \nILLIXR/qemu/ubuntu-18.04.5-desktop-amd64.iso\n.\n\n\nYou will be prompted to install Ubuntu;\n    follow the instructions and install Ubuntu to the virtual hard drive.\n\n\n\n\nChoose the \"erase all\" option and confirm:\n\n\n\n\n\n\nPick any account name and password you like.\n\n\n\n\nOnce Ubuntu is installed you will be asked to reboot.\nClose \nqemu\n and then run \n./run.sh\n again to boot into your brand new Ubuntu install!\n\n\nBooting the VM\n\n\nTo launch the VM from now on, just use \nILLIXR/qemu/run.sh\n.\nThis will boot from the Ubuntu image we created earlier (\nillixr.qcow2\n).\nOnce Ubuntu is installed, it is safe to delete \nubuntu-18.04.5-desktop-amd64.iso\n.\n\n\nSetting up the VM\n\n\nOnce inside the VM, set up and run ILLIXR as found on the \nGetting Started page\n.\n\n\nUninstalling\n\n\nTo delete your local VM, just delete \nILLIXR/qemu/illixr.qcow2\n.\n\n\nILLIXR/qemu/ubuntu-18.04.5-desktop-amd64.iso\n can be deleted anytime you want after Ubuntu\n    is installed to your VM.\n\n\nIf you've deleted \nillixr.qcow2\n, you can run \nrun.sh\n to recreate it and reinstall everything.",
            "title": "Virtualization"
        },
        {
            "location": "/virtualization/#setting-up-illixr-in-qemu",
            "text": "",
            "title": "Setting up ILLIXR in QEMU"
        },
        {
            "location": "/virtualization/#build-qemu",
            "text": "Run  ILLIXR/install_deps.sh  and select  yes  when asked to install  QEMU .\nThis will build QEMU and install it to  /opt/ILLIXR .",
            "title": "Build QEMU"
        },
        {
            "location": "/virtualization/#why-build-qemu-from-source",
            "text": "The version of QEMU available through package managers doesn't always ship with all\n    the options we need to run ILLIXR, so building QEMU from source is the best option.\nThis  qemu  installation will not conflict with existing  qemu  installs on your system.",
            "title": "Why build QEMU from source?"
        },
        {
            "location": "/virtualization/#setup-ubuntu-in-the-vm",
            "text": "Run  ILLIXR/qemu/run.sh  to download  Ubuntu 18.04 , create a virtual hard drive\n    ( illixr.qcow2 ), and launch  qemu  from  /opt/ILLIXR .  Your VM image will be created at  ILLIXR/qemu/illixr.qcow2 .\nUbuntu will be downloaded and saved at  ILLIXR/qemu/ubuntu-18.04.5-desktop-amd64.iso .  You will be prompted to install Ubuntu;\n    follow the instructions and install Ubuntu to the virtual hard drive.   Choose the \"erase all\" option and confirm:    Pick any account name and password you like.   Once Ubuntu is installed you will be asked to reboot.\nClose  qemu  and then run  ./run.sh  again to boot into your brand new Ubuntu install!",
            "title": "Setup Ubuntu in the VM"
        },
        {
            "location": "/virtualization/#booting-the-vm",
            "text": "To launch the VM from now on, just use  ILLIXR/qemu/run.sh .\nThis will boot from the Ubuntu image we created earlier ( illixr.qcow2 ).\nOnce Ubuntu is installed, it is safe to delete  ubuntu-18.04.5-desktop-amd64.iso .",
            "title": "Booting the VM"
        },
        {
            "location": "/virtualization/#setting-up-the-vm",
            "text": "Once inside the VM, set up and run ILLIXR as found on the  Getting Started page .",
            "title": "Setting up the VM"
        },
        {
            "location": "/virtualization/#uninstalling",
            "text": "To delete your local VM, just delete  ILLIXR/qemu/illixr.qcow2 .  ILLIXR/qemu/ubuntu-18.04.5-desktop-amd64.iso  can be deleted anytime you want after Ubuntu\n    is installed to your VM.  If you've deleted  illixr.qcow2 , you can run  run.sh  to recreate it and reinstall everything.",
            "title": "Uninstalling"
        },
        {
            "location": "/writing_your_plugin/",
            "text": "Writing Your Plugin\n\n\nAdding a New Plugin (Common Case)\n\n\nIn the common case, you only need to define a \nMakefile\n with the line \ninclude common/common.mk\n\n    and symlink common (\nln -s ../common common\n).\nThe included recipe file provides the necessary targets and uses the compiler \n$(CXX)\n,\n    which is defined based on the OS and environment variables.\nThe included \nMakefile\n:\n\n\n\n\n\n\nCompiles \nplugin.cpp\n and any other \n*.cpp\n files into the plugin.\n\n\n\n\n\n\nWill invoke a recompile of the target any time any \n*.hpp\n or \n*.cpp\n file changes.\n\n\n\n\n\n\nCompiles with C++17.\n    You can change this in your plugin by defining\n        \nSTDCXX = ...\n before the \ninclude\n.\n    This change will not affect other plugins; just yours.\n\n\n\n\n\n\nAccepts specifying libraries by appending to \nLDFLAGS\n and \nCFLAGS\n.\n    For example:\n\n\n\n\n\nLDFLAGS := $(LDFLAGS) $(shell pkg-config --ldflags eigen3)\nCFLAGS  := $(CFLAGS) $(shell pkg-config --cflags eigen3)\n\n\n\nSee the source for the other flags and variables that you can set.\n\n\n\n\n\n\nFinally, place the path of your plugin directory in the \nplugin_group\n list\n    for the configuration you would like to run (e.g. \nILLIXR/configs/native.yaml\n).\n\n\nAdding a New Plugin (General Case)\n\n\nEach plugin can have a completely independent build system, as long as:\n\n\n\n\n\n\nIt defines a \nMakefile\n with targets for \nplugin.dbg.so\n, \nplugin.opt.so\n, and \nclean\n.\n    Inside this \nMakefile\n, one can defer to another build system.\n\n\n\n\n\n\nIts compiler maintains \nABI compatibility\n with the compilers used in every other plugin.\n    Using the same version of Clang or GCC on the same architecture is sufficient for this.\n\n\n\n\n\n\nIts path is in the \nplugin_group\n list for the configuration you would like\n        to run (e.g. \nILLIXR/configs/native.yaml\n).\n\n\n\n\n\n\nTutorial\n\n\nYou can extend ILLIXR for your own purposes.\nTo add your own functionality via the plugin interface:\n\n\n\n\n\n\nCreate a new directory anywhere for your new plugin and set it up for ILLIXR.\n    We recommend you also push this plugin to a git repository on Github/Gitlab if you want it\n        as a part of upstream ILLIXR in the future.\n\n\n\n\n\n\nCreate a \nMakefile\n with the following contents.\n    See \nBuilding ILLIXR\n for more details and alternative setups.\n\n\n\n\n\ninclude common/common.mk\n\n\n\n\n\n\n\n\n\n\n\nYou must decide if your plugin should inherit the standardized \nthreadloop\n\n        or \nplugin\n.\n\n\n\n\n\n\nIf your plugin just needs to run one computation repeatedly, then your\n        plugin class should extend \nthreadloop\n. Your code goes in\n        \n_p_one_iteration\n, which gets called in a hot loop. \nthreadloop\n\n        inherits from plugin, but adds threading functionality. If you don't\n        use \n_p_one_iteration\n, inheriting from \nthreadloop\n is superfluous;\n        Inherit from plugin directly instead.\n\n\n\n\n\n\nIf you need custom concurrency (more complicated than a loop), triggered\n        concurrency (by events fired in other plugins), or no concurrency\n        then your plugin class should extend \nplugin\n. Your code goes\n        in the \nstart\n method.\n\n\n\n\n\n\nIf you want to schedule data-driven work in either case, call\n  \nsb->schedule(...)\n.\n\n\n\n\n\n\nIf you spin your own threads, they \nmust\n wait for\n      \npb->lookup_impl<Stoplight>()->wait_for_ready()\n the first time they\n      run. This allows the start of all threads in ILLIXR to be\n      synchronized.\n\n\n\n\n\n\nThey \nmust\n be joined-or-disowned at-or-before\n      \nplugin::stop()\n. This allows ILLIXR to shutdown cleanly.\n\n\n\n\n\n\n\n\n\n\nWrite a file called \nplugin.cpp\n with this body, replacing every instance of \nplugin_name\n:\n\n\n\n\n\n/// A minimal/no-op ILLIXR plugin\n\n#include \"common/phonebook.hpp\"\n#include \"common/plugin.hpp\"\n#include \"common/threadloop.hpp\"\n#include <chrono>\n#include <thread>\n\nusing namespace ILLIXR;\n\n/// Inherit from plugin if you don't need the threadloop\n/// Inherit from threadloop to provide a new thread to perform the task\nclass basic_plugin : public threadloop {\npublic:\n    basic_plugin(std::string name_, phonebook* pb_)\n        : threadloop{name_, pb_}\n    {\n        std::cout << \"Constructing basic_plugin.\" << std::endl;\n    }\n\n    /// Note the virtual.\n    virtual ~basic_plugin() override {\n        std::cout << \"Deconstructing basic_plugin.\" << std::endl;\n    }\n\n    /// For `threadloop` style plugins, do not override the start() method unless you know what you're doing!\n    /// _p_one_iteration() is called in a thread created by threadloop::start()\n    void _p_one_iteration() override {\n        std::cout << \"This goes to the log when `log` is set in the config.\" << std::endl;\n        std::cerr << \"This goes to the console.\" << std::endl;\n        std::this_thread::sleep_for(std::chrono::milliseconds{100});\n    }\n\n};\n\n/// This line makes the plugin importable by Spindle\nPLUGIN_MAIN(basic_plugin);\n\n\n\n\n\n\n\nAt this point, you should be able to build your plugin with ILLIXR.\n    Move to the ILLIXR repo and update \nconfigs/native.yaml\n.\n    If the new plugin is the same type as one of the other components you will need to\n        remove that component from the config before running the new component.\n    For example, if the new component is a SLAM then the old SLAM needs to be removed from\n        the config.\n    See \nBuilding ILLIXR\n for more details on the config file.\n\n\n\n\n\nplugin_groups:\n  - !include \"rt_slam_plugins.yaml\"\n  - !include \"core_plugins.yaml\"\n  - plugin_group:\n     - path: /PATH/TO/NEW/PLUGIN\n     - path: ground_truth_slam/\n     - path: gldemo/\n     - path: debugview/\n\ndata:\n  subpath: mav0\n  relative_to:\n  archive_path:\n  download_url: 'http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_medium/V1_02_medium.zip'\n  demo_data: demo_data/\n  loader:\n    name: native\n    # command: gdb -q --args %a\n    profile: opt\n\n\n\n\n\n\n\nFinally, run ILLIXR with your new plugin with the following command:\n\n\n\n\n\n./runner.sh configs/native.yaml\n\n\n\n\n\n\n\nThis is all that is required to be a plugin which can be loaded by Spindle in\n        the ILLIXR runtime.\n    Reading and writing from Phonebook and Switchboard is optional,\n        but nearly every plugin does it.\n    See \ndefault_plugins.md\n for more details.\n\n\nFirst, we can query the \nphonebook\n to get various services\n    including \nswitchboard\n.\nThen we query \nswitchboard\n for event-streams (topics).\nWe will read \ntopic1\n, write to \ntopic2\n, and schedule computation on \ntopic 3\n.\nSee the API documentation for \nphonebook\n and \nswitchboard\n for more details.\n\n\n\n\n\n#include \"common/phonebook.hpp\"\n#include \"common/plugin.hpp\"\n#include \"common/threadloop.hpp\"\n\n/* When datatypes have to be common across plugins\n *     (e.g. a phonebook service or switchboard topic),\n *      they are defined in this header,\n *      which is accessible to all plugins.\n */\n#include \"common/data_format.hpp\"\n\nclass plugin_name : public threadloop {\npublic:\n    /* After the constructor, C++ permits a list of member-constructors.\n     * We use uniform initialization (curly-braces) [1] instead of parens to\n     *     avoid ambiguity [2].\n     * We put the comma at the start of the line, so that lines can be copied around\n     *     or deleted freely (except for the first).\n     *\n     * [1]: https://en.wikipedia.org/wiki/C%2B%2B11#Uniform_initialization\n     * [2]: https://en.wikipedia.org/wiki/Most_vexing_parse\n     */\n    plugin_name(std::string name_, phonebook* pb_)\n        : threadloop{name_, pb_}\n          /// Find the switchboard in phonebook\n        , sb{pb->lookup_impl<switchboard>()}\n          /// Create a handle to a topic in switchboard for subscribing\n        , topic1{sb->get_reader<topic1_type>(\"topic1\")}\n          /// Create a handle to a topic in switchboard for publishing\n        , topic2{sb->get_writer<topic2_type>(\"topic2\")}\n    {\n        /// Read topic 1\n        switchboard::ptr<const topic1_type> event1 = topic1.get_ro();\n\n        /// Write to topic 2\n        topic2.put(\n            topic2.allocate<topic2_type>(\n                arg_1, // topic2_type::topic2_type() arg_type_1\n                ...,   // ...\n                arg_k  // topic2_type::topic2_type() arg_type_k\n            )\n        );\n\n        /// Read topic 3 synchronously\n        sb->schedule<topic3_type>(\n            get_name(),\n            \"topic3\",\n            [&](switchboard::ptr<const topic3_type> event3, std::size_t) {\n                /* This is a [lambda expression][1]\n                 *\n                 * [1]: https://en.cppreference.com/w/cpp/language/lambda\n                 */\n                std::cout << \"Got a new event on topic3: \" << event3 << std::endl;\n                callback(event3);\n            }\n        );\n    }\n\n    virtual void _p_one_iteration override() {\n        std::cout << \"Running\" << std::endl;\n        auto target = std::chrono::system_clock::now()\n                    + std::chrono::milliseconds{10};\n        reliable_sleep(target);\n    }\n\nprivate:\n    const std::shared_ptr<switchboard> sb;\n    switchboard::reader<topic1_type> topic1;\n    switchboard::writer<topic2> topic2;\n};\n\n/// This line makes the plugin importable by Spindle\nPLUGIN_MAIN(plugin_name);",
            "title": "Writing your plugin"
        },
        {
            "location": "/writing_your_plugin/#writing-your-plugin",
            "text": "",
            "title": "Writing Your Plugin"
        },
        {
            "location": "/writing_your_plugin/#adding-a-new-plugin-common-case",
            "text": "In the common case, you only need to define a  Makefile  with the line  include common/common.mk \n    and symlink common ( ln -s ../common common ).\nThe included recipe file provides the necessary targets and uses the compiler  $(CXX) ,\n    which is defined based on the OS and environment variables.\nThe included  Makefile :    Compiles  plugin.cpp  and any other  *.cpp  files into the plugin.    Will invoke a recompile of the target any time any  *.hpp  or  *.cpp  file changes.    Compiles with C++17.\n    You can change this in your plugin by defining\n         STDCXX = ...  before the  include .\n    This change will not affect other plugins; just yours.    Accepts specifying libraries by appending to  LDFLAGS  and  CFLAGS .\n    For example:   LDFLAGS := $(LDFLAGS) $(shell pkg-config --ldflags eigen3)\nCFLAGS  := $(CFLAGS) $(shell pkg-config --cflags eigen3)  See the source for the other flags and variables that you can set.    Finally, place the path of your plugin directory in the  plugin_group  list\n    for the configuration you would like to run (e.g.  ILLIXR/configs/native.yaml ).",
            "title": "Adding a New Plugin (Common Case)"
        },
        {
            "location": "/writing_your_plugin/#adding-a-new-plugin-general-case",
            "text": "Each plugin can have a completely independent build system, as long as:    It defines a  Makefile  with targets for  plugin.dbg.so ,  plugin.opt.so , and  clean .\n    Inside this  Makefile , one can defer to another build system.    Its compiler maintains  ABI compatibility  with the compilers used in every other plugin.\n    Using the same version of Clang or GCC on the same architecture is sufficient for this.    Its path is in the  plugin_group  list for the configuration you would like\n        to run (e.g.  ILLIXR/configs/native.yaml ).",
            "title": "Adding a New Plugin (General Case)"
        },
        {
            "location": "/writing_your_plugin/#tutorial",
            "text": "You can extend ILLIXR for your own purposes.\nTo add your own functionality via the plugin interface:    Create a new directory anywhere for your new plugin and set it up for ILLIXR.\n    We recommend you also push this plugin to a git repository on Github/Gitlab if you want it\n        as a part of upstream ILLIXR in the future.    Create a  Makefile  with the following contents.\n    See  Building ILLIXR  for more details and alternative setups.   include common/common.mk      You must decide if your plugin should inherit the standardized  threadloop \n        or  plugin .    If your plugin just needs to run one computation repeatedly, then your\n        plugin class should extend  threadloop . Your code goes in\n         _p_one_iteration , which gets called in a hot loop.  threadloop \n        inherits from plugin, but adds threading functionality. If you don't\n        use  _p_one_iteration , inheriting from  threadloop  is superfluous;\n        Inherit from plugin directly instead.    If you need custom concurrency (more complicated than a loop), triggered\n        concurrency (by events fired in other plugins), or no concurrency\n        then your plugin class should extend  plugin . Your code goes\n        in the  start  method.    If you want to schedule data-driven work in either case, call\n   sb->schedule(...) .    If you spin your own threads, they  must  wait for\n       pb->lookup_impl<Stoplight>()->wait_for_ready()  the first time they\n      run. This allows the start of all threads in ILLIXR to be\n      synchronized.    They  must  be joined-or-disowned at-or-before\n       plugin::stop() . This allows ILLIXR to shutdown cleanly.      Write a file called  plugin.cpp  with this body, replacing every instance of  plugin_name :   /// A minimal/no-op ILLIXR plugin\n\n#include \"common/phonebook.hpp\"\n#include \"common/plugin.hpp\"\n#include \"common/threadloop.hpp\"\n#include <chrono>\n#include <thread>\n\nusing namespace ILLIXR;\n\n/// Inherit from plugin if you don't need the threadloop\n/// Inherit from threadloop to provide a new thread to perform the task\nclass basic_plugin : public threadloop {\npublic:\n    basic_plugin(std::string name_, phonebook* pb_)\n        : threadloop{name_, pb_}\n    {\n        std::cout << \"Constructing basic_plugin.\" << std::endl;\n    }\n\n    /// Note the virtual.\n    virtual ~basic_plugin() override {\n        std::cout << \"Deconstructing basic_plugin.\" << std::endl;\n    }\n\n    /// For `threadloop` style plugins, do not override the start() method unless you know what you're doing!\n    /// _p_one_iteration() is called in a thread created by threadloop::start()\n    void _p_one_iteration() override {\n        std::cout << \"This goes to the log when `log` is set in the config.\" << std::endl;\n        std::cerr << \"This goes to the console.\" << std::endl;\n        std::this_thread::sleep_for(std::chrono::milliseconds{100});\n    }\n\n};\n\n/// This line makes the plugin importable by Spindle\nPLUGIN_MAIN(basic_plugin);    At this point, you should be able to build your plugin with ILLIXR.\n    Move to the ILLIXR repo and update  configs/native.yaml .\n    If the new plugin is the same type as one of the other components you will need to\n        remove that component from the config before running the new component.\n    For example, if the new component is a SLAM then the old SLAM needs to be removed from\n        the config.\n    See  Building ILLIXR  for more details on the config file.   plugin_groups:\n  - !include \"rt_slam_plugins.yaml\"\n  - !include \"core_plugins.yaml\"\n  - plugin_group:\n     - path: /PATH/TO/NEW/PLUGIN\n     - path: ground_truth_slam/\n     - path: gldemo/\n     - path: debugview/\n\ndata:\n  subpath: mav0\n  relative_to:\n  archive_path:\n  download_url: 'http://robotics.ethz.ch/~asl-datasets/ijrr_euroc_mav_dataset/vicon_room1/V1_02_medium/V1_02_medium.zip'\n  demo_data: demo_data/\n  loader:\n    name: native\n    # command: gdb -q --args %a\n    profile: opt    Finally, run ILLIXR with your new plugin with the following command:   ./runner.sh configs/native.yaml    This is all that is required to be a plugin which can be loaded by Spindle in\n        the ILLIXR runtime.\n    Reading and writing from Phonebook and Switchboard is optional,\n        but nearly every plugin does it.\n    See  default_plugins.md  for more details.  First, we can query the  phonebook  to get various services\n    including  switchboard .\nThen we query  switchboard  for event-streams (topics).\nWe will read  topic1 , write to  topic2 , and schedule computation on  topic 3 .\nSee the API documentation for  phonebook  and  switchboard  for more details.   #include \"common/phonebook.hpp\"\n#include \"common/plugin.hpp\"\n#include \"common/threadloop.hpp\"\n\n/* When datatypes have to be common across plugins\n *     (e.g. a phonebook service or switchboard topic),\n *      they are defined in this header,\n *      which is accessible to all plugins.\n */\n#include \"common/data_format.hpp\"\n\nclass plugin_name : public threadloop {\npublic:\n    /* After the constructor, C++ permits a list of member-constructors.\n     * We use uniform initialization (curly-braces) [1] instead of parens to\n     *     avoid ambiguity [2].\n     * We put the comma at the start of the line, so that lines can be copied around\n     *     or deleted freely (except for the first).\n     *\n     * [1]: https://en.wikipedia.org/wiki/C%2B%2B11#Uniform_initialization\n     * [2]: https://en.wikipedia.org/wiki/Most_vexing_parse\n     */\n    plugin_name(std::string name_, phonebook* pb_)\n        : threadloop{name_, pb_}\n          /// Find the switchboard in phonebook\n        , sb{pb->lookup_impl<switchboard>()}\n          /// Create a handle to a topic in switchboard for subscribing\n        , topic1{sb->get_reader<topic1_type>(\"topic1\")}\n          /// Create a handle to a topic in switchboard for publishing\n        , topic2{sb->get_writer<topic2_type>(\"topic2\")}\n    {\n        /// Read topic 1\n        switchboard::ptr<const topic1_type> event1 = topic1.get_ro();\n\n        /// Write to topic 2\n        topic2.put(\n            topic2.allocate<topic2_type>(\n                arg_1, // topic2_type::topic2_type() arg_type_1\n                ...,   // ...\n                arg_k  // topic2_type::topic2_type() arg_type_k\n            )\n        );\n\n        /// Read topic 3 synchronously\n        sb->schedule<topic3_type>(\n            get_name(),\n            \"topic3\",\n            [&](switchboard::ptr<const topic3_type> event3, std::size_t) {\n                /* This is a [lambda expression][1]\n                 *\n                 * [1]: https://en.cppreference.com/w/cpp/language/lambda\n                 */\n                std::cout << \"Got a new event on topic3: \" << event3 << std::endl;\n                callback(event3);\n            }\n        );\n    }\n\n    virtual void _p_one_iteration override() {\n        std::cout << \"Running\" << std::endl;\n        auto target = std::chrono::system_clock::now()\n                    + std::chrono::milliseconds{10};\n        reliable_sleep(target);\n    }\n\nprivate:\n    const std::shared_ptr<switchboard> sb;\n    switchboard::reader<topic1_type> topic1;\n    switchboard::writer<topic2> topic2;\n};\n\n/// This line makes the plugin importable by Spindle\nPLUGIN_MAIN(plugin_name);",
            "title": "Tutorial"
        },
        {
            "location": "/legacy/v1/README-audio/",
            "text": "Audio Pipeline\n\n\nPart of \nILLIXR\n, the Illinios Extended Reality Benchmark Suite.\nThe audio pipeline is responsible for both recording and playing back spatialized audio for XR.\n\n\nBuild\n\n\nThis version simplifies the build process to automate building of both libspatialaudio\n    and audio pipeline itself.\nIf you have a old version of this module and updating to the new version doesn't build correctly,\n    you may need to purge the old module and clone this new version again.\n\n\nBuild debug:\n\n\nmake\n\n\n\n\nor\n\n\nmake solo.dbg\n\n\n\n\nBuild release:\n\n\nmake solo.opt\n\n\n\n\nIf you are switching between builds, please do \nmake deepclean\n\n\nAlso note that release build (-O3) would show great performance improvement over debug build.\n\n\nUsage\n\n\n./solo.dbg <number of 1024-sample-block to process> <optional: decode/encode>\n\n\n\n\n\nNumber of blocks to process is a required parameter.\n\n\nDecode/encode specifies the different audio processing procedures to take on,\n        which is specificially designed for profiling.\n    No output would be generated.\n\n\n\n\nIf encode or decode is not specified, the code will do both encode and decode\n    on preset input sound sample files and generate a spatialized output audio at \noutput.wav\n.\n\n\nExample:\n\n\n./solo.dbg 500\n\n\n\nThis will generate a ~10 seconds spatialized audio output from two sound samples under \n./sample/\n\n\n./solo.dbg 2000 encode\n\n\n\nThis will encode 2000 sample blocks of audio input into ambisonics format.\n\n\nNotes\n\n\nThe input and output are hardcoded to be 48000 sample rate, 16-bit PCM wav file.\n\n\nAlso if you want to hear the output sound, limit the process sample blocks so that\n    the output is not longer than input!\nOtherwise, garbage sound samples would be generated.\n\n\nComponents\n\n\nlibspatialaudio\n\n\nSubmodule libspatialaudio provides the backend library for\n    Ambisonics encoding,\n    decoding,\n    rotation,\n    zoom,\n    and\n    binauralizer (HRTF included).\n\n\naudio pipeline code\n\n\nsound.cpp\n\n\nDescribes a sound source in the ambisonics sound-field,\n    including the input file for the sound source and its position in the sound-field.\n\n\naudio.cpp\n\n\nEncapsulate preset processing steps of\n    sound source reading,\n    encoding,\n    rotating,\n    zooming,\n    and\n    decoding.\n\n\nLicense\n\n\nThis code is available under the University of Illinois/NCSA Open Source License.\nThe sound samples provided in ./sample/ are available under the Creative Commons 0 license.",
            "title": "README audio"
        },
        {
            "location": "/legacy/v1/README-audio/#audio-pipeline",
            "text": "Part of  ILLIXR , the Illinios Extended Reality Benchmark Suite.\nThe audio pipeline is responsible for both recording and playing back spatialized audio for XR.",
            "title": "Audio Pipeline"
        },
        {
            "location": "/legacy/v1/README-audio/#build",
            "text": "This version simplifies the build process to automate building of both libspatialaudio\n    and audio pipeline itself.\nIf you have a old version of this module and updating to the new version doesn't build correctly,\n    you may need to purge the old module and clone this new version again.  Build debug:  make  or  make solo.dbg  Build release:  make solo.opt  If you are switching between builds, please do  make deepclean  Also note that release build (-O3) would show great performance improvement over debug build.",
            "title": "Build"
        },
        {
            "location": "/legacy/v1/README-audio/#usage",
            "text": "./solo.dbg <number of 1024-sample-block to process> <optional: decode/encode>   Number of blocks to process is a required parameter.  Decode/encode specifies the different audio processing procedures to take on,\n        which is specificially designed for profiling.\n    No output would be generated.   If encode or decode is not specified, the code will do both encode and decode\n    on preset input sound sample files and generate a spatialized output audio at  output.wav .",
            "title": "Usage"
        },
        {
            "location": "/legacy/v1/README-audio/#example",
            "text": "./solo.dbg 500  This will generate a ~10 seconds spatialized audio output from two sound samples under  ./sample/  ./solo.dbg 2000 encode  This will encode 2000 sample blocks of audio input into ambisonics format.",
            "title": "Example:"
        },
        {
            "location": "/legacy/v1/README-audio/#notes",
            "text": "The input and output are hardcoded to be 48000 sample rate, 16-bit PCM wav file.  Also if you want to hear the output sound, limit the process sample blocks so that\n    the output is not longer than input!\nOtherwise, garbage sound samples would be generated.",
            "title": "Notes"
        },
        {
            "location": "/legacy/v1/README-audio/#components",
            "text": "",
            "title": "Components"
        },
        {
            "location": "/legacy/v1/README-audio/#libspatialaudio",
            "text": "Submodule libspatialaudio provides the backend library for\n    Ambisonics encoding,\n    decoding,\n    rotation,\n    zoom,\n    and\n    binauralizer (HRTF included).",
            "title": "libspatialaudio"
        },
        {
            "location": "/legacy/v1/README-audio/#audio-pipeline-code",
            "text": "",
            "title": "audio pipeline code"
        },
        {
            "location": "/legacy/v1/README-audio/#soundcpp",
            "text": "Describes a sound source in the ambisonics sound-field,\n    including the input file for the sound source and its position in the sound-field.",
            "title": "sound.cpp"
        },
        {
            "location": "/legacy/v1/README-audio/#audiocpp",
            "text": "Encapsulate preset processing steps of\n    sound source reading,\n    encoding,\n    rotating,\n    zooming,\n    and\n    decoding.",
            "title": "audio.cpp"
        },
        {
            "location": "/legacy/v1/README-audio/#license",
            "text": "This code is available under the University of Illinois/NCSA Open Source License.\nThe sound samples provided in ./sample/ are available under the Creative Commons 0 license.",
            "title": "License"
        },
        {
            "location": "/legacy/v1/README-efusion/",
            "text": "ElasticFusion\n\n\nReal-time dense visual SLAM system capable of capturing comprehensive dense\n    globally consistent surfel-based maps of room scale environments explored using\n    an RGB-D camera.\n\n\nPart of \nILLIXR\n, the Illinios Extended Reality Benchmark Suite.\nThis version of ElasticFusion has been modified to enable fast odometry and disable the GUI.\n\nPlease use the following command to replicate the results from the paper:\n\n\n./ElasticFusion -l dyson_lab.klg -fo -nso -sc -q\n\n\n\n\nThe description of each flag is provided in \"How Do I Use It?\" below.\n\n\nRelated Publications\n\n\nPlease cite this work if you make use of our system in any of your own endeavors:\n\n\n\n\nElasticFusion: Real-Time Dense SLAM and Light Source Estimation\n,\n        \nT. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison and S. Leutenegger\n, IJRR '16\n\n\nElasticFusion: Dense SLAM Without A Pose Graph\n,\n        \nT. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker and A. J. Davison\n, RSS '15\n\n\n\n\n1. What do I need to build it?\n\n\n1.1. Ubuntu\n\n\n\n\nUbuntu 14.04, 15.04 or 16.04 (Though many other linux distros will work fine)\n\n\nCMake\n\n\nOpenGL\n\n\nCUDA >= 7.0\n\n\nOpenNI2\n\n\nSuiteSparse\n\n\nEigen\n\n\nzlib\n\n\nlibjpeg\n\n\nPangolin\n\n\nlibrealsense\n - Optional (for Intel RealSense cameras)\n\n\n\n\nFirstly, add \nnVidia's official CUDA repository\n to your apt sources,\n    then run the following command to pull in most dependencies from the official repos:\n\n\nsudo apt-get install -y cmake-qt-gui git build-essential libusb-1.0-0-dev libudev-dev openjdk-7-jdk freeglut3-dev libglew-dev cuda-7-5 libsuitesparse-dev libeigen3-dev zlib1g-dev libjpeg-dev\n\n\n\n\nAfterwards install \nOpenNI2\n and \nPangolin\n from source.\nNote, you may need to manually tell CMake where OpenNI2 is since Occipital's fork does not\n    have an install option.\nIt is important to build Pangolin last so that it can find some of the libraries it has\n    optional dependencies on. \n\n\nWhen you have all of the dependencies installed, build the Core followed by the GUI. \n\n\n1.2. Windows - Visual Studio\n\n\n\n\nWindows 7/10 with Visual Studio 2013 Update 5 (Though other configurations may work)\n\n\nCMake\n\n\nOpenGL\n\n\nCUDA >= 7.0\n\n\nOpenNI2\n\n\nSuiteSparse\n\n\nEigen\n\n\nPangolin\n\n\nzlib (Pangolin can automatically download and build this)\n\n\nlibjpeg (Pangolin can automatically download and build this)\n\n\n\n\n\n\nlibrealsense\n - Optional (for Intel RealSense cameras)\n\n\n\n\nFirstly install cmake and cuda.\nThen download and build from source OpenNI2, SuiteSparse.\nNext download Eigen (no need to build it since it is a header-only library).\nThen download and build from source Pangolin but pay attention to the following cmake settings. \nThere will be a lot of dependencies where path was not found.\nThat is OK except OPENNI2 and EIGEN3 (those should be set to valid paths).\nYou also need to set MSVC_USE_STATIC_CRT to false in order to correctly link\n    to ElasticFusion projects.\nAlso, you can set BUILD_EXAMPLES to false since we don't need them and some were crashing\n    on my machine.\n\n\nFinally, build Core and GUI.\n\n\n2. Is there an easier way to build it?\n\n\nYes, if you run the \nbuild.sh\n script on a fresh clean install\n    of Ubuntu 14.04, 15.04, or 16.04, enter your password for sudo a few times and wait\n    a few minutes all dependencies will get downloaded and installed and\n    it should build everything correctly.\nThis has not been tested on anything but fresh installs, so I would advise using it\n    with caution if you already have some of the dependencies installed.\n\n\n3. Installation issues\n\n\n#include <Eigen/Core>\n not found\n\n\nsudo ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen\nsudo ln -sf /usr/include/eigen3/unsupported /usr/include/unsupported\n\n\n\n\ninvalid use of incomplete type \u2018const struct Eigen ...\n\n\nPangolin must be installed AFTER all the other libraries to make use of optional dependencies.\n\n\nGLSL 3.30 is not supported.\nSupported versions are 1.10, 1.20, 1.30, 1.00 ES and 3.00 ES\n\n\nMake sure you are running ElasticFusion on your nVidia GPU.\nIn particular, if you have an Optimus GPU\n-   If you use Prime, follow instructions \nhere\n\n-   If you use Bumblebee, remember to run as \noptirun ./ElasticFusion\n\n\n4. How do I use it?\n\n\nThere are three subprojects in the repo:\n\n\n\n\nThe \nCore\n is the main engine which builds into a shared library that you can link\n        into other projects and treat like an API. \n\n\nThe \nGUI\n is the graphical interface used to run the system on either live sensor data\n        or a logged data file. \n\n\nThe \nGPUTest\n is a small benchmarking program you can use to tune\n        the CUDA kernel launch parameters used in the main engine. \n\n\n\n\nThe GUI (\nElasticFusion\n) can take a bunch of parameters when launching it from the command line.\nThey are as follows:\n\n\n\n\n-cal \n : Loads a camera calibration file specified as \nfx fy cx cy\n.\n\n\n-l \n : Processes the specified .klg log file.\n\n\n-p \n : Loads ground truth poses to use instead of estimated pose.\n\n\n-c \n : Surfel confidence threshold (default \n10\n).\n\n\n-d \n : Cutoff distance for depth processing (default \n3\nm).\n\n\n-i \n : Relative ICP/RGB tracking weight (default \n10\n).\n\n\n-ie \n : Local loop closure residual threshold (default \n5e-05\n).\n\n\n-ic \n : Local loop closure inlier threshold (default \n35000\n).\n\n\n-cv \n : Local loop closure covariance threshold (default \n1e-05\n).\n\n\n-pt \n : Global loop closure photometric threshold (default \n115\n).\n\n\n-ft \n : Fern encoding threshold (default \n0.3095\n).\n\n\n-t \n : Time window length (default \n200\n).\n\n\n-s \n : Frames to skip at start of log.\n\n\n-e \n : Cut off frame of log.\n\n\n-f\n : Flip RGB/BGR.\n\n\n-icl\n : Enable this if using the \nICL-NUIM\n dataset\n        (flips normals to account for negative focal length on that data).\n\n\n-o\n : Open loop mode.\n\n\n-rl\n : Enable relocalisation.\n\n\n-fs\n : Frame skip if processing a log to simulate real-time.\n\n\n-q\n : Quit when finished a log.\n\n\n-fo\n : Fast odometry (single level pyramid).\n\n\n-nso\n : Disables SO(3) pre-alignment in tracking.\n\n\n-r\n : Rewind and loop log forever. \n\n\n-ftf\n : Do frame-to-frame RGB tracking. \n\n\n-sc\n : Showcase mode (minimal GUI).\n\n\n\n\nEssentially by default \n./ElasticFusion\n will try run off an attached ASUS sensor live.\nYou can provide a .klg log file instead with the -l parameter. \nYou can capture .klg format logs using either \nLogger1\n or \nLogger2\n.\n\n\n5. How do I just use the Core API?\n\n\nThe libefusion.so shared library which gets built by the Core is what you want to link against.\n\n\nAn example of this can be seen in the GUI code.\nEssentially all you need to do is utilise the provided Findefusion.cmake file in GUI/src\n    and include the following in your CMakeLists.txt file:\n\n\nfind_package(efusion REQUIRED)\ninclude_directories(${EFUSION_INCLUDE_DIR})\ntarget_link_libraries(MyProject ${EFUSION_LIBRARY})\n\n\n\nTo then use the Core API, make sure to include the header file in your source file:\n\n\n    #include <ElasticFusion.h>\n\n\n\n\nInitialise the static configuration parameters once somewhere at the start of your program\n    (this \nsmells\n, but whatever):\n\n\n    Resolution::getInstance(640, 480);\n    Intrinsics::getInstance(528, 528, 320, 240);\n\n\n\n\nCreate an OpenGL context before creating an ElasticFusion object,\n    as ElasticFusion uses OpenGL internally.\nYou can do this whatever way you wish, using Pangolin is probably easiest given it's a dependency:\n\n\n    pangolin::Params windowParams;\n    windowParams.Set(\"SAMPLE_BUFFERS\", 0);\n    windowParams.Set(\"SAMPLES\", 0);\n    pangolin::CreateWindowAndBind(\"Main\", 1280, 800, windowParams);\n\n\n\n\nMake an ElasticFusion object and start using it:\n\n\n    ElasticFusion eFusion;\n    eFusion.processFrame(rgb, depth, timestamp, currentPose, weightMultiplier);\n\n\n\n\nSee the source code of MainController.cpp in the GUI source to see more usage.\n\n\n6. Datasets\n\n\nWe have provided a sample dataset which you can run easily with ElasticFusion\n    for download \nhere\n.\nLaunch it as follows:\n\n\n./ElasticFusion -l dyson_lab.klg\n\n\n\n\n7. License\n\n\nElasticFusion is freely available for non-commercial use only.\nFull terms and conditions which govern its use are detailed \nhere\n and in the LICENSE.txt file.\n\n\n8. FAQ\n\n\nWhat are the hardware requirements?\n\n\nA \nvery fast nVidia GPU (3.5TFLOPS+)\n, and a fast CPU (something like an i7).\nIf you want to use a non-nVidia GPU you can rewrite the tracking code or substitute it\n    with something else, as the rest of the pipeline is actually written in\n    the OpenGL Shading Language. \n\n\nHow can I get performance statistics?\n\n\nDownload \nStopwatch\n and run \nStopwatchViewer\n at the same time as ElasticFusion. \n\n\nI ran a large dataset and got assert(graph.size() / 16 < MAX_NODES) failed\n\n\nCurrently there's a limit on the number of nodes in the deformation graph down to lazy coding\n    (using a really wide texture instead of a proper 2D one).\nSo we're bound by the maximum dimension of a texture, which is 16384 on modern cards/OpenGL.\nEither fix the code so this isn't a problem any more, or increase the modulo factor\n    in \nShaders/sample.geom\n. \n\n\nI have a nice new laptop with a good GPU but it's still slow\n\n\nIf your laptop is running on battery power the GPU will throttle down to save power,\n    so that's unlikely to work (as an aside, \nKintinuous\n will run at 30Hz on\n    a modern laptop on battery power these days).\nYou can try disabling SO(3) pre-alignment, enabling fast odometry,\n    only using either ICP or RGB tracking and not both, running in open loop mode\n    or disabling the tracking pyramid.\nAll of these will cost you accuracy. \n\n\nI saved a map, how can I view it?\n\n\nDownload \nMeshlab\n. Select Render->Shaders->Splatting. \n\n\nThe map keeps getting corrupted - tracking is failing - loop closures\n    are incorrect/not working\n\n\nFirstly, if you're running live and not processing a log file, ensure you're hitting 30Hz,\n    this is important.\nSecondly, you cannot move the sensor extremely fast because this violates\n    the assumption behind projective data association.\nIn addition to this, you're probably using a primesense, which means you're suffering\n    from motion blur, unsynchronised cameras and rolling shutter.\nAll of these are aggravated by fast motion and hinder tracking performance. \n\n\nIf you're not getting loop closures and expecting some, pay attention to\n    the inlier and residual graphs in the bottom right, these are an indicator of how closae\n    you are to a local loop closure.\nFor global loop closures, you're depending on \nfern keyframe encoding\n to save you,\n    which like all appearance-based place recognition methods, has its limitations. \n\n\nIs there a ROS bridge/node?\n\n\nNo.\nThe system relies on an extremely fast and tight coupling between the mapping and tracking\n    on the GPU, which I don't believe ROS supports natively in terms of message passing. \n\n\nThis doesn't seem to work like it did in the videos/papers\n\n\nA substantial amount of refactoring was carried out in order to open source this system,\n    including rewriting a lot of functionality to avoid certain licenses and reduce dependencies.\nAlthough great care was taken during this process, it is possible that\n    performance regressions were introduced and have not yet been discovered.",
            "title": "README efusion"
        },
        {
            "location": "/legacy/v1/README-efusion/#elasticfusion",
            "text": "Real-time dense visual SLAM system capable of capturing comprehensive dense\n    globally consistent surfel-based maps of room scale environments explored using\n    an RGB-D camera.  Part of  ILLIXR , the Illinios Extended Reality Benchmark Suite.\nThis version of ElasticFusion has been modified to enable fast odometry and disable the GUI. \nPlease use the following command to replicate the results from the paper:  ./ElasticFusion -l dyson_lab.klg -fo -nso -sc -q  The description of each flag is provided in \"How Do I Use It?\" below.",
            "title": "ElasticFusion"
        },
        {
            "location": "/legacy/v1/README-efusion/#related-publications",
            "text": "Please cite this work if you make use of our system in any of your own endeavors:   ElasticFusion: Real-Time Dense SLAM and Light Source Estimation ,\n         T. Whelan, R. F. Salas-Moreno, B. Glocker, A. J. Davison and S. Leutenegger , IJRR '16  ElasticFusion: Dense SLAM Without A Pose Graph ,\n         T. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker and A. J. Davison , RSS '15",
            "title": "Related Publications"
        },
        {
            "location": "/legacy/v1/README-efusion/#1-what-do-i-need-to-build-it",
            "text": "",
            "title": "1. What do I need to build it?"
        },
        {
            "location": "/legacy/v1/README-efusion/#11-ubuntu",
            "text": "Ubuntu 14.04, 15.04 or 16.04 (Though many other linux distros will work fine)  CMake  OpenGL  CUDA >= 7.0  OpenNI2  SuiteSparse  Eigen  zlib  libjpeg  Pangolin  librealsense  - Optional (for Intel RealSense cameras)   Firstly, add  nVidia's official CUDA repository  to your apt sources,\n    then run the following command to pull in most dependencies from the official repos:  sudo apt-get install -y cmake-qt-gui git build-essential libusb-1.0-0-dev libudev-dev openjdk-7-jdk freeglut3-dev libglew-dev cuda-7-5 libsuitesparse-dev libeigen3-dev zlib1g-dev libjpeg-dev  Afterwards install  OpenNI2  and  Pangolin  from source.\nNote, you may need to manually tell CMake where OpenNI2 is since Occipital's fork does not\n    have an install option.\nIt is important to build Pangolin last so that it can find some of the libraries it has\n    optional dependencies on.   When you have all of the dependencies installed, build the Core followed by the GUI.",
            "title": "1.1. Ubuntu"
        },
        {
            "location": "/legacy/v1/README-efusion/#12-windows-visual-studio",
            "text": "Windows 7/10 with Visual Studio 2013 Update 5 (Though other configurations may work)  CMake  OpenGL  CUDA >= 7.0  OpenNI2  SuiteSparse  Eigen  Pangolin  zlib (Pangolin can automatically download and build this)  libjpeg (Pangolin can automatically download and build this)    librealsense  - Optional (for Intel RealSense cameras)   Firstly install cmake and cuda.\nThen download and build from source OpenNI2, SuiteSparse.\nNext download Eigen (no need to build it since it is a header-only library).\nThen download and build from source Pangolin but pay attention to the following cmake settings. \nThere will be a lot of dependencies where path was not found.\nThat is OK except OPENNI2 and EIGEN3 (those should be set to valid paths).\nYou also need to set MSVC_USE_STATIC_CRT to false in order to correctly link\n    to ElasticFusion projects.\nAlso, you can set BUILD_EXAMPLES to false since we don't need them and some were crashing\n    on my machine.  Finally, build Core and GUI.",
            "title": "1.2. Windows - Visual Studio"
        },
        {
            "location": "/legacy/v1/README-efusion/#2-is-there-an-easier-way-to-build-it",
            "text": "Yes, if you run the  build.sh  script on a fresh clean install\n    of Ubuntu 14.04, 15.04, or 16.04, enter your password for sudo a few times and wait\n    a few minutes all dependencies will get downloaded and installed and\n    it should build everything correctly.\nThis has not been tested on anything but fresh installs, so I would advise using it\n    with caution if you already have some of the dependencies installed.",
            "title": "2. Is there an easier way to build it?"
        },
        {
            "location": "/legacy/v1/README-efusion/#3-installation-issues",
            "text": "#include <Eigen/Core>  not found  sudo ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen\nsudo ln -sf /usr/include/eigen3/unsupported /usr/include/unsupported  invalid use of incomplete type \u2018const struct Eigen ...  Pangolin must be installed AFTER all the other libraries to make use of optional dependencies.  GLSL 3.30 is not supported.\nSupported versions are 1.10, 1.20, 1.30, 1.00 ES and 3.00 ES  Make sure you are running ElasticFusion on your nVidia GPU.\nIn particular, if you have an Optimus GPU\n-   If you use Prime, follow instructions  here \n-   If you use Bumblebee, remember to run as  optirun ./ElasticFusion",
            "title": "3. Installation issues"
        },
        {
            "location": "/legacy/v1/README-efusion/#4-how-do-i-use-it",
            "text": "There are three subprojects in the repo:   The  Core  is the main engine which builds into a shared library that you can link\n        into other projects and treat like an API.   The  GUI  is the graphical interface used to run the system on either live sensor data\n        or a logged data file.   The  GPUTest  is a small benchmarking program you can use to tune\n        the CUDA kernel launch parameters used in the main engine.    The GUI ( ElasticFusion ) can take a bunch of parameters when launching it from the command line.\nThey are as follows:   -cal   : Loads a camera calibration file specified as  fx fy cx cy .  -l   : Processes the specified .klg log file.  -p   : Loads ground truth poses to use instead of estimated pose.  -c   : Surfel confidence threshold (default  10 ).  -d   : Cutoff distance for depth processing (default  3 m).  -i   : Relative ICP/RGB tracking weight (default  10 ).  -ie   : Local loop closure residual threshold (default  5e-05 ).  -ic   : Local loop closure inlier threshold (default  35000 ).  -cv   : Local loop closure covariance threshold (default  1e-05 ).  -pt   : Global loop closure photometric threshold (default  115 ).  -ft   : Fern encoding threshold (default  0.3095 ).  -t   : Time window length (default  200 ).  -s   : Frames to skip at start of log.  -e   : Cut off frame of log.  -f  : Flip RGB/BGR.  -icl  : Enable this if using the  ICL-NUIM  dataset\n        (flips normals to account for negative focal length on that data).  -o  : Open loop mode.  -rl  : Enable relocalisation.  -fs  : Frame skip if processing a log to simulate real-time.  -q  : Quit when finished a log.  -fo  : Fast odometry (single level pyramid).  -nso  : Disables SO(3) pre-alignment in tracking.  -r  : Rewind and loop log forever.   -ftf  : Do frame-to-frame RGB tracking.   -sc  : Showcase mode (minimal GUI).   Essentially by default  ./ElasticFusion  will try run off an attached ASUS sensor live.\nYou can provide a .klg log file instead with the -l parameter. \nYou can capture .klg format logs using either  Logger1  or  Logger2 .",
            "title": "4. How do I use it?"
        },
        {
            "location": "/legacy/v1/README-efusion/#5-how-do-i-just-use-the-core-api",
            "text": "The libefusion.so shared library which gets built by the Core is what you want to link against.  An example of this can be seen in the GUI code.\nEssentially all you need to do is utilise the provided Findefusion.cmake file in GUI/src\n    and include the following in your CMakeLists.txt file:  find_package(efusion REQUIRED)\ninclude_directories(${EFUSION_INCLUDE_DIR})\ntarget_link_libraries(MyProject ${EFUSION_LIBRARY})  To then use the Core API, make sure to include the header file in your source file:      #include <ElasticFusion.h>  Initialise the static configuration parameters once somewhere at the start of your program\n    (this  smells , but whatever):      Resolution::getInstance(640, 480);\n    Intrinsics::getInstance(528, 528, 320, 240);  Create an OpenGL context before creating an ElasticFusion object,\n    as ElasticFusion uses OpenGL internally.\nYou can do this whatever way you wish, using Pangolin is probably easiest given it's a dependency:      pangolin::Params windowParams;\n    windowParams.Set(\"SAMPLE_BUFFERS\", 0);\n    windowParams.Set(\"SAMPLES\", 0);\n    pangolin::CreateWindowAndBind(\"Main\", 1280, 800, windowParams);  Make an ElasticFusion object and start using it:      ElasticFusion eFusion;\n    eFusion.processFrame(rgb, depth, timestamp, currentPose, weightMultiplier);  See the source code of MainController.cpp in the GUI source to see more usage.",
            "title": "5. How do I just use the Core API?"
        },
        {
            "location": "/legacy/v1/README-efusion/#6-datasets",
            "text": "We have provided a sample dataset which you can run easily with ElasticFusion\n    for download  here .\nLaunch it as follows:  ./ElasticFusion -l dyson_lab.klg",
            "title": "6. Datasets"
        },
        {
            "location": "/legacy/v1/README-efusion/#7-license",
            "text": "ElasticFusion is freely available for non-commercial use only.\nFull terms and conditions which govern its use are detailed  here  and in the LICENSE.txt file.",
            "title": "7. License"
        },
        {
            "location": "/legacy/v1/README-efusion/#8-faq",
            "text": "What are the hardware requirements?  A  very fast nVidia GPU (3.5TFLOPS+) , and a fast CPU (something like an i7).\nIf you want to use a non-nVidia GPU you can rewrite the tracking code or substitute it\n    with something else, as the rest of the pipeline is actually written in\n    the OpenGL Shading Language.   How can I get performance statistics?  Download  Stopwatch  and run  StopwatchViewer  at the same time as ElasticFusion.   I ran a large dataset and got assert(graph.size() / 16 < MAX_NODES) failed  Currently there's a limit on the number of nodes in the deformation graph down to lazy coding\n    (using a really wide texture instead of a proper 2D one).\nSo we're bound by the maximum dimension of a texture, which is 16384 on modern cards/OpenGL.\nEither fix the code so this isn't a problem any more, or increase the modulo factor\n    in  Shaders/sample.geom .   I have a nice new laptop with a good GPU but it's still slow  If your laptop is running on battery power the GPU will throttle down to save power,\n    so that's unlikely to work (as an aside,  Kintinuous  will run at 30Hz on\n    a modern laptop on battery power these days).\nYou can try disabling SO(3) pre-alignment, enabling fast odometry,\n    only using either ICP or RGB tracking and not both, running in open loop mode\n    or disabling the tracking pyramid.\nAll of these will cost you accuracy.   I saved a map, how can I view it?  Download  Meshlab . Select Render->Shaders->Splatting.   The map keeps getting corrupted - tracking is failing - loop closures\n    are incorrect/not working  Firstly, if you're running live and not processing a log file, ensure you're hitting 30Hz,\n    this is important.\nSecondly, you cannot move the sensor extremely fast because this violates\n    the assumption behind projective data association.\nIn addition to this, you're probably using a primesense, which means you're suffering\n    from motion blur, unsynchronised cameras and rolling shutter.\nAll of these are aggravated by fast motion and hinder tracking performance.   If you're not getting loop closures and expecting some, pay attention to\n    the inlier and residual graphs in the bottom right, these are an indicator of how closae\n    you are to a local loop closure.\nFor global loop closures, you're depending on  fern keyframe encoding  to save you,\n    which like all appearance-based place recognition methods, has its limitations.   Is there a ROS bridge/node?  No.\nThe system relies on an extremely fast and tight coupling between the mapping and tracking\n    on the GPU, which I don't believe ROS supports natively in terms of message passing.   This doesn't seem to work like it did in the videos/papers  A substantial amount of refactoring was carried out in order to open source this system,\n    including rewriting a lot of functionality to avoid certain licenses and reduce dependencies.\nAlthough great care was taken during this process, it is possible that\n    performance regressions were introduced and have not yet been discovered.",
            "title": "8. FAQ"
        },
        {
            "location": "/legacy/v1/README-hotlab/",
            "text": "Computational Holography\n\n\nPart of \nILLIXR\n, the Illinios Extended Reality Benchmark Suite.\nThis component is responsible for calculating image holograms (per-pixel phase masks) using\n    the Weighted Gerchberg\u2013Saxton (GSW) algorithm.\n\n\nFiles\n\n\ngenerateHologram.\ncu\n\n\ngenerateHologram\n\n\nHost side kernel launch code.\n\n\npropagateToSpotPositions\n\n\nCUDA kernel that propagates phases from the SLM plane to the depth plane using Fresnel summation.\n\n\npropagateToSpotSum\n\n\nCUDA kernel that sums up the per-thread block results from the propagateToSpotPositions() kernel.\n\n\npropagateToSLM\n\n\nCUDA kernel that calculates the error function at the depth planes and updates the SLM phases.\n\n\ngoldenHologram.\ncu\n\n\nThe original hologram implementation. This implementation did not support arbitrary SLM sizes\n    and colored holograms.\n\n\nInstallation & Usage\n\n\nUnder \nC/source/\n\n\nmake all\nmake jetson\n\n\n\nmake all\n compiles for the SM75 architecture, while \nmake jetson\n compiles for SM70.\nTo run this code on a older NVIDIA GPU, please change the SM architecture accordingly.\n\n\nTo run our modified hologram code:\n\n\n./hologram\n\n\n\nTo run the original hologram code:\n\n\n./goldenHologram\n\n\n\nLicense\n\n\nThis code is available under the LGPL license.",
            "title": "README hotlab"
        },
        {
            "location": "/legacy/v1/README-hotlab/#computational-holography",
            "text": "Part of  ILLIXR , the Illinios Extended Reality Benchmark Suite.\nThis component is responsible for calculating image holograms (per-pixel phase masks) using\n    the Weighted Gerchberg\u2013Saxton (GSW) algorithm.",
            "title": "Computational Holography"
        },
        {
            "location": "/legacy/v1/README-hotlab/#files",
            "text": "",
            "title": "Files"
        },
        {
            "location": "/legacy/v1/README-hotlab/#generatehologramcu",
            "text": "",
            "title": "generateHologram.cu"
        },
        {
            "location": "/legacy/v1/README-hotlab/#generatehologram",
            "text": "Host side kernel launch code.",
            "title": "generateHologram"
        },
        {
            "location": "/legacy/v1/README-hotlab/#propagatetospotpositions",
            "text": "CUDA kernel that propagates phases from the SLM plane to the depth plane using Fresnel summation.",
            "title": "propagateToSpotPositions"
        },
        {
            "location": "/legacy/v1/README-hotlab/#propagatetospotsum",
            "text": "CUDA kernel that sums up the per-thread block results from the propagateToSpotPositions() kernel.",
            "title": "propagateToSpotSum"
        },
        {
            "location": "/legacy/v1/README-hotlab/#propagatetoslm",
            "text": "CUDA kernel that calculates the error function at the depth planes and updates the SLM phases.",
            "title": "propagateToSLM"
        },
        {
            "location": "/legacy/v1/README-hotlab/#goldenhologramcu",
            "text": "The original hologram implementation. This implementation did not support arbitrary SLM sizes\n    and colored holograms.",
            "title": "goldenHologram.cu"
        },
        {
            "location": "/legacy/v1/README-hotlab/#installation-usage",
            "text": "Under  C/source/  make all\nmake jetson  make all  compiles for the SM75 architecture, while  make jetson  compiles for SM70.\nTo run this code on a older NVIDIA GPU, please change the SM architecture accordingly.  To run our modified hologram code:  ./hologram  To run the original hologram code:  ./goldenHologram",
            "title": "Installation &amp; Usage"
        },
        {
            "location": "/legacy/v1/README-hotlab/#license",
            "text": "This code is available under the LGPL license.",
            "title": "License"
        },
        {
            "location": "/legacy/v1/README-openvins/",
            "text": "Part of \nILLIXR\n, the Illinios Extended Reality Benchmark Suite.\nFor instructions on how to use OpenVINS for ILLIXR, see ILLIXR_INSTRUCTIONS.MD\n\n\nOpen VINS\n\n\nWelcome to the Open VINS project!\nThe Open VINS project houses some core computer vision code along with\n    a state-of-the art filter-based visual-inertial estimator.\nThe core filter is an \nExtended Kalman filter\n which fuses inertial information\n    with sparse visual feature tracks.\nThese visual feature tracks are fused leveraging\n    the \nMulti-State Constraint Kalman Filter (MSCKF)\n sliding window formulation which\n    allows for 3D features to update the state estimate without directly estimating\n    the feature states in the filter.\nInspired by graph-based optimization systems, the included filter has modularity allowing\n    for convenient covariance management with a proper type-based state system.\nPlease take a look at the feature list below for full details on what the system supports.\n\n\n\n\nGithub project page - https://github.com/rpng/open_vins\n\n\nDocumentation - https://docs.openvins.com/\n\n\nGetting started guide - https://docs.openvins.com/getting-started.html\n\n\nPublication reference - TBD\n\n\n\n\nNews / Events\n\n\n\n\nAugust 21, 2019\n - Open sourced \nov_maplab\n for interfacing OpenVINS with\n        the \nmaplab\n library.\n\n\nAugust 15, 2019\n - Initial release of OpenVINS repository and documentation website! \n\n\n\n\nProject Features\n\n\n\n\nSliding window visual-inertial MSCKF\n\n\nModular covariance type system\n\n\nComprehensive documentation and derivations\n\n\nExtendable visual-inertial simulator\n\n\nOn manifold SE(3) b-spline\n\n\nArbitrary number of cameras\n\n\nArbitrary sensor rate\n\n\nAutomatic feature generation\n\n\n\n\n\n\nFive different feature representations\n\n\nGlobal XYZ\n\n\nGlobal inverse depth\n\n\nAnchored XYZ\n\n\nAnchored inverse depth\n\n\nAnchored MSCKF inverse depth\n\n\n\n\n\n\nCalibration of sensor intrinsics and extrinsics\n\n\nCamera to IMU transform \n\n\nCamera to IMU time offset\n\n\nCamera intrinsics\n\n\n\n\n\n\nEnvironmental SLAM feature\n\n\nOpenCV ARUCO tag SLAM features\n\n\nSparse feature SLAM features\n\n\n\n\n\n\nVisual tracking support\n\n\nMonocular camera\n\n\nStereo camera\n\n\nKLT or descriptor based\n\n\n\n\n\n\nStatic IMU initialization (sfm will be open sourced later)\n\n\nOut of the box evaluation on EurocMav and TUM-VI datasets\n\n\nExtensive evaluation suite (ATE, RPE, NEES, RMSE, etc..)\n\n\n\n\nCredit / Licensing\n\n\nThis code was written by the \nRobot Perception and Navigation Group (RPNG)\n\n    at the University of Delaware.\nIf you have any issues with the code please open an issue on our github page\n    with relevant implementation details and references.\nFor researchers that have leveraged or compared to this work, please cite the following:\n\n\n@article{TBD,\n  author    = {},\n  title     = {},\n  journal   = {},\n  volume    = {},\n  year      = {2019},\n}\n\n\n\n\nThe codebase is licensed under the \nGNU General Public License v3 (GPL-3)\n.",
            "title": "README openvins"
        },
        {
            "location": "/legacy/v1/README-openvins/#open-vins",
            "text": "Welcome to the Open VINS project!\nThe Open VINS project houses some core computer vision code along with\n    a state-of-the art filter-based visual-inertial estimator.\nThe core filter is an  Extended Kalman filter  which fuses inertial information\n    with sparse visual feature tracks.\nThese visual feature tracks are fused leveraging\n    the  Multi-State Constraint Kalman Filter (MSCKF)  sliding window formulation which\n    allows for 3D features to update the state estimate without directly estimating\n    the feature states in the filter.\nInspired by graph-based optimization systems, the included filter has modularity allowing\n    for convenient covariance management with a proper type-based state system.\nPlease take a look at the feature list below for full details on what the system supports.   Github project page - https://github.com/rpng/open_vins  Documentation - https://docs.openvins.com/  Getting started guide - https://docs.openvins.com/getting-started.html  Publication reference - TBD",
            "title": "Open VINS"
        },
        {
            "location": "/legacy/v1/README-openvins/#news-events",
            "text": "August 21, 2019  - Open sourced  ov_maplab  for interfacing OpenVINS with\n        the  maplab  library.  August 15, 2019  - Initial release of OpenVINS repository and documentation website!",
            "title": "News / Events"
        },
        {
            "location": "/legacy/v1/README-openvins/#project-features",
            "text": "Sliding window visual-inertial MSCKF  Modular covariance type system  Comprehensive documentation and derivations  Extendable visual-inertial simulator  On manifold SE(3) b-spline  Arbitrary number of cameras  Arbitrary sensor rate  Automatic feature generation    Five different feature representations  Global XYZ  Global inverse depth  Anchored XYZ  Anchored inverse depth  Anchored MSCKF inverse depth    Calibration of sensor intrinsics and extrinsics  Camera to IMU transform   Camera to IMU time offset  Camera intrinsics    Environmental SLAM feature  OpenCV ARUCO tag SLAM features  Sparse feature SLAM features    Visual tracking support  Monocular camera  Stereo camera  KLT or descriptor based    Static IMU initialization (sfm will be open sourced later)  Out of the box evaluation on EurocMav and TUM-VI datasets  Extensive evaluation suite (ATE, RPE, NEES, RMSE, etc..)",
            "title": "Project Features"
        },
        {
            "location": "/legacy/v1/README-openvins/#credit-licensing",
            "text": "This code was written by the  Robot Perception and Navigation Group (RPNG) \n    at the University of Delaware.\nIf you have any issues with the code please open an issue on our github page\n    with relevant implementation details and references.\nFor researchers that have leveraged or compared to this work, please cite the following:  @article{TBD,\n  author    = {},\n  title     = {},\n  journal   = {},\n  volume    = {},\n  year      = {2019},\n}  The codebase is licensed under the  GNU General Public License v3 (GPL-3) .",
            "title": "Credit / Licensing"
        },
        {
            "location": "/legacy/v1/README-ritnet/",
            "text": "This is part of \nILLIXR\n, the Illinios Extended Reality Benchmark Suite.\nThe following explains how to use RITnet.\nThe code is based on Python3, and the profiling results are based on \ntest.py\n.\nFor the testing images, the size per image should be \n640x400\n in gray scale.\nPlease put them under \nSemantic_Segmentation_Dataset/test/images\n.\n\n\nRITnet\n\n\nRITnet is the winnning model of the OpenEDS Semantic Segmentation Challenge.\nIf you use this code, please cite:\n\n\n@misc{chaudhary2019ritnet,\n    title={RITnet: Real-time Semantic Segmentation of the Eye for Gaze Tracking},\n    author={Aayush K. Chaudhary and Rakshit Kothari and Manoj Acharya and Shusil Dangi and Nitinraj Nair and Reynold Bailey and Christopher Kanan and Gabriel Diaz and Jeff B. Pelz},\n    year={2019},\n    eprint={1910.00694},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n\n\n\n\nInstructions:\n\n\npython train.py --help\n\n\nTo train the model with densenet model:\n\n\npython train.py --model densenet --expname FINAL --bs 8 --useGPU True --dataset Semantic_Segmentation_Dataset/\n\n\nTo test the result:\n\n\npython test.py --model densenet --load best_model.pkl --bs 4 --dataset Semantic_Segmentation_Dataset/\n\n\nIf you type in \npython test.py\n, the batch size will be 8.\n\n\nContents in the zip folder\n\n\nbest_model.pkl     :: Our final model (potential winner model) which contains all the weights in Float32 format (Number of Parameters 248900).\nrequirements.txt   :: Includes all the necessary packages for the source code to run \nenvironment.yml    :: List of all packages and version of one of our system in which the code was run successfully. \ndataset.py  ::Data loader and augmentation\ntrain.py    ::Train code\ntest.py     ::Test code\ndensenet.py ::Model code\nutils.py    ::List of utility files\nopt.py      ::List of arguments for argparser\nmodels.py   ::List of all models\nstarburst_black.png:: A fixed structured pattern (with translation) used on train images to handle cases such as multiple reflections.(Train Image: 000000240768.png)\nStarburst generation from train image 000000240768.pdf  ::Procedure how starburst pattern is generated\n\n\n\n\nThe requirements.txt file contains all the packages necessary for the code to run.\nWe have also included an environment.yml file to recreate the conda environment we used.\n\n\nWe have submitted two models from this version of code:\n\n\n\n\nEpoch: 151 Validation accuracy: 95.7780  Test accuracy: 95.276  (Potential Winner Model:\n        Last Submission)\n\n\nEpoch: 117 Validation accuracy: 95.7023  Test accuracy: 95.159  (Our Second Last Submission)\n\n\n\n\nWe could reach upto\nEpoch: 240 Validation accuracy: 95.7820 Test accuracy:NA (Not submitted: result after the deadline)\n\n\nThe dataset.py contains data loader, preprocessing and post processing step\nRequired Preprocessing for all images (test, train and validation set).\n\n\n\n\nGamma correction by a factor of 0.8\n\n\nlocal Contrast limited adaptive histogram equalization algorithm\n        with clipLimit=1.5, tileGridSize=(8,8)\n\n\nNormalization [Mean 0.5, std=0.5]\n\n\n\n\nTrain Image Augmentation Procedure Followed (Not Required during test)\n\n\n\n\nRandom horizontal flip with 50% probability.\n\n\nStarburst pattern augmentation with 20% probability. \n\n\nRandom length lines (1 to 9) augmentation around a random center with 20% probability. \n\n\nGaussian blur with kernel size (7,7) and random sigma (2 to 7) with 20% probability. \n\n\nTranslation of image and labels in any direction with random factor less than 20\n        with 20% probability.\n\n\n\n\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 640, 400]             320\n           Dropout-2         [-1, 32, 640, 400]               0\n         LeakyReLU-3         [-1, 32, 640, 400]               0\n            Conv2d-4         [-1, 32, 640, 400]           1,088\n            Conv2d-5         [-1, 32, 640, 400]           9,248\n           Dropout-6         [-1, 32, 640, 400]               0\n         LeakyReLU-7         [-1, 32, 640, 400]               0\n            Conv2d-8         [-1, 32, 640, 400]           2,112\n            Conv2d-9         [-1, 32, 640, 400]           9,248\n          Dropout-10         [-1, 32, 640, 400]               0\n        LeakyReLU-11         [-1, 32, 640, 400]               0\n      BatchNorm2d-12         [-1, 32, 640, 400]              64\nDenseNet2D_down_block-13         [-1, 32, 640, 400]               0\n        AvgPool2d-14         [-1, 32, 320, 200]               0\n           Conv2d-15         [-1, 32, 320, 200]           9,248\n          Dropout-16         [-1, 32, 320, 200]               0\n        LeakyReLU-17         [-1, 32, 320, 200]               0\n           Conv2d-18         [-1, 32, 320, 200]           2,080\n           Conv2d-19         [-1, 32, 320, 200]           9,248\n          Dropout-20         [-1, 32, 320, 200]               0\n        LeakyReLU-21         [-1, 32, 320, 200]               0\n           Conv2d-22         [-1, 32, 320, 200]           3,104\n           Conv2d-23         [-1, 32, 320, 200]           9,248\n          Dropout-24         [-1, 32, 320, 200]               0\n        LeakyReLU-25         [-1, 32, 320, 200]               0\n      BatchNorm2d-26         [-1, 32, 320, 200]              64\nDenseNet2D_down_block-27         [-1, 32, 320, 200]               0\n        AvgPool2d-28         [-1, 32, 160, 100]               0\n           Conv2d-29         [-1, 32, 160, 100]           9,248\n          Dropout-30         [-1, 32, 160, 100]               0\n        LeakyReLU-31         [-1, 32, 160, 100]               0\n           Conv2d-32         [-1, 32, 160, 100]           2,080\n           Conv2d-33         [-1, 32, 160, 100]           9,248\n          Dropout-34         [-1, 32, 160, 100]               0\n        LeakyReLU-35         [-1, 32, 160, 100]               0\n           Conv2d-36         [-1, 32, 160, 100]           3,104\n           Conv2d-37         [-1, 32, 160, 100]           9,248\n          Dropout-38         [-1, 32, 160, 100]               0\n        LeakyReLU-39         [-1, 32, 160, 100]               0\n      BatchNorm2d-40         [-1, 32, 160, 100]              64\nDenseNet2D_down_block-41         [-1, 32, 160, 100]               0\n        AvgPool2d-42           [-1, 32, 80, 50]               0\n           Conv2d-43           [-1, 32, 80, 50]           9,248\n          Dropout-44           [-1, 32, 80, 50]               0\n        LeakyReLU-45           [-1, 32, 80, 50]               0\n           Conv2d-46           [-1, 32, 80, 50]           2,080\n           Conv2d-47           [-1, 32, 80, 50]           9,248\n          Dropout-48           [-1, 32, 80, 50]               0\n        LeakyReLU-49           [-1, 32, 80, 50]               0\n           Conv2d-50           [-1, 32, 80, 50]           3,104\n           Conv2d-51           [-1, 32, 80, 50]           9,248\n          Dropout-52           [-1, 32, 80, 50]               0\n        LeakyReLU-53           [-1, 32, 80, 50]               0\n      BatchNorm2d-54           [-1, 32, 80, 50]              64\nDenseNet2D_down_block-55           [-1, 32, 80, 50]               0\n        AvgPool2d-56           [-1, 32, 40, 25]               0\n           Conv2d-57           [-1, 32, 40, 25]           9,248\n          Dropout-58           [-1, 32, 40, 25]               0\n        LeakyReLU-59           [-1, 32, 40, 25]               0\n           Conv2d-60           [-1, 32, 40, 25]           2,080\n           Conv2d-61           [-1, 32, 40, 25]           9,248\n          Dropout-62           [-1, 32, 40, 25]               0\n        LeakyReLU-63           [-1, 32, 40, 25]               0\n           Conv2d-64           [-1, 32, 40, 25]           3,104\n           Conv2d-65           [-1, 32, 40, 25]           9,248\n          Dropout-66           [-1, 32, 40, 25]               0\n        LeakyReLU-67           [-1, 32, 40, 25]               0\n      BatchNorm2d-68           [-1, 32, 40, 25]              64\nDenseNet2D_down_block-69           [-1, 32, 40, 25]               0\n           Conv2d-70           [-1, 32, 80, 50]           2,080\n           Conv2d-71           [-1, 32, 80, 50]           9,248\n          Dropout-72           [-1, 32, 80, 50]               0\n        LeakyReLU-73           [-1, 32, 80, 50]               0\n           Conv2d-74           [-1, 32, 80, 50]           3,104\n           Conv2d-75           [-1, 32, 80, 50]           9,248\n          Dropout-76           [-1, 32, 80, 50]               0\n        LeakyReLU-77           [-1, 32, 80, 50]               0\nDenseNet2D_up_block_concat-78           [-1, 32, 80, 50]               0\n           Conv2d-79         [-1, 32, 160, 100]           2,080\n           Conv2d-80         [-1, 32, 160, 100]           9,248\n          Dropout-81         [-1, 32, 160, 100]               0\n        LeakyReLU-82         [-1, 32, 160, 100]               0\n           Conv2d-83         [-1, 32, 160, 100]           3,104\n           Conv2d-84         [-1, 32, 160, 100]           9,248\n          Dropout-85         [-1, 32, 160, 100]               0\n        LeakyReLU-86         [-1, 32, 160, 100]               0\nDenseNet2D_up_block_concat-87         [-1, 32, 160, 100]               0\n           Conv2d-88         [-1, 32, 320, 200]           2,080\n           Conv2d-89         [-1, 32, 320, 200]           9,248\n          Dropout-90         [-1, 32, 320, 200]               0\n        LeakyReLU-91         [-1, 32, 320, 200]               0\n           Conv2d-92         [-1, 32, 320, 200]           3,104\n           Conv2d-93         [-1, 32, 320, 200]           9,248\n          Dropout-94         [-1, 32, 320, 200]               0\n        LeakyReLU-95         [-1, 32, 320, 200]               0\nDenseNet2D_up_block_concat-96         [-1, 32, 320, 200]               0\n           Conv2d-97         [-1, 32, 640, 400]           2,080\n           Conv2d-98         [-1, 32, 640, 400]           9,248\n          Dropout-99         [-1, 32, 640, 400]               0\n       LeakyReLU-100         [-1, 32, 640, 400]               0\n          Conv2d-101         [-1, 32, 640, 400]           3,104\n          Conv2d-102         [-1, 32, 640, 400]           9,248\n         Dropout-103         [-1, 32, 640, 400]               0\n       LeakyReLU-104         [-1, 32, 640, 400]               0\nDenseNet2D_up_block_concat-105         [-1, 32, 640, 400]               0\n         Dropout-106         [-1, 32, 640, 400]               0\n          Conv2d-107          [-1, 4, 640, 400]             132\n================================================================\nTotal params: 248,900\nTrainable params: 248,900\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.98\nForward/backward pass size (MB): 1920.41\nParams size (MB): 0.95\nEstimated Total Size (MB): 1922.34\n----------------------------------------------------------------",
            "title": "README ritnet"
        },
        {
            "location": "/legacy/v1/README-ritnet/#ritnet",
            "text": "RITnet is the winnning model of the OpenEDS Semantic Segmentation Challenge.\nIf you use this code, please cite:  @misc{chaudhary2019ritnet,\n    title={RITnet: Real-time Semantic Segmentation of the Eye for Gaze Tracking},\n    author={Aayush K. Chaudhary and Rakshit Kothari and Manoj Acharya and Shusil Dangi and Nitinraj Nair and Reynold Bailey and Christopher Kanan and Gabriel Diaz and Jeff B. Pelz},\n    year={2019},\n    eprint={1910.00694},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}  Instructions:  python train.py --help  To train the model with densenet model:  python train.py --model densenet --expname FINAL --bs 8 --useGPU True --dataset Semantic_Segmentation_Dataset/  To test the result:  python test.py --model densenet --load best_model.pkl --bs 4 --dataset Semantic_Segmentation_Dataset/  If you type in  python test.py , the batch size will be 8.",
            "title": "RITnet"
        },
        {
            "location": "/legacy/v1/README-ritnet/#contents-in-the-zip-folder",
            "text": "best_model.pkl     :: Our final model (potential winner model) which contains all the weights in Float32 format (Number of Parameters 248900).\nrequirements.txt   :: Includes all the necessary packages for the source code to run \nenvironment.yml    :: List of all packages and version of one of our system in which the code was run successfully. \ndataset.py  ::Data loader and augmentation\ntrain.py    ::Train code\ntest.py     ::Test code\ndensenet.py ::Model code\nutils.py    ::List of utility files\nopt.py      ::List of arguments for argparser\nmodels.py   ::List of all models\nstarburst_black.png:: A fixed structured pattern (with translation) used on train images to handle cases such as multiple reflections.(Train Image: 000000240768.png)\nStarburst generation from train image 000000240768.pdf  ::Procedure how starburst pattern is generated  The requirements.txt file contains all the packages necessary for the code to run.\nWe have also included an environment.yml file to recreate the conda environment we used.  We have submitted two models from this version of code:   Epoch: 151 Validation accuracy: 95.7780  Test accuracy: 95.276  (Potential Winner Model:\n        Last Submission)  Epoch: 117 Validation accuracy: 95.7023  Test accuracy: 95.159  (Our Second Last Submission)   We could reach upto\nEpoch: 240 Validation accuracy: 95.7820 Test accuracy:NA (Not submitted: result after the deadline)  The dataset.py contains data loader, preprocessing and post processing step\nRequired Preprocessing for all images (test, train and validation set).   Gamma correction by a factor of 0.8  local Contrast limited adaptive histogram equalization algorithm\n        with clipLimit=1.5, tileGridSize=(8,8)  Normalization [Mean 0.5, std=0.5]   Train Image Augmentation Procedure Followed (Not Required during test)   Random horizontal flip with 50% probability.  Starburst pattern augmentation with 20% probability.   Random length lines (1 to 9) augmentation around a random center with 20% probability.   Gaussian blur with kernel size (7,7) and random sigma (2 to 7) with 20% probability.   Translation of image and labels in any direction with random factor less than 20\n        with 20% probability.   ----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 640, 400]             320\n           Dropout-2         [-1, 32, 640, 400]               0\n         LeakyReLU-3         [-1, 32, 640, 400]               0\n            Conv2d-4         [-1, 32, 640, 400]           1,088\n            Conv2d-5         [-1, 32, 640, 400]           9,248\n           Dropout-6         [-1, 32, 640, 400]               0\n         LeakyReLU-7         [-1, 32, 640, 400]               0\n            Conv2d-8         [-1, 32, 640, 400]           2,112\n            Conv2d-9         [-1, 32, 640, 400]           9,248\n          Dropout-10         [-1, 32, 640, 400]               0\n        LeakyReLU-11         [-1, 32, 640, 400]               0\n      BatchNorm2d-12         [-1, 32, 640, 400]              64\nDenseNet2D_down_block-13         [-1, 32, 640, 400]               0\n        AvgPool2d-14         [-1, 32, 320, 200]               0\n           Conv2d-15         [-1, 32, 320, 200]           9,248\n          Dropout-16         [-1, 32, 320, 200]               0\n        LeakyReLU-17         [-1, 32, 320, 200]               0\n           Conv2d-18         [-1, 32, 320, 200]           2,080\n           Conv2d-19         [-1, 32, 320, 200]           9,248\n          Dropout-20         [-1, 32, 320, 200]               0\n        LeakyReLU-21         [-1, 32, 320, 200]               0\n           Conv2d-22         [-1, 32, 320, 200]           3,104\n           Conv2d-23         [-1, 32, 320, 200]           9,248\n          Dropout-24         [-1, 32, 320, 200]               0\n        LeakyReLU-25         [-1, 32, 320, 200]               0\n      BatchNorm2d-26         [-1, 32, 320, 200]              64\nDenseNet2D_down_block-27         [-1, 32, 320, 200]               0\n        AvgPool2d-28         [-1, 32, 160, 100]               0\n           Conv2d-29         [-1, 32, 160, 100]           9,248\n          Dropout-30         [-1, 32, 160, 100]               0\n        LeakyReLU-31         [-1, 32, 160, 100]               0\n           Conv2d-32         [-1, 32, 160, 100]           2,080\n           Conv2d-33         [-1, 32, 160, 100]           9,248\n          Dropout-34         [-1, 32, 160, 100]               0\n        LeakyReLU-35         [-1, 32, 160, 100]               0\n           Conv2d-36         [-1, 32, 160, 100]           3,104\n           Conv2d-37         [-1, 32, 160, 100]           9,248\n          Dropout-38         [-1, 32, 160, 100]               0\n        LeakyReLU-39         [-1, 32, 160, 100]               0\n      BatchNorm2d-40         [-1, 32, 160, 100]              64\nDenseNet2D_down_block-41         [-1, 32, 160, 100]               0\n        AvgPool2d-42           [-1, 32, 80, 50]               0\n           Conv2d-43           [-1, 32, 80, 50]           9,248\n          Dropout-44           [-1, 32, 80, 50]               0\n        LeakyReLU-45           [-1, 32, 80, 50]               0\n           Conv2d-46           [-1, 32, 80, 50]           2,080\n           Conv2d-47           [-1, 32, 80, 50]           9,248\n          Dropout-48           [-1, 32, 80, 50]               0\n        LeakyReLU-49           [-1, 32, 80, 50]               0\n           Conv2d-50           [-1, 32, 80, 50]           3,104\n           Conv2d-51           [-1, 32, 80, 50]           9,248\n          Dropout-52           [-1, 32, 80, 50]               0\n        LeakyReLU-53           [-1, 32, 80, 50]               0\n      BatchNorm2d-54           [-1, 32, 80, 50]              64\nDenseNet2D_down_block-55           [-1, 32, 80, 50]               0\n        AvgPool2d-56           [-1, 32, 40, 25]               0\n           Conv2d-57           [-1, 32, 40, 25]           9,248\n          Dropout-58           [-1, 32, 40, 25]               0\n        LeakyReLU-59           [-1, 32, 40, 25]               0\n           Conv2d-60           [-1, 32, 40, 25]           2,080\n           Conv2d-61           [-1, 32, 40, 25]           9,248\n          Dropout-62           [-1, 32, 40, 25]               0\n        LeakyReLU-63           [-1, 32, 40, 25]               0\n           Conv2d-64           [-1, 32, 40, 25]           3,104\n           Conv2d-65           [-1, 32, 40, 25]           9,248\n          Dropout-66           [-1, 32, 40, 25]               0\n        LeakyReLU-67           [-1, 32, 40, 25]               0\n      BatchNorm2d-68           [-1, 32, 40, 25]              64\nDenseNet2D_down_block-69           [-1, 32, 40, 25]               0\n           Conv2d-70           [-1, 32, 80, 50]           2,080\n           Conv2d-71           [-1, 32, 80, 50]           9,248\n          Dropout-72           [-1, 32, 80, 50]               0\n        LeakyReLU-73           [-1, 32, 80, 50]               0\n           Conv2d-74           [-1, 32, 80, 50]           3,104\n           Conv2d-75           [-1, 32, 80, 50]           9,248\n          Dropout-76           [-1, 32, 80, 50]               0\n        LeakyReLU-77           [-1, 32, 80, 50]               0\nDenseNet2D_up_block_concat-78           [-1, 32, 80, 50]               0\n           Conv2d-79         [-1, 32, 160, 100]           2,080\n           Conv2d-80         [-1, 32, 160, 100]           9,248\n          Dropout-81         [-1, 32, 160, 100]               0\n        LeakyReLU-82         [-1, 32, 160, 100]               0\n           Conv2d-83         [-1, 32, 160, 100]           3,104\n           Conv2d-84         [-1, 32, 160, 100]           9,248\n          Dropout-85         [-1, 32, 160, 100]               0\n        LeakyReLU-86         [-1, 32, 160, 100]               0\nDenseNet2D_up_block_concat-87         [-1, 32, 160, 100]               0\n           Conv2d-88         [-1, 32, 320, 200]           2,080\n           Conv2d-89         [-1, 32, 320, 200]           9,248\n          Dropout-90         [-1, 32, 320, 200]               0\n        LeakyReLU-91         [-1, 32, 320, 200]               0\n           Conv2d-92         [-1, 32, 320, 200]           3,104\n           Conv2d-93         [-1, 32, 320, 200]           9,248\n          Dropout-94         [-1, 32, 320, 200]               0\n        LeakyReLU-95         [-1, 32, 320, 200]               0\nDenseNet2D_up_block_concat-96         [-1, 32, 320, 200]               0\n           Conv2d-97         [-1, 32, 640, 400]           2,080\n           Conv2d-98         [-1, 32, 640, 400]           9,248\n          Dropout-99         [-1, 32, 640, 400]               0\n       LeakyReLU-100         [-1, 32, 640, 400]               0\n          Conv2d-101         [-1, 32, 640, 400]           3,104\n          Conv2d-102         [-1, 32, 640, 400]           9,248\n         Dropout-103         [-1, 32, 640, 400]               0\n       LeakyReLU-104         [-1, 32, 640, 400]               0\nDenseNet2D_up_block_concat-105         [-1, 32, 640, 400]               0\n         Dropout-106         [-1, 32, 640, 400]               0\n          Conv2d-107          [-1, 4, 640, 400]             132\n================================================================\nTotal params: 248,900\nTrainable params: 248,900\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.98\nForward/backward pass size (MB): 1920.41\nParams size (MB): 0.95\nEstimated Total Size (MB): 1922.34\n----------------------------------------------------------------",
            "title": "Contents in the zip folder"
        },
        {
            "location": "/legacy/v1/README-visualpp/",
            "text": "Visual Post-Processing Pipeline\n\n\nPart of \nILLIXR\n, the Illinios Extended Reality Benchmark Suite.\nThis repo contains code for\n    lens distortion correction,\n    chromatic aberration correction,\n    and\n    timewarp.\n\n\nSome of the FBO intialization code is borrowed from Song Ho Ahn's excellent tutorial series.\nThe particular FBO code used is found at his \nwebsite\n.\n\n\nThe image loader is based on Morten Nobel-J\u00f8rgensen's \nblog post\n.\n\n\nCompiling and Running\n\n\nCompile on Linux with the included makefile. Run with \n./fbo <input image>\n\n\nWe provide three examples, \nlandscape.png\n, \nmuseum.png\n, and \ntundra.png\n,\n    but any PNG image should work.",
            "title": "README visualpp"
        },
        {
            "location": "/legacy/v1/README-visualpp/#visual-post-processing-pipeline",
            "text": "Part of  ILLIXR , the Illinios Extended Reality Benchmark Suite.\nThis repo contains code for\n    lens distortion correction,\n    chromatic aberration correction,\n    and\n    timewarp.  Some of the FBO intialization code is borrowed from Song Ho Ahn's excellent tutorial series.\nThe particular FBO code used is found at his  website .  The image loader is based on Morten Nobel-J\u00f8rgensen's  blog post .",
            "title": "Visual Post-Processing Pipeline"
        },
        {
            "location": "/legacy/v1/README-visualpp/#compiling-and-running",
            "text": "Compile on Linux with the included makefile. Run with  ./fbo <input image>  We provide three examples,  landscape.png ,  museum.png , and  tundra.png ,\n    but any PNG image should work.",
            "title": "Compiling and Running"
        },
        {
            "location": "/legacy/v1/",
            "text": "This is the final release of ILLIXR that contains only standalone components.\nAll future releases will contain both the components and the runtime, and can be found \nhere\n.\n\n\nILLIXR\n\n\nILLIXR (pronounced like elixir) is an open-source Extended Reality (XR) benchmark suite.\nIt contains several core state-of-the-art components of a generic XR pipeline,\n    components that are required in most, if not all, XR applications.\nWe use the term \ncomponents\n and not \nkernels\n or \ncomputations\n because each component\n    of ILLIXR is an entire application in itself, and consists of many kernels and computations.\nAt the moment, ILLIXR contains the following state-of-the-art components,\n    all of which are included as sub-modules in this repo.\n\n\n\n\nSimultaneous Localization and Mapping\n\n\nScene reconstruction\n\n\nEye tracking\n\n\nAmbisonic encoding\n\n\nAmbisonic manipulation and binauralization\n\n\nLens distortion correction\n\n\nChromatic aberration correction\n\n\nTime warp\n\n\nComputational holography for adaptive multi-focal displays\n\n\n\n\nWe plan on adding more components to ILLIXR\n    (e.g., graphics and multiple versions for individual components),\n    including a runtime to integrate all of the components into a full XR system.\nOur goal is not to create a commercial quality XR product for current hardware.\nInstead, the goal for ILLIXR is to advance\n    computer architecture,\n    systems,\n    and\n    hardware-software co-design\n    research for XR by making available key state-of-the-art components of both modern\n    and future XR applications. \n\n\nMany of the current components of ILLIXR were developed by domain experts and obtained\n    from publicly available repositories.\nThey were modified for one or more of the following reasons:\n    fixing compilation,\n    adding features,\n    or\n    removing extraneous code or dependencies.\nEach component not developed by us is available as a forked github repository\n    for proper attribution to its authors.\n\n\nDetailed descriptions of each component, including performance and energy profiles,\n    can be found in our \npaper\n.\n\n\nPublications\n\n\nWe request that you cite our following paper when you use ILLIXR for a publication.\nWe would also appreciate it if you send us a citation once your work has been published.\n\n\n@misc{HuzaifaDesai2020,\n    title={Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research},\n    author={Muhammad Huzaifa and Rishi Desai and Xutao Jiang and Joseph Ravichandran and Finn Sinclair and Sarita V. Adve},\n    year={2020},\n    eprint={2004.04643},\n    primaryClass={cs.DC}\n}\n\n\n\n\nSetup\n\n\nEach component of ILLIXR is packaged as its own repository for modularity.\nPlease refer to the setup instructions of each individual component in \nbenchmark/\n.\n\n\nTo clone this repo use the following command:\n\n\ngit clone https://github.com/ILLIXR/ILLIXR.git --recursive\n\n\n\n\nAcknowledgements\n\n\nMuhammad Huzaifa led the development of ILLIXR in \nSarita Adve\u2019s research group\n\n    at the University of Illinois at Urbana-Champaign.\nOther major contributors include\n    Rishi Desai,\n    Samuel Grayson,\n    Xutao Jiang,\n    Ying Jing,\n    Fang Lu,\n    Joseph Ravichandran,\n    and\n    Finn Sinclair.\n\n\nILLIXR came together after many consultations with researchers and practitioners in many domains:\n    audio,\n    graphics,\n    optics,\n    robotics,\n    signal processing,\n    and\n    extended reality systems.\nWe are deeply grateful for all of these discussions and specifically to the following:\n    Wei Cu,\n    Aleksandra Faust,\n    Liang Gao,\n    Matt Horsnell,\n    Amit Jindal,\n    Steve LaValle,\n    Steve Lovegrove,\n    Andrew Maimone,\n    Vegard \u00d8ye,\n    Martin Persson,\n    Archontis Politis,\n    Eric Shaffer,\n    Paris Smaragdis,\n    Sachin Talathi,\n    and\n    Chris Widdowson.\n\n\nThe development of ILLIXR was supported by\n    the Applications Driving Architectures (ADA) Research Center,\n        a JUMP Center co-sponsored by SRC and DARPA,\n    the Center for Future Architectures Research (C-FAR),\n        one of the six centers of STARnet,\n    a Semiconductor Research Corporation program sponsored by MARCO and DARPA,\n    and\n    by a Google Faculty Research Award.\nThe development of ILLIXR was also aided by generous hardware and software donations\n    from ARM and NVIDIA.\nFacebook Reality Labs provided the \nOpenEDS Semantic Segmentation Dataset\n.\n\n\nWesley Darvin came up with the name for ILLIXR.\nAbdulrahman Mahmoud helped with the design of this website.\n\n\nLicensing Structure\n\n\nILLIXR is available as open-source software under\n    the \nUniversity of Illinois/NCSA Open Source License\n.\nAs mentioned above, ILLIXR largely consists of components developed by domain experts and\n    modified for the purposes of inclusion in ILLIXR.\nHowever, ILLIXR does contain software developed solely by us.\n\nThe NCSA license is limited to only this software\n.\nThe external libraries and softwares included in ILLIXR each have their own licenses and\n    must be used according to those licenses:\n\n\n\n\nOpen-VINS\n - \nGNU General Public License v3.0\n\n\nElasticFusion\n - \nElasticFusion license\n\n\nRITnet\n - \nMIT License\n\n\nlibspatialaudio\n - \nGNU Lesser General Public License v2.1\n\n\nHOTlab\n - \nGNU Lesser General Public License v3.0\n\n\n\n\nGet In Touch\n\n\nWhether you are\n    a computer architect,\n    a systems person,\n    an XR application developer,\n    or\n    just anyone interested in XR,\n    we would love to hear your feedback on ILLIXR!\nILLIXR is a living benchmark suite and we would like to both refine existing components\n    and add new ones.\nWe believe ILLIXR has the opportunity to drive future computer architecture\n    and systems research for XR, and can benefit from contributions from other researchers\n    and organizations.\nIf you would like to be a part of this effort, please contact us at\n    \nillixr at cs dot illinois dot edu\n.",
            "title": "Home"
        },
        {
            "location": "/legacy/v1/#illixr",
            "text": "ILLIXR (pronounced like elixir) is an open-source Extended Reality (XR) benchmark suite.\nIt contains several core state-of-the-art components of a generic XR pipeline,\n    components that are required in most, if not all, XR applications.\nWe use the term  components  and not  kernels  or  computations  because each component\n    of ILLIXR is an entire application in itself, and consists of many kernels and computations.\nAt the moment, ILLIXR contains the following state-of-the-art components,\n    all of which are included as sub-modules in this repo.   Simultaneous Localization and Mapping  Scene reconstruction  Eye tracking  Ambisonic encoding  Ambisonic manipulation and binauralization  Lens distortion correction  Chromatic aberration correction  Time warp  Computational holography for adaptive multi-focal displays   We plan on adding more components to ILLIXR\n    (e.g., graphics and multiple versions for individual components),\n    including a runtime to integrate all of the components into a full XR system.\nOur goal is not to create a commercial quality XR product for current hardware.\nInstead, the goal for ILLIXR is to advance\n    computer architecture,\n    systems,\n    and\n    hardware-software co-design\n    research for XR by making available key state-of-the-art components of both modern\n    and future XR applications.   Many of the current components of ILLIXR were developed by domain experts and obtained\n    from publicly available repositories.\nThey were modified for one or more of the following reasons:\n    fixing compilation,\n    adding features,\n    or\n    removing extraneous code or dependencies.\nEach component not developed by us is available as a forked github repository\n    for proper attribution to its authors.  Detailed descriptions of each component, including performance and energy profiles,\n    can be found in our  paper .",
            "title": "ILLIXR"
        },
        {
            "location": "/legacy/v1/#publications",
            "text": "We request that you cite our following paper when you use ILLIXR for a publication.\nWe would also appreciate it if you send us a citation once your work has been published.  @misc{HuzaifaDesai2020,\n    title={Exploring Extended Reality with ILLIXR: A new Playground for Architecture Research},\n    author={Muhammad Huzaifa and Rishi Desai and Xutao Jiang and Joseph Ravichandran and Finn Sinclair and Sarita V. Adve},\n    year={2020},\n    eprint={2004.04643},\n    primaryClass={cs.DC}\n}",
            "title": "Publications"
        },
        {
            "location": "/legacy/v1/#setup",
            "text": "Each component of ILLIXR is packaged as its own repository for modularity.\nPlease refer to the setup instructions of each individual component in  benchmark/ .  To clone this repo use the following command:  git clone https://github.com/ILLIXR/ILLIXR.git --recursive",
            "title": "Setup"
        },
        {
            "location": "/legacy/v1/#acknowledgements",
            "text": "Muhammad Huzaifa led the development of ILLIXR in  Sarita Adve\u2019s research group \n    at the University of Illinois at Urbana-Champaign.\nOther major contributors include\n    Rishi Desai,\n    Samuel Grayson,\n    Xutao Jiang,\n    Ying Jing,\n    Fang Lu,\n    Joseph Ravichandran,\n    and\n    Finn Sinclair.  ILLIXR came together after many consultations with researchers and practitioners in many domains:\n    audio,\n    graphics,\n    optics,\n    robotics,\n    signal processing,\n    and\n    extended reality systems.\nWe are deeply grateful for all of these discussions and specifically to the following:\n    Wei Cu,\n    Aleksandra Faust,\n    Liang Gao,\n    Matt Horsnell,\n    Amit Jindal,\n    Steve LaValle,\n    Steve Lovegrove,\n    Andrew Maimone,\n    Vegard \u00d8ye,\n    Martin Persson,\n    Archontis Politis,\n    Eric Shaffer,\n    Paris Smaragdis,\n    Sachin Talathi,\n    and\n    Chris Widdowson.  The development of ILLIXR was supported by\n    the Applications Driving Architectures (ADA) Research Center,\n        a JUMP Center co-sponsored by SRC and DARPA,\n    the Center for Future Architectures Research (C-FAR),\n        one of the six centers of STARnet,\n    a Semiconductor Research Corporation program sponsored by MARCO and DARPA,\n    and\n    by a Google Faculty Research Award.\nThe development of ILLIXR was also aided by generous hardware and software donations\n    from ARM and NVIDIA.\nFacebook Reality Labs provided the  OpenEDS Semantic Segmentation Dataset .  Wesley Darvin came up with the name for ILLIXR.\nAbdulrahman Mahmoud helped with the design of this website.",
            "title": "Acknowledgements"
        },
        {
            "location": "/legacy/v1/#licensing-structure",
            "text": "ILLIXR is available as open-source software under\n    the  University of Illinois/NCSA Open Source License .\nAs mentioned above, ILLIXR largely consists of components developed by domain experts and\n    modified for the purposes of inclusion in ILLIXR.\nHowever, ILLIXR does contain software developed solely by us. The NCSA license is limited to only this software .\nThe external libraries and softwares included in ILLIXR each have their own licenses and\n    must be used according to those licenses:   Open-VINS  -  GNU General Public License v3.0  ElasticFusion  -  ElasticFusion license  RITnet  -  MIT License  libspatialaudio  -  GNU Lesser General Public License v2.1  HOTlab  -  GNU Lesser General Public License v3.0",
            "title": "Licensing Structure"
        },
        {
            "location": "/legacy/v1/#get-in-touch",
            "text": "Whether you are\n    a computer architect,\n    a systems person,\n    an XR application developer,\n    or\n    just anyone interested in XR,\n    we would love to hear your feedback on ILLIXR!\nILLIXR is a living benchmark suite and we would like to both refine existing components\n    and add new ones.\nWe believe ILLIXR has the opportunity to drive future computer architecture\n    and systems research for XR, and can benefit from contributions from other researchers\n    and organizations.\nIf you would like to be a part of this effort, please contact us at\n     illixr at cs dot illinois dot edu .",
            "title": "Get In Touch"
        }
    ]
}